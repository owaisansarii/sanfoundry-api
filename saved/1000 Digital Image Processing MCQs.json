[
    {
        "id": 1,
        "Question": "The spatial coordinates of a digital image (x,y) are proportional to:",
        "Options": [
            "a) Position",
            "b) Brightness",
            "c) Contrast",
            "d) Noise"
        ],
        "Answer": "Answer: b\nExplanation: The Brightness levels are distributed over the spatial area. Hence, the spatial coordinates are proportional to brightness levels."
    },
    {
        "id": 2,
        "Question": "Among the following image processing techniques which is fast, precise and flexible.",
        "Options": [
            "a)   Optical",
            "b)   Digital",
            "c)   Electronic",
            "d)   Photographic"
        ],
        "Answer": "Answer: b\nExplanation: Digital image processing is more flexible and agile techniques as it is fast, accurate and reliable."
    },
    {
        "id": 3,
        "Question": "An image is considered to be a function of a(x,y), where a represents:",
        "Options": [
            "a) Height of image",
            "b) Width of image",
            "c) Amplitude of image",
            "d) Resolution of image"
        ],
        "Answer": "Answer: c\nExplanation: The image is a collection of dots with a definite intensity or amplitude."
    },
    {
        "id": 4,
        "Question": "What is pixel?",
        "Options": [
            "a) Pixel is the elements of a digital image",
            "b) Pixel is the elements of an analog image",
            "c) Pixel is the cluster of a digital image",
            "d) Pixel is the cluster of an analog image"
        ],
        "Answer": "Answer: a\nExplanation: An Image is a collection of individual points referred as pixel, thus a Pixel is the element of a digital image."
    },
    {
        "id": 5,
        "Question": "The range of values spanned by the gray scale is called:",
        "Options": [
            "a) Dynamic range",
            "b) Band range",
            "c) Peak range",
            "d) Resolution range"
        ],
        "Answer": "Answer: a\nExplanation: The valued spanned in gray scale image are depicted using dynamic range values."
    },
    {
        "id": 6,
        "Question": "Which is a colour attribute that describes a pure colour?",
        "Options": [
            "a) Saturation",
            "b) Hue",
            "c) Brightness",
            "d) Intensity"
        ],
        "Answer": "Answer: b\nExplanation: The color attribute of an image refers to the contrast of colors, which can be controlled using the Hue values."
    },
    {
        "id": 7,
        "Question": "Which gives a measure of the degree to which a pure colour is diluted by white light?",
        "Options": [
            "a) Saturation",
            "b) Hue",
            "c) Intensity",
            "d) Brightness"
        ],
        "Answer": "Answer: a\nExplanation: Saturation is color recognizing capability of the human eye. Hence a degree of dilution is measured using saturation."
    },
    {
        "id": 8,
        "Question": "Which means the assigning meaning to a recognized object.",
        "Options": [
            "a) Interpretation",
            "b) Recognition",
            "c) Acquisition",
            "d) Segmentation"
        ],
        "Answer": "Answer: a\nExplanation: The interpretation is called the assigning meaning to recognized object."
    },
    {
        "id": 9,
        "Question": "A typical size comparable in quality to monochromatic TV image is of size.",
        "Options": [
            "a) 256 X 256",
            "b) 512 X 512",
            "c) 1920 X 1080",
            "d) 1080 X 1080"
        ],
        "Answer": "Answer: b\nExplanation: A normal T.V have 512 x 512 resolution."
    },
    {
        "id": 10,
        "Question": "The number of grey values are integer powers of:",
        "Options": [
            "a) 4",
            "b) 2",
            "c) 8",
            "d) 1"
        ],
        "Answer": "Answer: b\nExplanation: The gray values are interpreted as the power of number of colors. In monochromatic image the number of colors are 2."
    },
    {
        "id": 11,
        "Question": "What is the first and foremost step in Image Processing?",
        "Options": [
            "a) Image restoration",
            "b) Image enhancement",
            "c) Image acquisition",
            "d) Segmentation"
        ],
        "Answer": "Answer: c\nExplanation: Image acquisition is the first process in image processing. Note that acquisition could be as simple as being given an image that is already in digital form. Generally, the image acquisition stage involves preprocessing, such as scaling."
    },
    {
        "id": 12,
        "Question": "In which step of processing, the images are subdivided successively into smaller regions?",
        "Options": [
            "a) Image enhancement",
            "b) Image acquisition",
            "c) Segmentation",
            "d) Wavelets"
        ],
        "Answer": "Answer: d\nExplanation: Wavelets are the foundation for representing images in various degrees of resolution. Wavelets are particularly used for image data compression and for pyramidal representation, in which images are subdivided successively into smaller regions."
    },
    {
        "id": 13,
        "Question": "What is the next step in image processing after compression?",
        "Options": [
            "a) Wavelets",
            "b) Segmentation",
            "c) Representation and description",
            "d) Morphological processing"
        ],
        "Answer": "Answer: d\nExplanation: Steps in image processing:\nImage acquisition-> Image enhancement-> Image restoration-> Color image processing-> Wavelets and multi resolution processing-> Compression-> Morphological processing-> Segmentation-> Representation & description-> Object recognition."
    },
    {
        "id": 14,
        "Question": "What is the step that is performed before color image processing in image processing?",
        "Options": [
            "a) Wavelets and multi resolution processing",
            "b) Image enhancement",
            "c) Image restoration",
            "d) Image acquisition"
        ],
        "Answer": "Answer: c\nExplanation: Steps in image processing:\nImage acquisition-> Image enhancement-> Image restoration-> Color image processing-> Wavelets and multi resolution processing-> Compression-> Morphological processing-> Segmentation-> Representation & description-> Object recognition."
    },
    {
        "id": 15,
        "Question": "How many number of steps are involved in image processing?",
        "Options": [
            "a) 10",
            "b) 9",
            "c) 11",
            "d) 12"
        ],
        "Answer": "Answer: a\nExplanation: Steps in image processing:\nImage acquisition-> Image enhancement-> Image restoration-> Color image processing-> Wavelets and multi resolution processing-> Compression-> Morphological processing-> Segmentation-> Representation & description-> Object recognition."
    },
    {
        "id": 16,
        "Question": "What is the expanded form of JPEG?",
        "Options": [
            "a) Joint Photographic Expansion Group",
            "b) Joint Photographic Experts Group",
            "c) Joint Photographs Expansion Group",
            "d) Joint Photographic Expanded Group"
        ],
        "Answer": "Answer: b\nExplanation: Image compression is familiar (perhaps inadvertently) to most users of computers in the form of image file extensions, such as the jpg file extension used in the JPEG (Joint Photographic Experts Group) image compression standard."
    },
    {
        "id": 17,
        "Question": "Which of the following step deals with tools for extracting image components those are useful in the representation and description of shape?",
        "Options": [
            "a) Segmentation",
            "b) Representation & description",
            "c) Compression",
            "d) Morphological processing"
        ],
        "Answer": "Answer: d\nExplanation: Morphological processing deals with tools for extracting image components that are useful in the representation and description of shape. The material in this chapter begins a transition from processes that output images to processes that output image attributes."
    },
    {
        "id": 18,
        "Question": "In which step of the processing, assigning a label (e.g., “vehicle”) to an object based on its descriptors is done?",
        "Options": [
            "a) Object recognition",
            "b) Morphological processing",
            "c) Segmentation",
            "d) Representation & description"
        ],
        "Answer": "Answer: a\nExplanation: Recognition is the process that assigns a label (e.g., “vehicle”) to an object based on its descriptors. We conclude our coverage of digital image processing with the development of methods for recognition of individual objects."
    },
    {
        "id": 19,
        "Question": "What role does the segmentation play in image processing?",
        "Options": [
            "a) Deals with extracting attributes that result in some quantitative information of interest",
            "b) Deals with techniques for reducing the storage required saving an image, or the bandwidth required transmitting it",
            "c) Deals with partitioning an image into its constituent parts or objects",
            "d) Deals with property in which images are subdivided successively into smaller regions"
        ],
        "Answer": "Answer: c\nExplanation: Segmentation procedures partition an image into its constituent parts or objects. In general, autonomous segmentation is one of the most difficult tasks in digital image processing. A rugged segmentation procedure brings the process a long way toward successful solution of imaging problems that require objects to be identified individually."
    },
    {
        "id": 20,
        "Question": "What is the correct sequence of steps in image processing?",
        "Options": [
            "a) Image acquisition->Image enhancement->Image restoration->Color image processing->Compression->Wavelets and multi resolution processing->Morphological processing->Segmentation->Representation & description->Object recognition",
            "b) Image acquisition->Image enhancement->Image restoration->Color image processing->Wavelets and multi resolution processing->Compression->Morphological processing->Segmentation->Representation & description->Object recognition",
            "c) Image acquisition->Image enhancement->Color image processing->Image restoration->Wavelets and multi resolution processing->Compression->Morphological processing->Segmentation->Representation & description->Object recognition",
            "d) Image acquisition->Image enhancement->Image restoration->Color image processing->Wavelets and multi resolution processing->Compression->Morphological processing->Representation & description->Segmentation->Object recognition"
        ],
        "Answer": "Answer: b\nExplanation: Steps in image processing:\nImage acquisition-> Image enhancement->Image restoration->Color image processing->Wavelets and multi resolution processing->Compression->Morphological processing->Segmentation->Representation & description->Object recognition."
    },
    {
        "id": 21,
        "Question": "To convert a continuous sensed data into Digital form, which of the following is required?",
        "Options": [
            "a)\tSampling",
            "b)\tQuantization",
            "c)\tBoth Sampling and Quantization",
            "d)\tNeither Sampling nor Quantization"
        ],
        "Answer": "Answer: c\nExplanation:\tThe output of the most sensor is a continuous waveform and the amplitude and spatial behavior of such waveform are related to the physical phenomenon being sensed."
    },
    {
        "id": 22,
        "Question": "To convert a continuous image f(x, y) to digital form, we have to sample the function in __________",
        "Options": [
            "a)\tCoordinates",
            "b)\tAmplitude`",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tAn image may be continuous in the x- and y-coordinates or in amplitude, or in both."
    },
    {
        "id": 23,
        "Question": "For a continuous image f(x, y), how could be Sampling defined?",
        "Options": [
            "a)\tDigitizing the coordinate values",
            "b)\tDigitizing the amplitude values",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tSampling is the method of digitizing the coordinate values of the image."
    },
    {
        "id": 24,
        "Question": "For a continuous image f(x, y), Quantization is defined as",
        "Options": [
            "a)\tDigitizing the coordinate values",
            "b)\tDigitizing the amplitude values",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tSampling is the method of digitizing the amplitude values of the image."
    },
    {
        "id": 25,
        "Options": [
            "5. Validate the statement:",
            "“For a given image in one-dimension given by function f(x, y), to sample the function we take equally spaced samples, superimposed on the function, along a horizontal line. However, the sample values still span (vertically) a continuous range of gray-level values. So, to convert the given function into a digital function, the gray-level values must be divided into various discrete levels.”",
            "a)\tTrue",
            "b)\tFalse"
        ],
        "Answer": "Answer: a\nExplanation:\tDigital function requires both sampling and quantization of the one-dimensional image function."
    },
    {
        "id": 26,
        "Question": "How is sampling been done when an image is generated by a single sensing element combined with mechanical motion?",
        "Options": [
            "a)\tThe number of sensors in the strip defines the sampling limitations in one direction and Mechanical motion in the other direction.",
            "b)\tThe number of sensors in the sensing array establishes the limits of sampling in both directions.",
            "c)\tThe number of mechanical increments when the sensor is activated to collect data.",
            "d)\tNone of the mentioned."
        ],
        "Answer": "Answer: c\nExplanation:\tWhen an image is generated by a single sensing element along with mechanical motion, the output data is quantized by dividing the gray-level scale into many discrete levels. However, sampling is done by selecting the number of individual mechanical increments recorded at which we activate the sensor to collect data."
    },
    {
        "id": 27,
        "Question": "How does sampling gets accomplished with a sensing strip being used for image acquisition?",
        "Options": [
            "a)\tThe number of sensors in the strip establishes the sampling limitations in one image direction and Mechanical motion in the other direction",
            "b)\tThe number of sensors in the sensing array establishes the limits of sampling in both directions",
            "c)\tThe number of mechanical increments when the sensor is activated to collect data",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tWhen a sensing strip is used the number of sensors in the strip defines the sampling limitations in one direction and mechanical motion in the other direction."
    },
    {
        "id": 28,
        "Question": "How is sampling accomplished when a sensing array is used for image acquisition?",
        "Options": [
            "a)\tThe number of sensors in the strip establishes the sampling limitations in one image direction and Mechanical motion in the other direction",
            "b)\tThe number of sensors in the sensing array defines the limits of sampling in both directions",
            "c)\tThe number of mechanical increments at which we activate the sensor to collect data",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tWhen we use sensing array for image acquisition, there is no motion and so, only the number of sensors in the array defines the limits of sampling in both directions and the output of the sensor is quantized by dividing the gray-level scale into many discrete levels."
    },
    {
        "id": 29,
        "Question": "The quality of a digital image is well determined by ___________",
        "Options": [
            "a)\tThe number of samples",
            "b)\tThe discrete gray levels",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tThe quality of a digital image is determined mostly by the number of samples and discrete gray levels used in sampling and quantization. "
    },
    {
        "id": 30,
        "Question": "Assume that an image f(x, y) is sampled so that the result has M rows and N columns. If the values of the coordinates at the origin are (x, y) = (0, 0), then the notation (0, 1) is used to signify :",
        "Options": [
            "a)\tSecond sample along first row",
            "b)\tFirst sample along second row",
            "c)\tFirst sample along first row",
            "d)\tSecond sample along second row"
        ],
        "Answer": "Answer: a\nExplanation:\tThe values of the coordinates at the origin are (x, y) = (0, 0). Then, the next coordinate values (second sample) along the first row of the image are represented as (x, y) = (0, 1)."
    },
    {
        "id": 31,
        "Question": "The resulting image of sampling and quantization is considered a matrix of real numbers. By what name(s) the element of this matrix array is called __________",
        "Options": [
            "a)\tImage element or Picture element",
            "b)\tPixel or Pel",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tSampling and Quantization of an image f(x, y) forms a matrix of real numbers and each element of this matrix array is commonly known as Image element or Picture element or Pixel or Pel."
    },
    {
        "id": 32,
        "Question": "Let Z be the set of real integers and R the set of real numbers. The sampling process may be viewed as partitioning the x-y plane into a grid, with the central coordinates of each grid being from the Cartesian product Z2, that is a set of all ordered pairs (zi, zj), with zi and zj being integers from Z. Then, f(x, y) is said a digital image if:",
        "Options": [
            "a)\t(x, y) are integers from Z2 and f is a function that assigns a gray-level value (from Z) to each distinct pair of coordinates (x, y)",
            "b)\t (x, y) are integers from R2 and f is a function that assigns a gray-level value (from R) to each distinct pair of coordinates (x, y)",
            "c)\t(x, y) are integers from R2 and f is a function that assigns a gray-level value (from Z) to each distinct pair of coordinates (x, y)",
            "d)\t(x, y) are integers from Z2 and f is a function that assigns a gray-level value (from R) to each distinct pair of coordinates (x, y)"
        ],
        "Answer": "Answer: d\nExplanation:\tIn the given condition, f(x, y) is a digital image if (x, y) are integers from Z2 and f a function that assigns a gray-level value (that is, a real number from the set R) to each distinct coordinate pair (x, y)."
    },
    {
        "id": 33,
        "Question": "Let Z be the set of real integers and R the set of real numbers. The sampling process may be viewed as partitioning the x-y plane into a grid, with the central coordinates of each grid being from the Cartesian product Z2, that is a set of all ordered pairs (zi, zj), with zi and zj being integers from Z. Then, f(x, y) is a digital image if (x, y) are integers from Z2 and f is a function that assigns a gray-level value (that is, a real number from the set R) to each distinct coordinate pair (x, y). What happens to the digital image if the gray levels also are integers?",
        "Options": [
            "a)\tThe Digital image then becomes a 2-D function whose coordinates and amplitude values are integers",
            "b)\tThe Digital image then becomes a 1-D function whose coordinates and amplitude values are integers",
            "c)\tThe gray level can never be integer",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tIn Quantization Process if the gray levels also are integers the Digital image then becomes a 2-D function whose coordinates and amplitude values are integers."
    },
    {
        "id": 34,
        "Question": "The digitization process i.e. the digital image has M rows and N columns, requires decisions about values for M, N, and for the number, L, of gray levels allowed for each pixel. The value M and N have to be:",
        "Options": [
            "a)\tM and N have to be positive integer",
            "b)\tM and N have to be negative integer",
            "c)\tM have to be negative and N have to be positive integer",
            "d)\tM have to be positive and N have to be negative integer"
        ],
        "Answer": "Answer: a\nExplanation:\tThe digitization process i.e. the digital image has M rows and N columns, requires decisions about values for M, N, and for the number, L, of max gray level. There are no requirements on M and N, other than that M and N have to be positive integer."
    },
    {
        "id": 35,
        "Question": "The digitization process i.e. the digital image has M rows and N columns, requires decisions about values for M, N, and for the number, L, of max gray levels. There are no requirements on M and N, other than that M and N have to be positive integer. However, the number of gray levels typically is",
        "Options": [
            "a)\tAn integer power of 2 i.e. L = 2k",
            "b)\tA Real power of 2 i.e. L = 2k",
            "c)\tTwo times the integer value i.e. L = 2k",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tDue to processing, storage, and considering the sampling hardware, the number of gray levels typically is an integer power of 2 i.e. L = 2k."
    },
    {
        "id": 36,
        "Question": "The digitization process i.e. the digital image has M rows and N columns, requires decisions about values for M, N, and for the number, L, of max gray levels is an integer power of 2 i.e. L = 2k, allowed for each pixel. If we assume that the discrete levels are equally spaced and that they are integers then they are in the interval __________ and Sometimes the range of values spanned by the gray scale is called the ________ of an image.",
        "Options": [
            "a)\t[0, L – 1] and static range respectively",
            "b)\t[0, L / 2] and dynamic range respectively",
            "c)\t[0, L / 2] and static range respectively",
            "d)\t[0, L – 1] and dynamic range respectively"
        ],
        "Answer": "Answer: d\nExplanation:\tIn digitization process M rows and N columns have to be positive and for the number, L, of discrete gray levels typically an integer power of 2 for each pixel. If we assume that the discrete levels are equally spaced and that they are integers then they lie in the interval [0, L-1] and Sometimes the range of values spanned by the gray scale is called the dynamic range of an image."
    },
    {
        "id": 37,
        "Question": "After digitization process a digital image with M rows and N columns have to be positive and for the number, L, max gray levels i.e. an integer power of 2 for each pixel. Then, the number b, of bits required to store a digitized image is:",
        "Options": [
            "a)\tb=M*N*k",
            "b)\tb=M*N*L",
            "c)\tb=M*L*k",
            "d)\tb=L*N*k"
        ],
        "Answer": "Answer: a\nExplanation:\tIn digital image of M rows and N columns and L max gray levels an integer power of 2 for each pixel. The number, b, of bits required to store a digitized image is: b=M*N*k."
    },
    {
        "id": 38,
        "Question": "An image whose gray-levels span a significant portion of gray scale have __________ dynamic range while an image with dull, washed out gray look have __________ dynamic range.",
        "Options": [
            "a)\tLow and High respectively",
            "b)\tHigh and Low respectively",
            "c)\tBoth have High dynamic range, irrespective of gray levels span significance on gray scale",
            "d)\tBoth have Low dynamic range, irrespective of gray levels span significance on gray scale"
        ],
        "Answer": "Answer: b\nExplanation:\tAn image whose gray-levels signifies a large portion of gray scale have High dynamic range, while that with dull, washed out gray look have Low dynamic range."
    },
    {
        "id": 39,
        "Question": "In digital image of M rows and N columns and L discrete gray levels, calculate the bits required to store a digitized image for M=N=32 and L=16.",
        "Options": [
            "a)\t16384",
            "b)\t4096",
            "c)\t8192",
            "d)\t512"
        ],
        "Answer": "Answer: a\nExplanation:\tIn an Image if an appreciable number of pixels exhibit high dynamic range property, the image will have high contrast."
    },
    {
        "id": 40,
        "Question": "A continuous image is digitised at _______ points.",
        "Options": [
            "a) random",
            "b) vertex",
            "c) contour",
            "d) sampling"
        ],
        "Answer": "Answer: d\nExplanation: The sampling points are ordered in the plane and their relation is called a Grid."
    },
    {
        "id": 41,
        "Question": " The transition between continuous values of the image function and its digital equivalent is called ______________",
        "Options": [
            "a) Quantisation",
            "b) Sampling",
            "c) Rasterisation",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: a\nExplanation: The transition between continuous values of the image function and its digital equivalent is called Quantisation."
    },
    {
        "id": 42,
        "Question": "Images quantised with insufficient brightness levels will lead to the occurrence of ____________",
        "Options": [
            "a) Pixillation",
            "b) Blurring",
            "c) False Contours",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: c\nExplanation:  This effect arises when the number brightness levels is lower that which the human eye can distinguish."
    },
    {
        "id": 43,
        "Question": "The smallest discernible change in intensity level is called ____________",
        "Options": [
            "a) Intensity Resolution",
            "b) Contour",
            "c) Saturation",
            "d) Contrast"
        ],
        "Answer": "Answer: a\nExplanation: Number of bits used to quantise intensity of an image is called intensity resolution."
    },
    {
        "id": 44,
        "Question": "What is the tool used in tasks such as zooming, shrinking, rotating, etc.?",
        "Options": [
            "a) Sampling",
            "b) Interpolation",
            "c) Filters",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: b\nExplanation: Interpolation is the basic tool used for zooming, shrinking, rotating, etc."
    },
    {
        "id": 45,
        "Question": "The type of Interpolation where for each new location the intensity of the immediate pixel is assigned is ___________",
        "Options": [
            "a) bicubic interpolation",
            "b) cubic interpolation",
            "c) bilinear interpolation",
            "d) nearest neighbour interpolation"
        ],
        "Answer": "Answer: d\nExplanation: Its called as Nearest Neighbour Interpolation since for each new location the intensity of the next neighbouring pixel is assigned."
    },
    {
        "id": 46,
        "Question": "The type of Interpolation where the intensity of the FOUR neighbouring pixels is used to obtain intensity a new location is called ___________",
        "Options": [
            "a) cubic interpolation",
            "b) nearest neighbour interpolation",
            "c) bilinear interpolation",
            "d) bicubic interpolation"
        ],
        "Answer": "Answer: b\nExplanation: Bilinear interpolation is where the FOUR neighbouring pixels is used to estimate intensity for a new location."
    },
    {
        "id": 47,
        "Question": "Dynamic range of imaging system is a ratio where the upper limit is determined by",
        "Options": [
            "a) Saturation",
            "b) Noise",
            "c) Brightness",
            "d) Contrast"
        ],
        "Answer": "Answer: a\nExplanation: Saturation is taken as the Numerator."
    },
    {
        "id": 48,
        "Question": "For Dynamic range ratio the lower limit is determined by",
        "Options": [
            "a) Saturation",
            "b) Brightness",
            "c) Noise",
            "d) Contrast"
        ],
        "Answer": "Answer: c\nExplanation: Noise is taken as the Denominator."
    },
    {
        "id": 49,
        "Question": "Quantitatively, spatial resolution cannot be represented in which of the following ways",
        "Options": [
            "a) line pairs",
            "b) pixels",
            "c) dots",
            "d) none of the Mentioned"
        ],
        "Answer": "Answer: d\nExplanation: All the options can be used to represent spatial resolution."
    },
    {
        "id": 50,
        "Question": "The most familiar single sensor used for Image Acquisition is",
        "Options": [
            "a) Microdensitometer",
            "b) Photodiode",
            "c) CMOS",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: b\nExplanation: Photodiode is the most commonly used single sensor made up of silicon materials."
    },
    {
        "id": 51,
        "Question": " A geometry consisting of in-line arrangement of sensors for image acquisition",
        "Options": [
            "a) A photodiode",
            "b) Sensor strips",
            "c) Sensor arrays",
            "d) CMOS"
        ],
        "Answer": "Answer: b\nExplanation: Sensor strips are very common next to single sensor and use in-line arrangement."
    },
    {
        "id": 52,
        "Question": "CAT in imaging stands for",
        "Options": [
            "a) Computer Aided Telegraphy",
            "b) Computer Aided Tomography",
            "c) Computerised Axial Telegraphy",
            "d) Computerised Axial Tomography"
        ],
        "Answer": "Answer: d\nExplanation: Industrial Computerised Axial Tomography is based on image acquisition using sensor strips."
    },
    {
        "id": 53,
        "Question": "The section of the real plane spanned by the coordinates of an image is called the _____________",
        "Options": [
            "a) Spacial Domain",
            "b) Coordinate Axes",
            "c) Plane of Symmetry",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: a\nExplanation:  The section of the real plane spanned by the coordinates of an image is called the Spacial Domain, with the x and y coordinates referred to as Spacial coordinates."
    },
    {
        "id": 54,
        "Question": "The difference is intensity between the highest and the lowest intensity levels in an image is ___________",
        "Options": [
            "a) Noise",
            "b) Saturation",
            "c) Contrast",
            "d) Brightness"
        ],
        "Answer": "Answer: c\nExplanation: Contrast is the measure of the difference is intensity between the highest and the lowest intensity levels in an image."
    },
    {
        "id": 55,
        "Question": "_____________ is the effect caused by the use of an insufficient number of intensity levels in smooth areas of a digital image.",
        "Options": [
            "a) Gaussian smooth",
            "b) Contouring",
            "c) False Contouring",
            "d) Interpolation"
        ],
        "Answer": "Answer: c\nExplanation: It is called so because the ridges resemble the contours of a map."
    },
    {
        "id": 56,
        "Question": "The process of using known data to estimate values at unknown locations is called",
        "Options": [
            "a) Acquisition",
            "b) Interpolation",
            "c) Pixelation",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: b\nExplanation: Interpolation is the process used to estimate unknown locations. It is applied in all image resampling methods."
    },
    {
        "id": 57,
        "Question": "Which of the following is NOT an application of Image Multiplication?",
        "Options": [
            "a) Shading Correction",
            "b) Masking",
            "c) Pixelation",
            "d) Region of Interest operations"
        ],
        "Answer": "Answer: c\nExplanation: Because Pixelation deals with enlargement of pixels."
    },
    {
        "id": 58,
        "Question": "The procedure done on a digital image to alter the values of its individual pixels is",
        "Options": [
            "a) Neighbourhood Operations",
            "b) Image Registration",
            "c) Geometric Spacial Transformation",
            "d) Single Pixel Operation"
        ],
        "Answer": "Answer: d\nExplanation: It is expressed as a transformation function T, of the form s=T(z) , where z is the intensity."
    },
    {
        "id": 59,
        "Question": "In Geometric Spacial Transformation, points whose locations are known precisely in input and reference images.",
        "Options": [
            "a) Tie points",
            "b) Réseau points",
            "c) Known points",
            "d) Key-points"
        ],
        "Answer": "Answer: a\nExplanation: Tie points, also called Control points are points whose locations are known precisely in input and reference images."
    },
    {
        "id": 60,
        "Question": "Of the following, _________ has the maximum frequency.",
        "Options": [
            "a) UV Rays",
            "b) Gamma Rays",
            "c) Microwaves",
            "d) Radio Waves"
        ],
        "Answer": "Answer: b\nExplanation: Gamma Rays come first in the electromagnetic spectrum sorted in the decreasing order of frequency."
    },
    {
        "id": 61,
        "Question": "In the Visible spectrum the ______ colour has the maximum wavelength.",
        "Options": [
            "a) Violet",
            "b) Blue",
            "c) Red",
            "d) Yellow"
        ],
        "Answer": "Answer: c\nExplanation: Red is towards the right in the electromagnetic spectrum sorted in the increasing order of wavelength."
    },
    {
        "id": 62,
        "Question": "Wavelength and frequency are related as : (c = speed of light)",
        "Options": [
            "a) c = wavelength / frequency",
            "b) frequency = wavelength / c",
            "c) wavelength = c * frequency",
            "d) c = wavelength * frequency"
        ],
        "Answer": "Answer: d\nExplanation: It is usually written as wavelength = c / frequency."
    },
    {
        "id": 63,
        "Question": "Electromagnetic waves can be visualised as a",
        "Options": [
            "a) sine wave",
            "b) cosine wave",
            "c) tangential wave",
            "d) None of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation: Electromagnetic waves are visualised as sinusoidal wave."
    },
    {
        "id": 64,
        "Question": "How is radiance measured?",
        "Options": [
            "a) lumens",
            "b) watts",
            "c) armstrong",
            "d) hertz"
        ],
        "Answer": "Answer: b\nExplanation: Radiance is the total amount of energy that flows from the light source and is measured in Watts."
    },
    {
        "id": 65,
        "Question": "Which of the following is used for chest and dental scans?",
        "Options": [
            "a) Hard X-Rays",
            "b) Soft X-Rays",
            "c) Radio waves",
            "d) Infrared Rays"
        ],
        "Answer": "Answer: b\nExplanation: Soft X-Rays (low energy) are used for dental and chest scans."
    },
    {
        "id": 66,
        "Question": "Which of the following is impractical to measure?",
        "Options": [
            "a) Frequency",
            "b) Radiance",
            "c) Luminance",
            "d) Brightness"
        ],
        "Answer": "Answer: d\nExplanation: Brightness is subjective descriptor of light perception that is impossible to measure."
    },
    {
        "id": 67,
        "Question": "Massless particle containing a certain amount of energy is called",
        "Options": [
            "a) Photon",
            "b) Shell",
            "c) Electron",
            "d) None of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation: Each bundle of massless energy is called a Photon."
    },
    {
        "id": 68,
        "Question": "What do you mean by achromatic light?",
        "Options": [
            "a) Chromatic light",
            "b) Monochromatic light",
            "c) Infrared light",
            "d) Invisible light"
        ],
        "Answer": "Answer: b\nExplanation: Achromatic light is also called monochromatic light.(Light void of color)"
    },
    {
        "id": 69,
        "Question": "Which of the following embodies the achromatic notion of intensity?",
        "Options": [
            "a) Luminance",
            "b) Brightness",
            "c) Frequency",
            "d) Radiance"
        ],
        "Answer": "Answer: b\nExplanation: Brightness embodies the achromatic notion of intensity and is a key factor in describing color sensation."
    },
    {
        "id": 70,
        "Question": "How is array operation carried out involving one or more images?",
        "Options": [
            "a) array by array",
            "b) pixel by pixel",
            "c) column by column",
            "d) row by row"
        ],
        "Answer": "Answer: b\nExplanation: Any array operation is carried out on a pixel by pixel basis."
    },
    {
        "id": 71,
        "Question": "The property indicating that the output of a linear operation due to the sum of two inputs is same as performing the operation on the inputs individually and then summing the results is called ___________",
        "Options": [
            "a) additivity",
            "b) heterogeneity",
            "c) homogeneity",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: a\nExplanation: This property is called additivity ."
    },
    {
        "id": 72,
        "Question": "The property indicating that the output of a linear operation to a constant times as input is the same as the output of operation due to original input multiplied by that constant is called _________",
        "Options": [
            "a) additivity",
            "b) heterogeneity",
            "c) homogeneity",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: c\nExplanation: This property is called homogeneity ."
    },
    {
        "id": 73,
        "Question": "Enhancement of differences between images is based on the principle of ____________",
        "Options": [
            "a) Additivity",
            "b) Homogeneity",
            "c) Subtraction",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: c\nExplanation: A frequent application of image subtraction is in the enhancement of differences between images ."
    },
    {
        "id": 74,
        "Question": "A commercial use of Image Subtraction is ___________",
        "Options": [
            "a) Mask mode radiography",
            "b) MRI scan",
            "c) CT scan",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: a\nExplanation: Mask mode radiography is an important medical imaging area based on Image Subtraction."
    },
    {
        "id": 75,
        "Question": "Region of Interest (ROI) operations is commonly called as ___________",
        "Options": [
            "a) Shading correction",
            "b) Masking",
            "c) Dilation",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: b\nExplanation: A common use of image multiplication is Masking, also called ROI operation."
    },
    {
        "id": 76,
        "Question": "If every element of a set A is also an element of a set B, then A is said to be a _________ of set B.",
        "Options": [
            "a) Disjoint set",
            "b) Union",
            "c) Subset",
            "d) Complement set"
        ],
        "Answer": "Answer: c\nExplanation: A is called the subset of B."
    },
    {
        "id": 77,
        "Question": "Consider two regions A and B composed of foreground pixels. The ________ of these two sets is the set of elements belonging to set A or set B or both.",
        "Options": [
            "a) OR",
            "b) AND",
            "c) NOT",
            "d) XOR"
        ],
        "Answer": "Answer: a\nExplanation: This is called an OR operation."
    },
    {
        "id": 78,
        "Question": "Imaging systems having physical artefacts embedded in the imaging sensors produce a set of points called __________",
        "Options": [
            "a) Tie Points",
            "b) Control Points",
            "c) Reseau Marks",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: c\nExplanation: These points are called “known” points or “Reseau marks”."
    },
    {
        "id": 79,
        "Question": "Image processing approaches operating directly on pixels of input image work directly in ____________",
        "Options": [
            "a) Transform domain",
            "b) Spatial domain",
            "c) Inverse transformation",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: b\nExplanation: Operations directly on pixels of input image work directly in Spatial Domain."
    },
    {
        "id": 80,
        "Question": "What is the output of a smoothing, linear spatial filter?",
        "Options": [
            "a) Median of pixels",
            "b) Maximum of pixels",
            "c) Minimum of pixels",
            "d) Average of pixels"
        ],
        "Answer": "Answer: a\nExplanation: Noise reduction is obtained by blurring the image using smoothing filter. Blurring is used in pre-processing steps, such as removal of small details from an image prior to object extraction and, bridging of small gaps in lines or curves."
    },
    {
        "id": 81,
        "Question": "Which of the following in an image can be removed by using smoothing filter?",
        "Options": [
            "a) Smooth transitions of gray levels",
            "b) Smooth transitions of brightness levels",
            "c) Sharp transitions of gray levels",
            "d) Sharp transitions of brightness levels"
        ],
        "Answer": "Answer: d\nExplanation: The output or response of a smoothing, linear spatial filter is simply the average of the pixels contained in the neighbourhood of the filter mask."
    },
    {
        "id": 82,
        "Question": "Which of the following is the disadvantage of using smoothing filter?",
        "Options": [
            "a) Blur edges",
            "b) Blur inner pixels",
            "c) Remove sharp transitions",
            "d) Sharp edges"
        ],
        "Answer": "Answer: b\nExplanation: Since the smoothing spatial filter performs the average of the pixels, it is also called as averaging filter."
    },
    {
        "id": 83,
        "Question": "Which of the following comes under the application of image blurring?",
        "Options": [
            "a) Object detection",
            "b) Gross representation",
            "c) Object motion",
            "d) Image segmentation"
        ],
        "Answer": "Answer: c\nExplanation: Smoothing filter replaces the value of every pixel in an image by the average value of the gray levels. So, this helps in removing the sharp transitions in the gray levels between the pixels. This is done because, random noise typically consists of sharp transitions in gray levels."
    },
    {
        "id": 84,
        "Question": "Which of the following filters response is based on ranking of pixels?",
        "Options": [
            "a) Nonlinear smoothing filters",
            "b) Linear smoothing filters",
            "c) Sharpening filters",
            "d) Geometric mean filter"
        ],
        "Answer": "Answer: a\nExplanation: Edges, which almost always are desirable features of an image, also are characterized by sharp transitions in gray level. So, averaging filters have an undesirable side effect that they blur these edges."
    },
    {
        "id": 85,
        "Question": "Median filter belongs to which category of filters?",
        "Options": [
            "a) Linear spatial filter",
            "b) Frequency domain filter",
            "c) Order static filter",
            "d) Sharpening filter"
        ],
        "Answer": "Answer: b\nExplanation: One of the application of smoothing spatial filters is that, they help in smoothing the false contours that result from using an insufficient number of gray levels."
    },
    {
        "id": 86,
        "Question": "What is the maximum area of the cluster that can be eliminated by using an n×n median filter?",
        "Options": [
            "a) n2",
            "b) n2/2",
            "c) 2*n2",
            "d) n"
        ],
        "Answer": "Answer: d\nExplanation: This is a smoothing spatial filter. This mask yields a so called weighted average, which means that different pixels are multiplied with different coefficient values. This helps in giving much importance to the some pixels at the expense of others."
    },
    {
        "id": 87,
        "Question": "Which of the following expression is used to denote spatial domain process?",
        "Options": [
            "a) g(x,y)=T[f(x,y)]",
            "b) f(x+y)=T[g(x+y)]",
            "c) g(xy)=T[f(xy)]",
            "d) g(x-y)=T[f(x-y)]"
        ],
        "Answer": "Answer: a\nExplanation: Spatial domain processes will be denoted by the expression g(x,y)=T[f(x,y)], where f(x,y) is the input image, g(x,y) is the processed image, and T is an operator on f, defined over some neighborhood of (x, y). In addition, T can operate on a set of input images, such as performing the pixel-by-pixel sum of K images for noise reduction."
    },
    {
        "id": 88,
        "Question": "Which of the following shows three basic types of functions used frequently for image enhancement?",
        "Options": [
            "a) Linear, logarithmic and inverse law",
            "b) Power law, logarithmic and inverse law",
            "c) Linear, logarithmic and power law",
            "d) Linear, exponential and inverse law"
        ],
        "Answer": "Answer: b\nExplanation: In introduction to gray-level transformations, which shows three basic types of functions used frequently for image enhancement: linear (negative and identity transformations), logarithmic (log and inverse-log transformations), and power-law (nth power and nth root transformations).The identity function is the trivial case in which output intensities are identical to input intensities. It is included in the graph only for completeness."
    },
    {
        "id": 89,
        "Question": "Which expression is obtained by performing the negative transformation on the negative of an image with gray levels in the range[0,L-1] ?",
        "Options": [
            "a) s=L+1-r",
            "b) s=L+1+r",
            "c) s=L-1-r",
            "d) s=L-1+r"
        ],
        "Answer": "Answer: c\nExplanation: The negative of an image with gray levels in the range[0,L-1] is obtained by using the negative transformation, which is given by the expression:  s=L-1-r."
    },
    {
        "id": 90,
        "Question": "What is the general form of representation of log transformation?",
        "Options": [
            "a) s=clog10(1/r)",
            "b) s=clog10(1+r)",
            "c) s=clog10(1*r)",
            "d) s=clog10(1-r)"
        ],
        "Answer": "Answer: b\nExplanation: The general form of the log transformation: s=clog10(1+r), where c is a constant, and it is assumed that r ≥ 0."
    },
    {
        "id": 91,
        "Question": "What is the general form of representation of power transformation?",
        "Options": [
            "a) s=crγ",
            "b) c=srγ",
            "c) s=rc",
            "d) s=rcγ"
        ],
        "Answer": "Answer: a\nExplanation: Power-law transformations have the basic form: s=crγ where c and g are positive constants. Sometimes s=crγ is written as s=c.(r+ε)γ to account for an offset (that is, a measurable output when the input is zero)."
    },
    {
        "id": 92,
        "Question": "What is the name of process used to correct the power-law response phenomena?",
        "Options": [
            "a) Beta correction",
            "b) Alpha correction",
            "c) Gamma correction",
            "d) Pie correction"
        ],
        "Answer": "Answer: c\nExplanation: A variety of devices used for image capture, printing, and display respond according to a power law. By convention, the exponent in the power-law equation is referred to as gamma .The process used to correct these power-law response phenomena is called gamma correction."
    },
    {
        "id": 93,
        "Question": "Which of the following transformation function requires much information to be specified at the time of input?",
        "Options": [
            "a) Log transformation",
            "b) Power transformation",
            "c) Piece-wise transformation",
            "d) Linear transformation"
        ],
        "Answer": "Answer: c\nExplanation: The practical implementation of some important transformations can be formulated only as piecewise functions. The principal disadvantage of piecewise functions is that their specification requires considerably more user input."
    },
    {
        "id": 94,
        "Question": "In contrast stretching, if r1=s1 and r2=s2 then which of the following is true?",
        "Options": [
            "a) The transformation is not a linear function that produces no changes in gray levels",
            "b) The transformation is a linear function that produces no changes in gray levels",
            "c) The transformation is a linear function that produces changes in gray levels",
            "d) The transformation is not a linear function that produces changes in gray levels"
        ],
        "Answer": "Answer: b\nExplanation: The locations of points (r1,s1) and (r2,s2) control the shape of the transformation function. If r1=s1 and r2=s2 then the transformation is a linear function that produces no changes in gray levels."
    },
    {
        "id": 95,
        "Question": "In contrast stretching, if r1=r2, s1=0 and s2=L-1 then which of the following is true?",
        "Options": [
            "a) The transformation becomes a thresholding function that creates an octal image",
            "b) The transformation becomes a override function that creates an octal image",
            "c) The transformation becomes a thresholding function that creates a binary image",
            "d) The transformation becomes a thresholding function that do not create an octal image"
        ],
        "Answer": "Answer: c\nExplanation: If r1=r2, s1=0 and s2=L-1,the transformation becomes a thresholding function that creates a binary image."
    },
    {
        "id": 96,
        "Question": "In contrast stretching, if r1≤r2  and s1≤s2 then which of the following is true?",
        "Options": [
            "a) The transformation function is double valued and exponentially increasing",
            "b) The transformation function is double valued and monotonically increasing",
            "c) The transformation function is single valued and exponentially increasing",
            "d) The transformation function is single valued and monotonically increasing"
        ],
        "Answer": "Answer: d\nExplanation: The locations of points (r1,s1) and (r2,s2) control the shape of the transformation function. If r1≤r2  and s1≤s2 then the function is single valued and monotonically increasing."
    },
    {
        "id": 97,
        "Question": "In which type of slicing, highlighting a specific range of gray levels in an image often is desired?",
        "Options": [
            "a) Gray-level slicing",
            "b) Bit-plane slicing",
            "c) Contrast stretching",
            "d) Byte-level slicing"
        ],
        "Answer": "Answer: a\nExplanation: Highlighting a specific range of gray levels in an image often is desired in gray-level slicing. Applications include enhancing features such as masses of water in satellite imagery and enhancing flaws in X-ray images."
    },
    {
        "id": 98,
        "Question": "Which of the following depicts the main functionality of the Bit-plane slicing?",
        "Options": [
            "a) Highlighting a specific range of gray levels in an image",
            "b) Highlighting the contribution made to total image appearance by specific bits",
            "c) Highlighting the contribution made to total image appearance by specific byte",
            "d) Highlighting the contribution made to total image appearance by specific pixels"
        ],
        "Answer": "Answer: b\nExplanation: Instead of highlighting gray-level ranges, highlighting the contribution made to total image appearance by specific bits might be desired. Suppose , each pixel in an image is represented by 8 bits. Imagine that the image is composed of eight 1-bit planes, ranging from bit-plane 0 for the least significant bit to bit-plane 7 for the most significant bit. In terms of 8-bit bytes, plane 0 contains all the lowest order bits in the bytes comprising the pixels in the image and plane 7 contains all the high-order bits."
    },
    {
        "id": 99,
        "Question": "Which of the following is the primary objective of sharpening of an image?",
        "Options": [
            "a) Blurring the image",
            "b) Highlight fine details in the image",
            "c) Increase the brightness of the image",
            "d) Decrease the brightness of the image"
        ],
        "Answer": "Answer: b\nExplanation: The sharpening of image helps in highlighting the fine details that are present in the image or to enhance the details that are blurred due to some reason like adding noise."
    },
    {
        "id": 100,
        "Question": "In spatial domain, which of the following operation is done on the pixels in sharpening the image?",
        "Options": [
            "a) Integration",
            "b) Average",
            "c) Median",
            "d) Differentiation"
        ],
        "Answer": "Answer: a\nExplanation: The applications of image sharpening is present in various fields like electronic printing, autonomous guidance in military systems, medical imaging and industrial inspection."
    },
    {
        "id": 101,
        "Question": "In which of the following cases, we wouldn’t worry about the behaviour of sharpening filter?",
        "Options": [
            "a) Flat segments",
            "b) Step discontinuities",
            "c) Ramp discontinuities",
            "d) Slow varying gray values"
        ],
        "Answer": "Answer: d\nExplanation: We know that, in blurring the image, we perform the average of pixels which can be considered as integration. As sharpening is the opposite process of blurring, logically we can tell that we perform differentiation on the pixels to sharpen the image."
    },
    {
        "id": 102,
        "Question": "Which of the following is the valid response when we apply a first derivative?",
        "Options": [
            "a) Non-zero at flat segments",
            "b) Zero at the onset of gray level step",
            "c) Zero in flat segments",
            "d) Zero along ramps"
        ],
        "Answer": "Answer: a\nExplanation: Fundamentally, the strength of the response of the derivative operative is proportional to the degree of discontinuity in the image. So, we can state that image differentiation enhances the edges, discontinuities and deemphasizes the pixels with slow varying gray levels."
    },
    {
        "id": 103,
        "Question": "Which of the following is not a valid response when we apply a second derivative?",
        "Options": [
            "a) Zero response at onset of gray level step",
            "b) Nonzero response at onset of gray level step",
            "c) Zero response at flat segments",
            "d) Nonzero response along the ramps"
        ],
        "Answer": "Answer: d\nExplanation: We are interested in the behaviour of derivatives used in sharpening in the constant gray level areas i.e., flat segments, and at the onset and end of discontinuities, i.e., step and ramp discontinuities."
    },
    {
        "id": 104,
        "Question": "If f(x,y) is an image function of two variables, then the first order derivative of a one dimensional function, f(x) is:",
        "Options": [
            "a) f(x+1)-f(x)",
            "b) f(x)-f(x+1)",
            "c) f(x-1)-f(x+1)",
            "d) f(x)+f(x-1)"
        ],
        "Answer": "Answer: c\nExplanation: The derivations of digital functions are defined in terms of differences. The definition we use for first derivative should be zero in flat segments, nonzero at the onset of a gray level step or ramp and nonzero along the ramps."
    },
    {
        "id": 105,
        "Question": "What is the thickness of the edges produced by first order derivatives when compared to that of second order derivatives?",
        "Options": [
            "a) Finer",
            "b) Equal",
            "c) Thicker",
            "d) Independent"
        ],
        "Answer": "Answer: b\nExplanation: The derivations of digital functions are defined in terms of differences. The definition we use for second derivative should be zero in flat segments, zero at the onset of a gray level step or ramp and nonzero along the ramps."
    },
    {
        "id": 106,
        "Question": "Which of the following derivatives produce a double response at step changes in gray level?",
        "Options": [
            "a) First order derivative",
            "b) Third order derivative",
            "c) Second order derivative",
            "d) First and second order derivatives"
        ],
        "Answer": "Answer: a\nExplanation: The first order derivative of a single dimensional function f(x) is the difference between f(x) and f(x+1).\nThat is, ∂f/∂x=f(x+1)-f(x)."
    },
    {
        "id": 107,
        "Question": "1.\tThe objective of sharpening spatial filters is/are to ___________",
        "Options": [
            "a)\tHighlight fine detail in an image",
            "b)\tEnhance detail that has been blurred because of some error",
            "c)\tEnhance detail that has been blurred because of some natural effect of some method of image acquisition",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation:\tHighlighting the fine detail in an image or Enhancing detail that has been blurred because of some error or some natural effect of some method of image acquisition, is the principal objective of sharpening spatial filters."
    },
    {
        "id": 108,
        "Question": "2.\tSharpening is analogous to which of the following operations?",
        "Options": [
            "a)\tTo spatial integration",
            "b)  To spatial differentiation",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tSmoothing is analogous to integration and so, sharpening to spatial differentiation."
    },
    {
        "id": 109,
        "Question": "3.\tWhich of the following fact(s) is/are true about sharpening spatial filters using digital differentiation?",
        "Options": [
            "a)\tSharpening spatial filter response is proportional to the discontinuity of the image at the point where the derivative operation is applied",
            "b)\tSharpening spatial filters enhances edges and discontinuities like noise",
            "c)\tSharpening spatial filters deemphasizes areas that have slowly varying gray-level values",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation:\tDerivative operator’s response is proportional to the discontinuity of the image at the point where the derivative operation is applied.\nImage differentiation enhances edges and discontinuities like noise and deemphasizes areas that have slowly varying gray-level values.\nSince a sharpening spatial filters are analogous to differentiation, so, all the above mentioned facts are true for sharpening spatial filters."
    },
    {
        "id": 110,
        "Question": "4.\tWhich of the facts(s) is/are true for the first order derivative of a digital function?",
        "Options": [
            "a)\tMust be nonzero in the areas of constant grey values",
            "b)\tMust be zero at the onset of a gray-level step or ramp discontinuities",
            "c)\tMust be nonzero along the gray-level ramps",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tThe first order derivative of a digital function is defined as:\n\tMust be zero in the areas of constant grey values.\n\tMust be nonzero at the onset of a gray-level step or ramp discontinuities.\n\tMust be nonzero along the gray-level ramps."
    },
    {
        "id": 111,
        "Question": "5.\tWhich of the facts(s) is/are true for the second order derivative of a digital function?",
        "Options": [
            "a)\tMust be zero in the flat areas",
            "b)\tMust be nonzero at the onset and end of a gray-level step or ramp discontinuities",
            "c)\tMust be zero along the ramps of constant slope",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tThe second order derivative of a digital function is defined as:\n\tMust be zero in the flat areas i.e. areas of constant grey values.\n\tMust be nonzero at the onset of a gray-level step or ramp discontinuities.\n\tMust be zero along the gray-level ramps of constant slope."
    },
    {
        "id": 112,
        "Question": "6.\tThe derivative of digital function is defined in terms of difference. Then, which of the following defines the first order derivative ∂f/∂x= ___________ of a one-dimensional function f(x)?",
        "Options": [
            "a)\tf(x+1)-f(x)",
            "b)\tf(x+1)+ f(x-1)-2f(x)",
            "c)\tAll of the mentioned depending upon the time when partial derivative will be dealt along two spatial axes",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tThe definition of a first order derivative of a one dimensional image f(x) is:\n∂f/∂x= f(x+1)-f(x), where the partial derivative is used to keep notation same even for f(x, y) when partial derivative will be dealt along two spatial axes.\n"
    },
    {
        "id": 113,
        "Question": "7.\tThe derivative of digital function is defined in terms of difference. Then, which of the following defines the second order derivative ∂2 f/∂x2 = ___________ of a one-dimensional function f(x)?",
        "Options": [
            "a)\tf(x+1)-f(x)",
            "b)\tf(x+1)+ f(x-1)-2f(x)",
            "c)\tAll of the mentioned depending upon the time when partial derivative will be dealt along two spatial axes",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tThe definition of a second order derivative of a one dimensional image f(x) is:\n (∂2 f)/∂x2 =f(x+1)+ f(x-1)-2f(x), where the partial derivative is used to keep notation same even for f(x, y) when partial derivative will be dealt along two spatial axes."
    },
    {
        "id": 114,
        "Question": "8.\tWhat kind of relation can be obtained between first order derivative and second order derivative of an image having a on the basis of edge productions that shows a transition like a ramp of constant slope?",
        "Options": [
            "a)\tFirst order derivative produces thick edge while second order produces a very fine edge",
            "b)\tSecond order derivative produces thick edge while first order produces a very fine edge",
            "c)\tBoth first and second order produces thick edge",
            "d)\tBoth first and second order produces a very fine edge"
        ],
        "Answer": "Answer: a\nExplanation:\tthe first order derivative remains nonzero along the entire ramp of constant slope, while the second order derivative remain nonzero only at onset and end of such ramps.\nIf an edge in an image shows transition like the ramp of constant slope, the first order and second order derivative values shows the production of thick and finer edge respectively."
    },
    {
        "id": 115,
        "Question": "9.\tWhat kind of relation can be obtained between first order derivative and second order derivative of an image on the response obtained by encountering an isolated noise point in the image?",
        "Options": [
            "a)\tFirst order derivative has a stronger response than a second order",
            "b)\tSecond order derivative has a stronger response than a first order",
            "c)\tBoth enhances the same and so the response is same for both first and second order derivative",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tThis is because a second order derivative is more aggressive toward enhancing sharp changes than a first order."
    },
    {
        "id": 116,
        "Question": "10.\tWhat kind of relation can be obtained between the response of first order derivative and second order derivative of an image having a transition into gray-level step from zero?",
        "Options": [
            "a)\tFirst order derivative has a stronger response than a second order",
            "b)\tSecond order derivative has a stronger response than a first order",
            "c)\tBoth first and second order derivative has the same response",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tThis is because a first order derivative has stronger response to a gray-level step than a second order, but, the response becomes same if transition into gray-level step is from zero."
    },
    {
        "id": 117,
        "Question": "11.\tIf in an image there exist similar change in gray-level values in the image, which of the following shows a stronger response using second order derivative operator for sharpening?",
        "Options": [
            "a)\tA line",
            "b)\tA step",
            "c)\tA point",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tsecond order derivative shows a stronger response to a line than a step and to a point than a line, if there is similar changes in gray-level values in an image."
    },
    {
        "id": 118,
        "Question": "The principle objective of Sharpening, to highlight transitions is ________",
        "Options": [
            "a) Pixel density",
            "b) Composure",
            "c) Intensity",
            "d) Brightness"
        ],
        "Answer": "Answer: c\nExplanation: The principle objective of Sharpening, to highlight transitions is Intensity."
    },
    {
        "id": 119,
        "Question": "How can Sharpening be achieved?",
        "Options": [
            "a) Pixel averaging",
            "b) Slicing",
            "c) Correlation",
            "d) None of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation: Sharpening is achieved using Spatial Differentiation."
    },
    {
        "id": 120,
        "Question": "What does Image Differentiation enhance?",
        "Options": [
            "a) Edges",
            "b) Pixel Density",
            "c) Contours",
            "d) None of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation: Image Differentiation enhances Edges and other discontinuities."
    },
    {
        "id": 121,
        "Question": " What does Image Differentiation de-emphasize?",
        "Options": [
            "a) Pixel Density",
            "b) Contours",
            "c) Areas with slowly varying intensities",
            "d) None of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation: Image Differentiation de-emphasizes areas with slowly varying intensities."
    },
    {
        "id": 122,
        "Question": "The requirements of the First Derivative of a digital function:",
        "Options": [
            "a) Must be zero in areas of constant intensity",
            "b) Must be non-zero at the onset of an intensity step",
            "c) Must be non-zero along ramps",
            "d) All of the Mentioned"
        ],
        "Answer": "Answer: d\nExplanation: All the three conditions must be satisfied."
    },
    {
        "id": 123,
        "Question": "What is the Second Derivative of Image Sharpening called?",
        "Options": [
            "a) Gaussian",
            "b) Laplacian",
            "c) Canny",
            "d) None of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation: It is also called Laplacian."
    },
    {
        "id": 124,
        "Question": "The ability that rotating the image and applying the filter gives the same result, as applying the filter to the image first, and then rotating it, is called _____________",
        "Options": [
            "a) Isotropic filtering",
            "b) Laplacian",
            "c) Rotation Invariant",
            "d) None of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation: It is called Rotation Invariant, although the process used is Isotropic filtering."
    },
    {
        "id": 125,
        "Question": "For a function f(x,y), the gradient of ‘f’ at coordinates (x,y) is defined as a ___________",
        "Options": [
            "a) 3-D row vector",
            "b) 3-D column vector",
            "c) 2-D row vector",
            "d) 2-D column vector"
        ],
        "Answer": "Answer: d\nExplanation: The gradient is a 2-D column vector."
    },
    {
        "id": 126,
        "Question": "Where do you find frequent use of Gradient?",
        "Options": [
            "a) Industrial inspection",
            "b) MRI Imaging",
            "c) PET Scan",
            "d) None of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation: Gradient is used in Industrial inspection, to aid humans, in detection of defects."
    },
    {
        "id": 127,
        "Question": "Which of the following occurs in Unsharp Masking?",
        "Options": [
            "a) Blurring original image",
            "b) Adding a mask to original image",
            "c) Subtracting blurred image from original",
            "d) All of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation: In Unsharp Masking, all of the above occurs in the order: Blurring, Subtracting the blurred image and then Adding the mask."
    },
    {
        "id": 128,
        "Question": "Which of the following make an image difficult to enhance?",
        "Options": [
            "a) Narrow range of intensity levels",
            "b) Dynamic range of intensity levels",
            "c) High noise",
            "d) All of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation: All the mentioned options make it difficult to enhance an image."
    },
    {
        "id": 129,
        "Question": "Which of the following is a second-order derivative operator?",
        "Options": [
            "a) Histogram",
            "b) Laplacian",
            "c) Gaussian",
            "d) None of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation: Laplacian is a second-order derivative operator."
    },
    {
        "id": 130,
        "Question": "Response of the gradient to noise and fine detail is _____________ the Laplacian’s.",
        "Options": [
            "a) equal to",
            "b) lower than",
            "c) greater than",
            "d) has no relation with"
        ],
        "Answer": "Answer: b\nExplanation: Response of the gradient to noise and fine detail is lower than the Laplacian’s and can further be lowered by smoothing."
    },
    {
        "id": 131,
        "Question": "Dark characteristics in an image are better solved using ___________",
        "Options": [
            "a) Laplacian Transform",
            "b) Gaussian Transform",
            "c) Histogram Specification",
            "d) Power-law Transformation"
        ],
        "Answer": "Answer: d\nExplanation: It can be solved by Histogram Specification but it is better handled by Power-law Transformation."
    },
    {
        "id": 132,
        "Question": "What is the smallest possible value of a gradient image?",
        "Options": [
            "a) e",
            "b) 1",
            "c) 0",
            "d) -e"
        ],
        "Answer": "Answer: c\nExplanation: The smallest possible value of a gradient image is 0."
    },
    {
        "id": 133,
        "Question": "Which of the following fails to work on dark intensity distributions?",
        "Options": [
            "a) Laplacian Transform",
            "b) Gaussian Transform",
            "c) Histogram Equalization",
            "d) Power-law Transformation"
        ],
        "Answer": "Answer: c\nExplanation: Histogram Equalization fails to work on dark intensity distributions."
    },
    {
        "id": 134,
        "Question": "_____________ is used to detect diseases such as bone infection and tumors.",
        "Options": [
            "a) MRI Scan",
            "b) PET Scan",
            "c) Nuclear Whole Body Scan",
            "d) X-Ray"
        ],
        "Answer": "Answer: c\nExplanation: Nuclear Whole Body Scan is used to detect diseases such as bone infection and tumors"
    },
    {
        "id": 135,
        "Question": "How do you bring out more of the skeletal detail from a Nuclear Whole Body Bone Scan?",
        "Options": [
            "a) Sharpening",
            "b) Enhancing",
            "c) Transformation",
            "d) None of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation: Sharpening is used to bring out more of the skeletal detail."
    },
    {
        "id": 136,
        "Question": "An alternate approach to median filtering is ______________",
        "Options": [
            "a) Use a mask",
            "b) Gaussian filter",
            "c) Sharpening",
            "d) Laplacian filter"
        ],
        "Answer": "Answer:a\nExplanation: Using a mask, formed from the smoothed version of the gradient image, can be used for median filtering."
    },
    {
        "id": 137,
        "Question": "Final step of enhancement lies in _____________ of the sharpened image.",
        "Options": [
            "a) Increase range of contrast",
            "b) Increase range of brightness",
            "c) Increase dynamic range",
            "d) None of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation: Increasing the dynamic range of the sharpened image is the final step in enhancement."
    },
    {
        "id": 138,
        "Question": "What is accepting or rejecting certain frequency components called as?",
        "Options": [
            "a) Filtering",
            "b) Eliminating",
            "c) Slicing",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: a\nExplanation: Filtering is the process of accepting or rejecting certain frequency components."
    },
    {
        "id": 139,
        "Question": "A filter that passes low frequencies is _____________",
        "Options": [
            "a) Band pass filter",
            "b) High pass filter",
            "c) Low pass filter",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: c\nExplanation: Low pass filter passes low frequencies."
    },
    {
        "id": 140,
        "Question": "What is the process of moving a filter mask over the image and computing the sum of products at each location called as?",
        "Options": [
            "a) Convolution",
            "b) Correlation",
            "c) Linear spatial filtering",
            "d) Non linear spatial filtering"
        ],
        "Answer": "Answer: b\nExplanation: The process is called as Correlation."
    },
    {
        "id": 141,
        "Question": "The standard deviation controls ___________ of the bell (2-D Gaussian function of bell shape).",
        "Options": [
            "a) Size",
            "b) Curve",
            "c) Tightness",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: c\nExplanation: The standard deviation controls “tightness” of the bell."
    },
    {
        "id": 142,
        "Question": "What is required to generate an M X N linear spatial filter?",
        "Options": [
            "a) MN mask coefficients",
            "b) M+N coordinates",
            "c) MN spatial coefficients",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: a\nExplanation: To generate an M X N linear spatial filter MN mask coefficients must be specified."
    },
    {
        "id": 143,
        "Question": "What is the difference between Convolution and Correlation?",
        "Options": [
            "a) Image is pre-rotated by 180 degree for Correlation",
            "b) Image is pre-rotated by 180 degree for Convolution",
            "c) Image is pre-rotated by 90 degree for Correlation",
            "d) Image is pre-rotated by 90 degree for Convolution"
        ],
        "Answer": "Answer: b\nExplanation: Convolution is the same as Correlation except that the image must be rotated by 180 degrees initially."
    },
    {
        "id": 144,
        "Question": "Convolution and Correlation are functions of _____________",
        "Options": [
            "a) Distance",
            "b) Time",
            "c) Intensity",
            "d) Displacement"
        ],
        "Answer": "Answer: d\nExplanation: Convolution and Correlation are functions of displacement."
    },
    {
        "id": 145,
        "Question": "The function that contains a single 1 with the rest being 0s is called ______________",
        "Options": [
            "a) Identity function",
            "b) Inverse function",
            "c) Discrete unit impulse",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: c\nExplanation: It is called Discrete unit impulse."
    },
    {
        "id": 146,
        "Question": "Which of the following involves Correlation?",
        "Options": [
            "a) Matching",
            "b) Key-points",
            "c) Blobs",
            "d) None of the Mentioned."
        ],
        "Answer": "Answer: a\nExplanation: Correlation is applied in finding matches."
    },
    {
        "id": 147,
        "Question": "An example of a continuous function of two variables is __________",
        "Options": [
            "a) Identity function",
            "b) Intensity function",
            "c) Contrast stretching",
            "d) Gaussian function"
        ],
        "Answer": "Answer: d\nExplanation: Gaussian function has two variables and is an exponential continuous function."
    },
    {
        "id": 148,
        "Question": "The histogram of a digital image with gray levels in the range [0, L-1] is represented by a discrete function:",
        "Options": [
            "a) h(r_k)=n_k",
            "b) h(r_k )=n/n_k",
            "c) p(r_k )=n_k",
            "d) h(r_k )=n_k/n"
        ],
        "Answer": "Answer: a\nExplanation: The histogram of a digital image with gray levels in the range [0, L-1] is a discrete function h(rk )=nk, where rk is the kth gray level and nkis the number of pixels in the image having gray level rk."
    },
    {
        "id": 149,
        "Question": "How is the expression represented for the normalized histogram?",
        "Options": [
            "a) p(r_k )=n_k",
            "b) p(r_k )=n_k/n",
            "c) p(r_k)=nn_k",
            "d) p(r_k )=n/n_k"
        ],
        "Answer": "Answer: b\nExplanation: It is common practice to normalize a histogram by dividing each of its values by the total number of pixels in the image, denoted by n. Thus, a normalized histogram is given by p(rk )=nk/n, for k=0,1,2…..L-1. Loosely speaking, p(rk ) gives an estimate of the probability of occurrence of gray-level rk. Note that the sum of all components of a normalized histogram is equal to 1."
    },
    {
        "id": 150,
        "Question": "The inverse transformation from s back to r is denoted as:",
        "Options": [
            "a) s=T-1(r) for 0≤s≤1",
            "b) r=T-1(s) for 0≤r≤1",
            "c) r=T-1(s) for 0≤s≤1",
            "d) r=T-1(s) for 0≥s≥1"
        ],
        "Answer": "Answer: d\nExplanation: For any r satisfying the aforementioned conditions, we focus attention on transformations of the form\n               s=T(r)     For 0≤r≤1\nThat produces a level s for every pixel value r in the original image.\n For reasons that will become obvious shortly, we assume that the transformation function T(r) satisfies the following conditions:\nT(r)  is single-valued and monotonically increasing in the interval 0≤r≤1; and\n  0≤T(r)≤1 for 0≤r≤1."
    },
    {
        "id": 151,
        "Question": "The probability density function p_s (s) of the transformed variable s can be obtained by using which of the following formula?",
        "Options": [
            "a) p_s (s)=p_r (r)|dr/ds|",
            "b) p_s (s)=p_r (r)|ds/dr|",
            "c) p_r (r)=p_s (s)|dr/ds|",
            "d) p_s (s)=p_r (r)|dr/dr|"
        ],
        "Answer": "Answer: c\nExplanation: The inverse transformation from s back to r is denoted by:\nr=T-1(s) for 0≤s≤1."
    },
    {
        "id": 152,
        "Question": "A transformation function of particular importance in image processing is represented in which of the following form?",
        "Options": [
            "a) s=T(r)=∫0 (2r)pr (ω)dω",
            "b) s=T(r)=∫0 (r-1)pr (ω)dω",
            "c) s=T(r)=∫0 (r/2)pr (ω)dω",
            "d) s=T(r)=∫0 pr (ω)dω"
        ],
        "Answer": "Answer: a\nExplanation: The probability density function p_s (s) of the transformed variable s can be obtained using a basic formula: p_s (s)=p_r (r)|dr/ds|\nThus, the probability density function of the transformed variable, s, is determined by the gray-level PDF of the input image and by the chosen transformation function."
    },
    {
        "id": 153,
        "Question": "Histogram equalization or Histogram linearization is represented by of the following equation:",
        "Options": [
            "a) sk =∑k j =1 nj/n   k=0,1,2,……,L-1",
            "b) sk =∑k j =0 nj/n   k=0,1,2,……,L-1",
            "c) sk =∑k j =0 n/nj   k=0,1,2,……,L-1",
            "d) sk =∑k j =n nj/n   k=0,1,2,……,L-1"
        ],
        "Answer": "Answer: d\nExplanation: A transformation function of particular importance in image processing has the form: s=T(r)=∫0 r pr(ω)dw, where ω is a dummy variable of integration. The right side of is recognized as the cumulative distribution function (CDF) of random variable r."
    },
    {
        "id": 154,
        "Question": "What is the method that is used to generate a processed image that have a specified histogram?",
        "Options": [
            "a) Histogram linearization",
            "b) Histogram equalization",
            "c) Histogram matching",
            "d) Histogram processing"
        ],
        "Answer": "Answer: b\nExplanation: A plot of pk_ (rk) versus r_k is called a histogram .The transformation (mapping) given in sk =∑k j =0)k nj/n k=0,1,2,……,L-1 is called histogram equalization or histogram linearization."
    },
    {
        "id": 155,
        "Question": "In a dark image, the components of histogram are concentrated on which side of the grey scale?",
        "Options": [
            "a) High",
            "b) Medium",
            "c) Low",
            "d) Evenly distributed"
        ],
        "Answer": "Answer: c\nExplanation: In particular, it is useful sometimes to be able to specify the shape of the histogram that we wish the processed image to have. The method used to generate a processed image that has a specified histogram is called histogram matching or histogram specification."
    },
    {
        "id": 156,
        "Question": "What is the basis for numerous spatial domain processing techniques?",
        "Options": [
            "a) Transformations",
            "b) Scaling",
            "c) Histogram",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: c\nExplanation: Histogram is the basis for numerous spatial domain processing techniques."
    },
    {
        "id": 157,
        "Question": "In _______ image we notice that the components of histogram are concentrated on the low side on intensity scale.",
        "Options": [
            "a) bright",
            "b) dark",
            "c) colourful",
            "d) All of the Mentioned"
        ],
        "Answer": "Answer: b\nExplanation: Only in dark images, we notice that the components of histogram are concentrated on the low side on intensity scale."
    },
    {
        "id": 158,
        "Question": "What is Histogram Equalisation also called as?",
        "Options": [
            "a) Histogram Matching",
            "b) Image Enhancement",
            "c) Histogram linearisation",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: c\nExplanation: Histogram Linearisation is also known as Histogram Equalisation."
    },
    {
        "id": 159,
        "Question": "What is Histogram Matching also called as?",
        "Options": [
            "a) Histogram Equalisation",
            "b) Histogram Specification",
            "c) Histogram linearisation",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: b\nExplanation: Histogram Specification is also known as Histogram Matching."
    },
    {
        "id": 160,
        "Question": "Histogram Equalisation is mainly used for ________________",
        "Options": [
            "a) Image enhancement",
            "b) Blurring",
            "c) Contrast adjustment",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: a\nExplanation: It is mainly used for Enhancement of usually dark images."
    },
    {
        "id": 161,
        "Question": "To reduce computation if one utilises non-overlapping regions, it usually produces ______ effect.",
        "Options": [
            "a) Dimming",
            "b) Blurred",
            "c) Blocky",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: c\nExplanation: Utilising non-overlapping regions usually produces “Blocky” effect."
    },
    {
        "id": 162,
        "Question": "What does SEM stands for?",
        "Options": [
            "a) Scanning Electronic Machine",
            "b) Self Electronic Machine",
            "c) Scanning Electron Microscope",
            "d) Scanning Electric Machine"
        ],
        "Answer": "Answer: c\nExplanation: SEM stands for Scanning Electron Microscope."
    },
    {
        "id": 163,
        "Question": "The type of Histogram Processing in which pixels are modified based on the intensity distribution of the image is called _______________.",
        "Options": [
            "a) Intensive",
            "b) Local",
            "c) Global",
            "d) Random"
        ],
        "Answer": "Answer: c\nExplanation: It is called Global Histogram Processing."
    },
    {
        "id": 164,
        "Question": "Which type of Histogram Processing is suited for minute detailed enhancements?",
        "Options": [
            "a) Intensive",
            "b) Local",
            "c) Global",
            "d) Random"
        ],
        "Answer": "Answer: b\nExplanation: Local Histogram Processing is used."
    },
    {
        "id": 165,
        "Question": "In uniform PDF, the expansion of PDF is ________________",
        "Options": [
            "a) Portable Document Format",
            "b) Post Derivation Function",
            "c) Previously Derived Function",
            "d) Probability Density Function"
        ],
        "Answer": "Answer: d\nExplanation: PDF stands for Probability Density Function."
    },
    {
        "id": 166,
        "Question": "The output of a smoothing, linear spatial filtering is a ____________ of the pixels contained in the neighbourhood of the filter mask.",
        "Options": [
            "a) Sum",
            "b) Product",
            "c) Average",
            "d) Dot Product"
        ],
        "Answer": "Answer: c\nExplanation: Smoothing is simply the average of the pixels contained in the neighbourhood."
    },
    {
        "id": 167,
        "Question": "Averaging filters is also known as ____________ filter.",
        "Options": [
            "a) Low pass",
            "b) High pass",
            "c) Band pass",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: a\nExplanation: Averaging filters is also known as  Low pass filters."
    },
    {
        "id": 168,
        "Question": "What is the undesirable side effects of Averaging filters?",
        "Options": [
            "a) No side effects",
            "b) Blurred image",
            "c) Blurred edges",
            "d) Loss of sharp transitions"
        ],
        "Answer": "Answer: c\nExplanation: Blue edges is the undesirable side effect of Averaging filters."
    },
    {
        "id": 169,
        "Question": "A spatial averaging filter in which all coefficients are equal is called _______________.",
        "Options": [
            "a) Square filter",
            "b) Neighbourhood",
            "c) Box filter",
            "d) Zero filter"
        ],
        "Answer": "Answer: c\nExplanation: It is called a Box filter."
    },
    {
        "id": 170,
        "Question": "Which term is used to indicate that pixels are multiplied by different coefficients?",
        "Options": [
            "a) Weighted average",
            "b) Squared average",
            "c) Spatial average",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: a\nExplanation: It is called weighted average since more importance(weight) is given to some pixels."
    },
    {
        "id": 171,
        "Question": "The non linear spacial filters whose response is based on ordering of the pixels contained is called _____________.",
        "Options": [
            "a) Box filter",
            "b) Square filter",
            "c) Gaussian filter",
            "d) Order-statistic filter"
        ],
        "Answer": "Answer: d\nExplanation: It is called Order-statistic filter."
    },
    {
        "id": 172,
        "Question": "Impulse noise in Order-statistic filter is also called as _______________",
        "Options": [
            "a) Median noise",
            "b) Bilinear noise",
            "c) Salt and pepper noise",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: c\nExplanation: It is called salt-and-pepper noise because of its appearance as white and black dots superimposed on an image."
    },
    {
        "id": 173,
        "Question": "Best example for a Order-statistic filter is ____________________",
        "Options": [
            "a) Impulse filter",
            "b) Averaging filter",
            "c) Median filter",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: c\nExplanation: Median filter is the best known Order-statistic filter."
    },
    {
        "id": 174,
        "Question": "What does “eliminated” refer to in median filter?",
        "Options": [
            "a) Force to average intensity of neighbours",
            "b) Force to median intensity of neighbours",
            "c) Eliminate median value of pixels",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: b\nExplanation: It refers to forcing to median intensity of neighbours."
    },
    {
        "id": 175,
        "Question": "Which of the following is best suited for salt-and-pepper noise elimination?",
        "Options": [
            "a) Average filter",
            "b) Box filter",
            "c) Max filter",
            "d) Median filter"
        ],
        "Answer": "Answer: d\nExplanation: Median filter is better suited than average filter for salt-and-pepper noise elimination."
    },
    {
        "id": 176,
        "Question": "Smoothing filter is used for which of the following work(s)?",
        "Options": [
            "a)\tBlurring",
            "b)\tNoise reduction",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tSmoothing filter is used for blurring and noise reduction."
    },
    {
        "id": 177,
        "Question": "The response of the smoothing linear spatial filter is/are __________",
        "Options": [
            "a)\tSum of image pixel in the neighborhood filter mask",
            "b)\tDifference of image in the neighborhood filter mask",
            "c)\tProduct of pixel in the neighborhood filter mask",
            "d)\tAverage of pixels in the neighborhood of filter mask"
        ],
        "Answer": "Answer: d\nExplanation:\tThe average of pixels in the neighborhood of filter mask is simply the output of the smoothing linear spatial filter."
    },
    {
        "id": 178,
        "Question": "Which of the following filter(s) results in a value as average of pixels in the neighborhood of filter mask.",
        "Options": [
            "a)\tSmoothing linear spatial filter",
            "b)\tAveraging filter",
            "c)\tLowpass filter",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation:\tThe output as an average of pixels in the neighborhood of filter mask is simply the output of the smoothing linear spatial filter also known as averaging filter and lowpass filter."
    },
    {
        "id": 179,
        "Question": "What is/are the resultant image of a smoothing filter?",
        "Options": [
            "a)\tImage with high sharp transitions in gray levels",
            "b)\tImage with reduced sharp transitions in gray levels",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tRandom noise has sharp transitions in gray levels and smoothing filters does noise reduction."
    },
    {
        "id": 180,
        "Question": "At which of the following scenarios averaging filters is/are used?",
        "Options": [
            "a)\tIn the reduction of irrelevant details in an image",
            "b)\tFor smoothing of false contours",
            "c)\tFor noise reductions",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation:\tAveraging filter or smoothing linear spatial filter is used: for noise reduction by reducing the sharp transitions in gray level, for smoothing false contours that arises because of use of insufficient number of gray values and for reduction of irrelevant data i.e. the pixels regions that are small in comparison of filter mask."
    },
    {
        "id": 181,
        "Question": " A spatial averaging filter having all the coefficients equal is termed _________",
        "Options": [
            "a)\tA box filter",
            "b)\tA weighted average filter",
            "c)\tA standard average filter",
            "d)\tA median filter"
        ],
        "Answer": "Answer: a\nExplanation:\tAn averaging filter is termed as box filter if all the coefficients of spatial averaging filter are equal."
    },
    {
        "id": 182,
        "Question": "What does using a mask having central coefficient maximum and then the coefficients reducing as a function of increasing distance from origin results?",
        "Options": [
            "a)\tIt results in increasing blurring in smoothing process",
            "b)\tIt results to reduce blurring in smoothing process",
            "c)\tNothing with blurring occurs as mask coefficient relation has no effect on smoothing process",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tUse of a mask having central coefficient maximum and then the coefficients reducing as a function of increasing distance from origin is a strategy to reduce blurring in smoothing process."
    },
    {
        "id": 183,
        "Question": "What is the relation between blurring effect with change in filter size?",
        "Options": [
            "a)\tBlurring increases with decrease of the size of filter size",
            "b)\tBlurring decrease with decrease of the size of filter size",
            "c)\tBlurring decrease with increase of the size of filter size",
            "d)\tBlurring increases with increase of the size of filter size"
        ],
        "Answer": "Answer: d\nExplanation:\tUsing a size 3 filter 3*3 and 5*5 size squares and other objects shows a significant blurring with respect to object of larger size.\nThe blurring gets more pronounced while using filter size 5, 9 and so on."
    },
    {
        "id": 184,
        "Question": "Which of the following filter(s) has the response in which the central pixel value is replaced by value defined by ranking the pixel in the image encompassed by filter?",
        "Options": [
            "a)\tOrder-Statistic filters",
            "b)\tNon-linear spatial filters",
            "c)\tMedian filter",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation:\tAn Order-Statistic filters also called non-linear spatial filters, response is based on ranking the pixel in the image encompassed by filter that replaces the central pixel value. A Median filter is an example of such filters."
    },
    {
        "id": 185,
        "Question": "Two filters of similar size are used for smoothing image having impulse noise. One is median filter while the other is a linear spatial filter. Which would the blurring effect of both?",
        "Options": [
            "a)\tMedian filter effects in considerably less blurring than the linear spatial filters",
            "b)\tMedian filter effects in considerably more blurring than the linear spatial filters",
            "c)\tBoth have the same blurring effect",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tA median filter the pixel value is replaced by median of the gray-level in the neighborhood of that pixel and also the original pixel value is included while computing the median."
    },
    {
        "id": 186,
        "Question": "An image contains noise having appearance as black and white dots superimposed on the image. Which of the following noise(s) has the same appearance?",
        "Options": [
            "a)\tSalt-and-pepper noise",
            "b)\tGaussian noise",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tFor impulse noise, median filter is much effective for noise reduction and causes considerably less blurring than the linear spatial filters."
    },
    {
        "id": 187,
        "Question": "While performing the median filtering, suppose a 3*3 neighborhood has value (10, 20, 20, 20, 15, 20, 20, 25, 100), then what is the median value to be given to the pixel under filter?",
        "Options": [
            "a)\t15",
            "b)\t20",
            "c)\t100",
            "d)\t25"
        ],
        "Answer": "Answer: c\nExplanation:\tAn impulse noise has an appearance as black and white dots superimposed on the image. This is also known as Salt-and-pepper noise."
    },
    {
        "id": 188,
        "Question": "Which of the following are forced to the median intensity of the neighbors by n*n median filter?",
        "Options": [
            "a)\tIsolated cluster of pixels that are light or dark in comparison to their neighbors",
            "b)\tIsolated cluster of pixels whose area is less than one-half the filter area",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tThe values are first sorted and so turns out to (10, 15, 20, 20, 20, 20, 20, 25, and 100). For a 3*3 neighborhood the 5th largest value is the median, and so is 20."
    },
    {
        "id": 189,
        "Question": "Which filter(s) used to find the brightest point in the image?",
        "Options": [
            "a)\tMedian filter",
            "b)\tMax filter",
            "c)\tMean filter",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tThe isolated cluster pixel value doesn’t come as a median value and since are either are light or dark as compared to neighbors, so are forced with median intensity of neighbors that aren’t even close to their original value and so are sometimes termed “eliminated”.\nIf the area of such isolated pixels are < n2/2, that is again the pixel value won’t be a median value and so are eliminated.\nLarger cluster pixels value are more pronounced to be a median value, so are considerably less forced to median intensity."
    },
    {
        "id": 190,
        "Question": "The median filter also represents which of the following ranked set of numbers?",
        "Options": [
            "a)\t100th percentile",
            "b)\t0th percentile",
            "c)\t50th percentile",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tA max filter gives the brightest point in an image and so is used."
    },
    {
        "id": 191,
        "Question": "Which of the following filter represents a 0th percentile set of numbers?",
        "Options": [
            "a)\tMax filter",
            "b)\tMean filter",
            "c)\tMedian filter",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tSince the median filter forces median intensity to the pixel which is almost the largest value in the middle of the list of values as per the ranking, so represents a 50th percentile ranked set of numbers."
    },
    {
        "id": 192,
        "Question": "In neighborhood operations working is being done with the value of image pixel in the neighborhood and the corresponding value of a subimage that has same dimension as neighborhood. The subimage is referred as _________",
        "Options": [
            "a)\tFilter",
            "b)\tMask",
            "c)\tTemplate",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation:\tWorking in neighborhood operations is done with the value of a subimage having same dimension as neighborhood corresponding to the value in the image pixel. The subimage is called as filter, mask, template, kernel or window."
    },
    {
        "id": 193,
        "Question": "The response for linear spatial filtering is given by the relationship __________",
        "Options": [
            "a)\tSum of filter coefficient’s product and corresponding image pixel under filter mask",
            "b)\tDifference of filter coefficient’s product and corresponding image pixel under filter mask",
            "c)\tProduct of filter coefficient’s product and corresponding image pixel under filter mask",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tIn spatial filtering the mask is moved from point to point and at each point the response is calculated using a predefined relationship. The relationship in linear spatial filtering is given by: the Sum of filter coefficient’s product and corresponding image pixel in area under filter mask."
    },
    {
        "id": 194,
        "Question": "In linear spatial filtering, what is the pixel of the image under mask corresponding to the mask coefficient w (1, -1), assuming a 3*3 mask?",
        "Options": [
            "a)\tf (x, -y)",
            "b)\tf (x + 1, y)",
            "c)\tf (x, y – 1)",
            "d)\tf (x + 1, y – 1)"
        ],
        "Answer": "Answer: d\nExplanation:\tThe pixel corresponding to mask coefficient (a 3*3 mask) w (0, 0) is f (x, y), and so for w (1, -1) is f (x + 1, y – 1)."
    },
    {
        "id": 195,
        "Question": "Which of the following is/are a nonlinear operation?",
        "Options": [
            "a)\tComputation of variance",
            "b)\tComputation of median",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tComputation of variance as well as median comes under nonlinear operation."
    },
    {
        "id": 196,
        "Question": "Which of the following is/are used as basic function in nonlinear filter for noise reduction?",
        "Options": [
            "a)\tComputation of variance",
            "b)\tComputation of median",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tComputation of median gray-level value in the neighborhood is the basic function of nonlinear filter for noise reduction."
    },
    {
        "id": 197,
        "Question": "In neighborhood operation for spatial filtering if a square mask of size n*n is used it is restricted that the center of mask must be at a distance ≥ (n – 1)/2 pixels from border of image, what happens to the resultant image?",
        "Options": [
            "a)\tThe resultant image will be of same size as original image",
            "b)\tThe resultant image will be a little larger size than original image",
            "c)\tThe resultant image will be a little smaller size than original image",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tIf the center of mask must be at a distance ≥ (n – 1)/2 pixels from border of image, the border pixels won’t get processed under mask and so the resultant image would be of smaller size."
    },
    {
        "id": 198,
        "Question": "Which of the following method is/are used for padding the image?",
        "Options": [
            "a)\tAdding rows and column of 0 or other constant gray level",
            "b)\tSimply replicating the rows or columns",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tIn neighborhood operation for spatial filtering using square mask, padding of original image is done to obtain filtered image of same size as of original image done, by adding rows and column of 0 or other constant gray level or by replicating the rows or columns of the original image."
    },
    {
        "id": 199,
        "Question": "In neighborhood operation for spatial filtering using square mask of n*n, which of the following approach is/are used to obtain a perfectly filtered result irrespective of the size?",
        "Options": [
            "a)\tBy padding the image",
            "b)\tBy filtering all the pixels only with the mask section that is fully contained in the image",
            "c)\tBy ensuring that center of mask must be at a distance ≥ (n – 1)/2 pixels from border of image",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tBy ensuring that center of mask must be at a distance ≥ (n – 1)/2 pixels from border of image, the resultant image would be of smaller size but all the pixels would be the result of the filter processing and so is a fully filtered result.\nIn the other approach like padding affect the values near the edges that gets more prevalent with mask size increase, while the another approach results in the band of pixels near border that gets processed with partial filter mask. So, not a fully filtered case."
    },
    {
        "id": 200,
        "Question": "Which of the following fact(s) is/are true for the relationship between low frequency component of Fourier transform and the rate of change of gray levels?",
        "Options": [
            "a)\tMoving away from the origin of transform the low frequency corresponds to smooth gray level variation",
            "b)\tMoving away from the origin of transform the low frequencies corresponds to abrupt change in gray level",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tMoving away from the origin of transform the low frequency corresponds to the slowly varying components in an image. Moving further away from origin the higher frequencies corresponds to faster gray level changes."
    },
    {
        "id": 201,
        "Question": "Which of the following fact(s) is/are true for the relationship between high frequency component of Fourier transform and the rate of change of gray levels?",
        "Options": [
            "a)\tMoving away from the origin of transform the high frequency corresponds to smooth gray level variation",
            "b)\tMoving away from the origin of transform the higher frequencies corresponds to abrupt change in gray level",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tMoving away from the origin of transform the low frequency corresponds to the slowly varying components in an image. Moving further away from origin the higher frequencies corresponds to faster gray level changes."
    },
    {
        "id": 202,
        "Question": "What is the name of the filter that multiplies two functions F(u, v) and H(u, v), where F has complex components too since is Fourier transformed function of f(x, y), in an order that each component of H multiplies both real and complex part of corresponding component in F?",
        "Options": [
            "a)\tUnsharp mask filter",
            "b)\tHigh-boost filter",
            "c)\tZero-phase-shift-filter",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tZero-phase-shift-filter multiplies two functions F(u, v) and H(u, v), where F has complex components too since is Fourier transformed function of f(x, y), in an order that each component of H multiplies both real and complex part of corresponding component in F."
    },
    {
        "id": 203,
        "Question": "To set the average value of an image zero, which of the following term would be set 0 in the frequency domain and the inverse transformation is done, where F(u, v) is Fourier transformed function of f(x, y)?",
        "Options": [
            "a)\tF(0, 0)",
            "b)\tF(0, 1)",
            "c)\tF(1, 0)",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tFor an image f(x, y), the Fourier transform at origin of an image, F(0, 0), is equal to the average value of the image."
    },
    {
        "id": 204,
        "Question": "What is the name of the filter that is used to turn the average value of a processed image zero?",
        "Options": [
            "a)\tUnsharp mask filter",
            "b)\tNotch filter",
            "c)\tZero-phase-shift-filter",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tNotch filter sets F (0, 0), to zero, hence setting up the average value of image zero. The filter is named so, because it is a constant function with a notch at origin and so is able to set F (0, 0) to zero leaving out other values."
    },
    {
        "id": 205,
        "Question": "Which of the following filter(s) attenuates high frequency while passing low frequencies of an image?",
        "Options": [
            "a)\tUnsharp mask filter",
            "b)\tLowpass filter",
            "c)\tZero-phase-shift filter",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tA lowpass filter attenuates high frequency while passing low frequencies."
    },
    {
        "id": 206,
        "Question": "Which of the following filter(s) attenuates low frequency while passing high frequencies of an image?",
        "Options": [
            "a)\tUnsharp mask filter",
            "b)\tHighpass filter",
            "c)\tZero-phase-shift filter",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tA highpass filter attenuates low frequency while passing high frequencies."
    },
    {
        "id": 207,
        "Question": " Which of the following filter have a less sharp detail than the original image because of attenuation of high frequencies?",
        "Options": [
            "a)\tHighpass filter",
            "b)\tLowpass filter",
            "c)\tZero-phase-shift filter",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tA lowpass filter attenuates high so the image has less sharp details."
    },
    {
        "id": 208,
        "Question": "The feature(s) of a highpass filtered image is/are  ___________",
        "Options": [
            "a)\tHave less gray-level variation in smooth areas",
            "b)\tEmphasized transitional gray-level details",
            "c)\tAn overall sharper image",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation:\tA highpass filter attenuates low frequency so have less gray-level variation in smooth areas, and allows high frequencies so have emphasized transitional gray-level details, resulting in a sharper image."
    },
    {
        "id": 209,
        "Question": "A spatial domain filter of the corresponding filter in frequency domain can be obtained by applying which of the following operation(s) on filter in frequency domain?",
        "Options": [
            "a)\tFourier transform",
            "b)\tInverse Fourier transform",
            "c)\tNone of the mentioned",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tFilters in spatial domain and frequency domain has a Fourier transform pair relation.  A spatial domain filter of the corresponding filter in frequency domain can be obtained by applying inverse Fourier transform on frequency domain filter."
    },
    {
        "id": 210,
        "Question": "A frequency domain filter of the corresponding filter in spatial domain can be obtained by applying which of the following operation(s) on filter in spatial domain?",
        "Options": [
            "a)\tFourier transform",
            "b)\tInverse Fourier transform",
            "c)\tNone of the mentioned",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tFilters in spatial domain and frequency domain has a Fourier transform pair relation.  A frequency domain filter of the corresponding filter in spatial domain can be obtained by applying inverse Fourier transform on spatial domain filter."
    },
    {
        "id": 211,
        "Question": "Which of the following filtering is done in frequency domain in correspondence to lowpass filtering in spatial domain?",
        "Options": [
            "a)\tGaussian filtering",
            "b)\tUnsharp mask filtering",
            "c)\tHigh-boost filtering",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tA plot of Gaussian filter in frequency domain can be recognized similar to lowpass filter in spatial domain."
    },
    {
        "id": 212,
        "Question": "Using the feature of reciprocal relationship of filter in spatial domain and corresponding filter in frequency domain, which of the following fact is true?",
        "Options": [
            "a)\tThe narrower the frequency domain filter results in increased blurring",
            "b)\tThe wider the frequency domain filter results in increased blurring",
            "c)\tThe narrower the frequency domain filter results in decreased blurring",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tThe characteristics feature of reciprocal relationship says that the narrower the frequency domain filter becomes it attenuates more low frequency component and so increases blurring."
    },
    {
        "id": 213,
        "Question": "1.\tSmoothing in frequency domain is achieved by attenuating which of the following component in the transform of a given image?",
        "Options": [
            "a)\tAttenuating a range of high-frequency components",
            "b)\tAttenuating a range of low-frequency components",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tSince, edges and sharp transitions contribute significantly to high-frequency contents in the gray level of an image. So, smoothing is done by attenuating a range of high-frequency components."
    },
    {
        "id": 214,
        "Question": "2.\tWhich of the following is/are considered as type(s) of lowpass filters?",
        "Options": [
            "a)\tIdeal",
            "b)\tButterworth",
            "c)\tGaussian",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation:\tLowpass filters are considered of three types: Ideal, Butterworth, and Gaussian."
    },
    {
        "id": 215,
        "Question": "3.\tWhich of the following lowpass filters is/are covers the range of very sharp filter function?",
        "Options": [
            "a)\tIdeal lowpass filters",
            "b)\tButterworth lowpass filter",
            "c)\tGaussian lowpass filter",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tIdeal lowpass filter covers the range of very sharp filter functioning of lowpass filters."
    },
    {
        "id": 216,
        "Question": "4.\tWhich of the following lowpass filters is/are covers the range of very smooth filter function?",
        "Options": [
            "a)\tIdeal lowpass filters",
            "b)\tButterworth lowpass filter",
            "c)\tGaussian lowpass filter",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tGaussian lowpass filter covers the range of very smooth filter functioning of lowpass filters."
    },
    {
        "id": 217,
        "Question": "5.\tButterworth lowpass filter has a parameter, filter order, determining its functionality as very sharp or very smooth filter function or an intermediate filter function. If the parameter value is very high, the filter approaches to which of the following filter(s)?",
        "Options": [
            "a)\tIdeal lowpass filter",
            "b)\tGaussian lowpass filter",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tFor high value of filter order Butterworth lowpass filter behaves as Ideal lowpass filter, while for lower order value it has a smoother form behaving like Gaussian lowpass filter."
    },
    {
        "id": 218,
        "Question": "6.\tButterworth lowpass filter has a parameter, filter order, determining its functionality as very sharp or very smooth filter function or an intermediate filter function. If the parameter value is of lower order, the filter approaches to which of the following filter(s)?",
        "Options": [
            "a)\tIdeal lowpass filter",
            "b)\tGaussian lowpass filter",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tFor high value of filter order Butterworth lowpass filter behaves as Ideal lowpass filter, while for lower order value it has a smoother form behaving like Gaussian lowpass filter."
    },
    {
        "id": 219,
        "Question": "7.\tIn a filter, all the frequencies inside a circle of radius D0 are not attenuated while all frequencies outside circle are completely attenuated. The D0 is the specified nonnegative distance from origin of the Fourier transform. Which of the following filter(s) characterizes the same?",
        "Options": [
            "a)\tIdeal filter",
            "b)\tButterworth filter",
            "c)\tGaussian filter",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tIn ideal filter all the frequencies inside a circle of radius D0 are not attenuated while all frequencies outside the circle are completely attenuated."
    },
    {
        "id": 220,
        "Question": "8.\tIn an ideal lowpass filter case, what is the relation between the filter radius and the blurring effect caused because of the filter?",
        "Options": [
            "a)\tFilter size is directly proportional to blurring caused because of filter",
            "b)\tFilter size is inversely proportional to blurring caused because of filter",
            "c)\tThere is no relation between filter size and blurring caused because of it",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tIncrease in filter size, removes less power from the image and so less severe blurring occurs."
    },
    {
        "id": 221,
        "Question": "9.\tThe characteristics of the lowpass filter h(x, y) is/are_________",
        "Options": [
            "a)\tHas a dominant component at origin",
            "b)\tHas a concentric, circular components about the center component",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tthe lowpass filter has two different characteristics: one is a dominant component at origin and other one is a concentric, circular components about the center component."
    },
    {
        "id": 222,
        "Question": "10.\tWhat is the relation for the components of ideal lowpass filter and the image enhancement?",
        "Options": [
            "a)\tThe concentric component is primarily responsible for blurring",
            "b)\tThe center component is primarily for the ringing characteristic of ideal filter",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation:\tThe center component of ideal lowpass filter is primarily responsible for blurring while, concentric component is primarily for the ringing characteristic of ideal filter."
    },
    {
        "id": 223,
        "Question": "11.\tUsing the feature of reciprocal relationship of filter in spatial domain and corresponding filter in frequency domain along with convolution, which of the following fact is true?",
        "Options": [
            "a)\tThe narrower the frequency domain filter more severe is the ringing",
            "b)\tThe wider the frequency domain filter more severe is the ringing",
            "c)\tThe narrower the frequency domain filter less severe is the ringing",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tThe characteristics feature of reciprocal relationship says that the narrower the frequency domain filter becomes it attenuates more low frequency component and so increases blurring and more severe becomes the ringing."
    },
    {
        "id": 224,
        "Question": "12.\tWhich of the following defines the expression for BLPF H(u, v) of order n, where D(u, v) is the distance from point (u, v), D0  is the distance defining cutoff frequency?",
        "Options": [
            "a)\t<img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-frequencydomain-filters-smoothing-q12.png\" alt=\"digital-image-processing-questions-answers-frequencydomain-filters-smoothing-q12\" width=\"119\" height=\"38\" class=\"alignnone size-full wp-image-148770\" />",
            "b)\t<img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-frequencydomain-filters-smoothing-q12a.png\" alt=\"digital-image-processing-questions-answers-frequencydomain-filters-smoothing-q12a\" width=\"170\" height=\"49\" class=\"alignnone size-full wp-image-148771\" />",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tBLPF is the Butterworth lowpass filter and is defined as:\n<img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-frequencydomain-filters-smoothing-q12.png\" alt=\"digital-image-processing-questions-answers-frequencydomain-filters-smoothing-q12\" width=\"119\" height=\"38\" class=\"alignnone size-full wp-image-148770\" />."
    },
    {
        "id": 225,
        "Question": "13.\tWhich of the following defines the expression for ILPF H(u, v) of order n, where D(u, v) is the distance from point (u, v), D0  is the distance defining cutoff frequency?",
        "Options": [
            "a)\t<img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-frequencydomain-filters-smoothing-q12.png\" alt=\"digital-image-processing-questions-answers-frequencydomain-filters-smoothing-q12\" width=\"119\" height=\"38\" class=\"alignnone size-full wp-image-148770\" />",
            "b)\t<img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-frequencydomain-filters-smoothing-q12a.png\" alt=\"digital-image-processing-questions-answers-frequencydomain-filters-smoothing-q12a\" width=\"170\" height=\"49\" class=\"alignnone size-full wp-image-148771\" />",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tILPF is the Ideal lowpass filter and is defined as:\n<img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-frequencydomain-filters-smoothing-q12a.png\" alt=\"digital-image-processing-questions-answers-frequencydomain-filters-smoothing-q12a\" width=\"170\" height=\"49\" class=\"alignnone size-full wp-image-148771\" />."
    },
    {
        "id": 226,
        "Question": "\tA Butterworth filter of what order has no ringing?",
        "Options": [
            "a)\t1",
            "b)\t2",
            "c)\t3",
            "d)\t4"
        ],
        "Answer": "Answer: b\nExplanation:\tILPF has sharp discontinuity and BLPF doesn’t, so BLPF establishes a clear cutoff b/w passed and filtered frequencies."
    },
    {
        "id": 227,
        "Question": "In frequency domain terminology, which of the following is defined as “obtaining a highpass filtered image by subtracting from the given image a lowpass filtered version of itself”?",
        "Options": [
            "a)\tEmphasis filtering",
            "b)\tUnsharp masking",
            "c)\tButterworth filtering",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tIn frequency domain terminology unsharp masking is defined as “obtaining a highpass filtered image by subtracting from the given image a lowpass filtered version of itself”."
    },
    {
        "id": 228,
        "Question": "Which of the following is/ are a generalized form of unsharp masking?",
        "Options": [
            "a)\tLowpass filtering",
            "b)\tHigh-boost filtering",
            "c)\tEmphasis filtering",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tUnsharp masking is defined as “obtaining a highpass filtered image by subtracting from the given image a lowpass filtered version of itself” while high-boost filtering generalizes it by multiplying the input image by a constant, say A≥1."
    },
    {
        "id": 229,
        "Question": "High boost filtered image is expressed as: fhb = A f(x, y) – flp(x, y), where f(x, y) the input image, A is a constant and flp(x, y) is the lowpass filtered version of f(x, y). Which of the following fact validates if A=1?",
        "Options": [
            "a)\tHigh-boost filtering reduces to regular Highpass filtering",
            "b)\tHigh-boost filtering reduces to regular Lowpass filtering",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tHigh boost filtered image is modified as: fhb = (A-1) f(x, y) +f(x, y) – flp(x, y)\ni.e.  fhb = (A-1) f(x, y) + fhp(x, y). So, when A=1, High-boost filtering reduces to regular Highpass filtering."
    },
    {
        "id": 230,
        "Question": "High boost filtered image is expressed as: fhb = A f(x, y) – flp(x, y), where f(x, y) the input image, A is a constant and flp(x, y) is the lowpass filtered version of f(x, y). Which of the following fact(s) validates if A increases past 1?",
        "Options": [
            "a)\tThe contribution of the image itself becomes more dominant",
            "b)\tThe contribution of the highpass filtered version of image becomes less dominant",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tHigh boost filtered image is modified as: fhb = (A-1) f(x, y) +f(x, y) – flp(x, y)\ni.e.  fhb = (A-1) f(x, y) + fhp(x, y). So, when A>1, the contribution of the image itself becomes more dominant over the highpass filtered version of image."
    },
    {
        "id": 231,
        "Question": "If, Fhp(u, v)=F(u, v) – Flp(u, v) and Flp(u, v) = Hlp(u, v)F(u, v), where F(u, v) is the image in frequency domain with Fhp(u, v) its highpass filtered version, Flp(u, v) its lowpass filtered component and  Hlp(u, v) the transfer function of a lowpass filter. Then, unsharp masking can be implemented directly in frequency domain by using a filter. Which of the following is the required filter?",
        "Options": [
            "a)\tHhp(u, v) = Hlp(u, v)",
            "b)\tHhp(u, v) = 1 + Hlp(u, v)",
            "c)\tHhp(u, v) = – Hlp(u, v)",
            "d)\tHhp(u, v) = 1 – Hlp(u, v)"
        ],
        "Answer": "Answer: d\nExplanation:\tUnsharp masking can be implemented directly in frequency domain by using a composite filter: Hhp(u, v) = 1 – Hlp(u, v)."
    },
    {
        "id": 232,
        "Question": "Unsharp masking can be implemented directly in frequency domain by using a filter: Hhp(u, v) = 1 – Hlp(u, v), where Hlp(u, v) the transfer function of a lowpass filter. What kind of filter is Hhp(u, v)?",
        "Options": [
            "a)\tComposite filter",
            "b)\tM-derived filter",
            "c)\tConstant k filter",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tUnsharp masking can be implemented directly in frequency domain by using a composite filter: Hhp(u, v) = 1 – Hlp(u, v)."
    },
    {
        "id": 233,
        "Question": "If unsharp masking can be implemented directly in frequency domain by using a composite filter: Hhp(u, v) = 1 – Hlp(u, v), where Hlp(u, v) the transfer function of a lowpass filter. Then, the composite filter for High-boost filtering is __________",
        "Options": [
            "a)\tHhb(u, v) = 1 – Hhp(u, v)",
            "b)\tHhb(u, v) = 1 + Hhp(u, v)",
            "c)\tHhb(u, v) = (A-1) – Hhp(u, v), A is a constant",
            "d)\tHhb(u, v) = (A-1) + Hhp(u, v), A is a constant"
        ],
        "Answer": "Answer: d\nExplanation:\tFor given composite filter of unsharp masking Hhp(u, v) = 1 – Hlp(u, v), the composite filter for High-boost filtering is Hhb(u, v) = (A-1) + Hhp(u, v)."
    },
    {
        "id": 234,
        "Question": "The frequency domain Laplacian is closer to which of the following mask?",
        "Options": [
            "a)\tMask that excludes the diagonal neighbors",
            "b)\tMask that excludes neighbors in 4-adjacancy",
            "c)\tMask that excludes neighbors in 8-adjacancy",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tThe frequency domain Laplacian is closer to mask that excludes the diagonal neighbors."
    },
    {
        "id": 235,
        "Question": "To accentuate the contribution to enhancement made by high-frequency components, which of the following method(s) should be more appropriate to apply?",
        "Options": [
            "a)\tMultiply the highpass filter by a constant",
            "b)\tAdd an offset to the highpass filter to prevent eliminating zero frequency term by filter",
            "c)\tAll of the mentioned combined and applied",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tTo accentuate the contribution to enhancement made by high-frequency components, we have to multiply the highpass filter by a constant and add an offset to the highpass filter to prevent eliminating zero frequency term by filter."
    },
    {
        "id": 236,
        "Question": "A process that accentuate the contribution to enhancement made by high-frequency components, by multiplying the highpass filter by a constant and adding an offset to the highpass filter to prevent eliminating zero frequency term by filter is known as _______",
        "Options": [
            "a)\tUnsharp masking",
            "b)\tHigh-boost filtering",
            "c)\tHigh frequency emphasis",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tHigh frequency emphasis is the method that accentuate the contribution to enhancement made by high-frequency component. In this we multiply the highpass filter by a constant and add an offset to the highpass filter to prevent eliminating zero frequency term by filter."
    },
    {
        "id": 237,
        "Question": "Which of the following a transfer function of High frequency emphasis {Hhfe(u, v)} for Hhp(u, v) being the highpass filtered version of image?",
        "Options": [
            "a)\tHhfe(u, v) = 1 – Hhp(u, v)",
            "b)\tHhfe(u, v) = a – Hhp(u, v), a≥0",
            "c)\tHhfe(u, v) = 1 – b Hhp(u, v), a≥0 and b>a",
            "d)\tHhfe(u, v) = a + b Hhp(u, v), a≥0 and b>a"
        ],
        "Answer": "Answer: d\nExplanation:\tThe transfer function of High frequency emphasis is given as:Hhfe(u, v) = a + b Hhp(u, v), a≥0 and b>a."
    },
    {
        "id": 238,
        "Question": "The transfer function of High frequency emphasis is given as: Hhfe(u, v) = a + b Hhp(u, v), for Hhp(u, v) being the highpass filtered version of image,a≥0 and b>a. for certain values of a and b it reduces to High-boost filtering. Which of the following is the required value?",
        "Options": [
            "a)\ta = (A-1) and b = 0,A is some constant",
            "b)\ta = 0 and b = (A-1),A is some constant",
            "c)\ta = 1 and b = 1",
            "d)\ta = (A-1) and b =1,A is some constant"
        ],
        "Answer": "Answer: d\nExplanation:\tThe transfer function of High frequency emphasis is given as: Hhfe(u, v) = a + b Hhp(u, v) and the transfer function for High-boost filtering is Hhb(u, v) = (A-1) + Hhp(u, v), A being some constant. So, for a = (A-1) and b =1, Hhfe(u, v) = Hhb(u, v)."
    },
    {
        "id": 239,
        "Question": "The transfer function of High frequency emphasis is given as: Hhfe(u, v) = a + b Hhp(u, v), for Hhp(u, v) being the highpass filtered version of image,a≥0 and b>a. What happens when b increases past 1?",
        "Options": [
            "a)\tThe high frequency are emphasized",
            "b)\tThe low frequency are emphasized",
            "c)\tAll frequency are emphasized",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tThe transfer function of High frequency emphasis is given as: Hhfe(u, v) = a + b Hhp(u, v), for Hhp(u, v) being the highpass filtered version of image,a≥0 and b>a. When b increases past 1, the high frequency are emphasized."
    },
    {
        "id": 240,
        "Question": "The transfer function of High frequency emphasis is given as: Hhfe(u, v) = a + b Hhp(u, v), for Hhp(u, v) being the highpass filtered version of image,a≥0 and b>a. When b increases past 1 the filtering process is specifically termed as__________",
        "Options": [
            "a)\tUnsharp masking",
            "b)\tHigh-boost filtering",
            "c)\tEmphasized filtering",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tThe transfer function of High frequency emphasis is given as: Hhfe(u, v) = a + b Hhp(u, v), for Hhp(u, v) being the highpass filtered version of image,a≥0 and b>a. When b increases past 1, the high frequency are emphasized and so the filtering process is better known as Emphasized filtering."
    },
    {
        "id": 241,
        "Question": "1.\tWhich of the following fact is true for a image?",
        "Options": [
            "a)\tAn image is the addition of illumination and reflectance component",
            "b)\tAn image is the subtraction of illumination component from reflectance component",
            "c)\tAn image is the subtraction of reflectance component from illumination component",
            "d)\tAn image is the multiplication of illumination and reflectance component"
        ],
        "Answer": "Answer: d\nExplanation:\tAn image is expressed as the multiplication of illumination and reflectance component."
    },
    {
        "id": 242,
        "Question": "3.\tIn Homomorphic filtering which of the following operations is used to convert input image to discrete Fourier transformed function?",
        "Options": [
            "a)\tLogarithmic operation",
            "b)\tExponential operation",
            "c)\tNegative transformation",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tFor an image is expressed as the multiplication of illumination and reflectance component i.e. f(x, y)= i(x, y) * r(x, y), the equation can’t be used directly to operate separately on the frequency component of illumination and reflectance because the Fourier transform of the product of two function is not separable."
    },
    {
        "id": 243,
        "Question": "4.\tA class of system that achieves the separation of illumination and reflectance component of an image is termed as __________",
        "Options": [
            "a)\tBase class system",
            "b)\tHomomorphic system",
            "c)\tBase separation system",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tFor an image is expressed as the multiplication of illumination and reflectance component i.e. f(x, y) = i(x, y) * r(x, y), the equation can’t be used directly to operate separately on the frequency component of illumination and reflectance because the Fourier transform of the product of two function is not separable. So, the logarithmic operation is used.I{z(x,y)}=I{ln⁡(f(x,y)) }=I{ln⁡(i(x,y)) }+I{ln⁡(r(x,y))}."
    },
    {
        "id": 244,
        "Question": "5.\tWhich of the following image component is characterized by a slow spatial variation?",
        "Options": [
            "a)\tIllumination component",
            "b)\tReflectance component",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tHomomorphic system is a class of system that achieves the separation of illumination and reflectance component of an image."
    },
    {
        "id": 245,
        "Question": "6.\tWhich of the following image component varies abruptly particularly at the junction of dissimilar objects?",
        "Options": [
            "a)\tIllumination component",
            "b)\tReflectance component",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tThe illumination component of an image is characterized by a slow spatial variation."
    },
    {
        "id": 246,
        "Question": "7.\tThe reflectance component of an image varies abruptly particularly at the junction of dissimilar objects. The characteristic lead to associate illumination with __________",
        "Options": [
            "a)\tThe low frequency of Fourier transform of logarithm of the image",
            "b)\tThe high frequency of Fourier transform of logarithm of the image",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tThe reflectance component of an image varies abruptly particularly at the junction of dissimilar objects."
    },
    {
        "id": 247,
        "Question": "8.\tThe illumination component of an image is characterized by a slow spatial variation. The characteristic lead to associate illumination with __________",
        "Options": [
            "a)\tThe low frequency of Fourier transform of logarithm of the image",
            "b)\tThe high frequency of Fourier transform of logarithm of the image",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tThe reflectance component of an image varies abruptly, so, is associated with the high frequency of Fourier transform of logarithm of the image."
    },
    {
        "id": 248,
        "Question": "9.\tIf the contribution made by illumination component of image is decreased and the contribution of reflectance component is amplified, what will be the net result?",
        "Options": [
            "a)\tDynamic range compression",
            "b)\tContrast enhancement",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tThe illumination component of an image is characterized by a slow spatial variation, so, is associated with the low frequency of Fourier transform of logarithm of the image."
    },
    {
        "id": 249,
        "Question": "How is negative of an image obtained with intensity levels [0,L-1] with “r” and “s” being pixel values?",
        "Options": [
            "a) s = L – 1 + r",
            "b) s = L – 1 – r",
            "c) s = L + 1 + r",
            "d) s = L + 1 + r"
        ],
        "Answer": "Answer: b\nExplanation: The negative is obtained using s = L – 1 + r."
    },
    {
        "id": 250,
        "Question": "The general form of log transformations is ____________________",
        "Options": [
            "a) s = c.log(1 + r)",
            "b) s = c+log(1 + r)",
            "c) s = c.log(1 – r)",
            "d) s = c-log(1 – r)"
        ],
        "Answer": "Answer: a\nExplanation: s = c.log(1 + r) is the log transformation."
    },
    {
        "id": 251,
        "Question": "Power-law transformations has the basic form of ________________ where c and ∆ are constants.",
        "Options": [
            "a) s = c + r∆",
            "b) s = c – r∆",
            "c) s = c * r∆",
            "d) s = c / r.∆"
        ],
        "Answer": "Answer: c\nExplanation: s = c * r∆ is called the Power-law transformation."
    },
    {
        "id": 252,
        "Question": "For what value of the output must the Power-law transformation account for offset?",
        "Options": [
            "a) No offset needed",
            "b) All values",
            "c) One",
            "d) Zero"
        ],
        "Answer": "Answer: d\nExplanation: When the output is Zero, an offset is necessary."
    },
    {
        "id": 253,
        "Question": "What is Gamma Correction?",
        "Options": [
            "a) A Power-law response phenomenon",
            "b) Inverted Intensity curve",
            "c) Light brightness variation",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: a\nExplanation: The exponent in Power-law is called gamma and the process used to correct the response of Power-law transformation is called Gamma Correction."
    },
    {
        "id": 254,
        "Question": "Which process expands the range of intensity levels in an image so that it spans the full intensity range of the display?",
        "Options": [
            "a) Shading correction",
            "b) Contrast sketching",
            "c) Gamma correction",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: b\nExplanation: Contrast sketching is the process used to expand intensity levels in an image."
    },
    {
        "id": 255,
        "Question": "Highlighting a specific range of intensities of an image is called _______________",
        "Options": [
            "a) Intensity Matching",
            "b) Intensity Highlighting",
            "c) Intensity Slicing",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: c\nExplanation: Highlighting a specific range of intensities of an image is called Intensity Slicing."
    },
    {
        "id": 256,
        "Question": "Highlighting the contribution made to total image by specific bits instead of highlighting intensity-level changes is called ____________________",
        "Options": [
            "a) Intensity Highlighting",
            "b) Byte-Slicing",
            "c) Bit-plane slicing",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: c\nExplanation: It is called Bit-plane slicing."
    },
    {
        "id": 257,
        "Question": "Which of the following involves reversing the intensity levels of an image?",
        "Options": [
            "a) Log Transformations",
            "b) Piecewise Linear Transformations",
            "c) Image Negatives",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: c\nExplanation: Image negatives use reversing intensity levels."
    },
    {
        "id": 258,
        "Question": "Piecewise Linear Transformation function involves which of the following?",
        "Options": [
            "a) Bit-plane slicing",
            "b) Intensity level slicing",
            "c) Contrast stretching",
            "d) All of the Mentioned"
        ],
        "Answer": "Answer: d\nExplanation: Piecewise Linear Transformation function involves all the mentioned functions."
    },
    {
        "id": 259,
        "Question": "What is the set generated using infinite-value membership functions, called?",
        "Options": [
            "a) Crisp set",
            "b) Boolean set",
            "c) Fuzzy set",
            "d) All of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation: It is called fuzzy set."
    },
    {
        "id": 260,
        "Question": "Which is the set, whose membership only can be true or false, in bi-values Boolean logic?",
        "Options": [
            "a) Boolean set",
            "b) Crisp set",
            "c) Null set",
            "d) None of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation: The so called Crisp set is the one in which membership only can be true or false, in bi-values Boolean logic."
    },
    {
        "id": 261,
        "Question": "If Z is a set of elements with a generic element z, i.e. Z = {z}, then this set is called _____________",
        "Options": [
            "a) Universe set",
            "b) Universe of discourse",
            "c) Derived set",
            "d) None of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation: It is called the universe of discourse."
    },
    {
        "id": 262,
        "Question": "A fuzzy set ‘A’ in Z is characterized by a ____________ that associates with element of Z, a real number in the interval [0, 1].",
        "Options": [
            "a) Grade of membership",
            "b) Generic element",
            "c) Membership function",
            "d) None of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation: A fuzzy set is characterized by a membership function."
    },
    {
        "id": 263,
        "Question": "A fuzzy set is ________ if and only if membership function is identically zero in Z.",
        "Options": [
            "a) Empty",
            "b) Subset",
            "c) Complement",
            "d) None of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation: It is called an Empty set."
    },
    {
        "id": 264,
        "Question": "Which of the following is a type of Membership function?",
        "Options": [
            "a) Triangular",
            "b) Trapezoidal",
            "c) Sigma",
            "d) All of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation: All of them are types of Membership functions."
    },
    {
        "id": 265,
        "Question": "Which of the following is not a type of Membership function?",
        "Options": [
            "a) S-shape",
            "b) Bell shape",
            "c) Truncated Gaussian",
            "d) None of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation: All of the mentioned above are types of Membership functions."
    },
    {
        "id": 266,
        "Question": "Using IF-THEN rule to create the output of fuzzy system is called _______________.",
        "Options": [
            "a) Inference",
            "b) Implication",
            "c) Both the mentioned",
            "d) None of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation: It is called Inference or Implication."
    },
    {
        "id": 267,
        "Question": "What is the independent variable of fuzzy output?",
        "Options": [
            "a) Maturity",
            "b) Membership",
            "c) Generic Element",
            "d) None of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation: Maturity is the independent variable of fuzzy output."
    },
    {
        "id": 268,
        "Question": "Which of the following is not a principle step in fuzzy technique?",
        "Options": [
            "a) Fuzzify input",
            "b) Apply implication method",
            "c) Defuzzify final output",
            "d) None of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation: All of the mentioned above are key steps in fuzzy technique."
    },
    {
        "id": 269,
        "Question": "Which gray-level transformation increase the dynamic range of gray-level in the image?",
        "Options": [
            "a)\tPower-law transformations",
            "b)\tNegative transformations",
            "c)\tContrast stretching",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tIncreasing the dynamic range of gray-levels in the image is the basic idea behind contrast stretching."
    },
    {
        "id": 270,
        "Question": "When is the contrast stretching transformation a linear function, for r and s as gray-value of image before and after processing respectively?",
        "Options": [
            "a)\tr1 = s1 and r2 = s2",
            "b)\tr1 = r2, s1 = 0 and s2 = L – 1, L is the max gray value allowed",
            "c)\tr1 = 1 and r2 = 0",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tIf r1 = s1 and r2 = s2 the contrast stretching transformation is a linear function."
    },
    {
        "id": 271,
        "Question": "When is the contrast stretching transformation a thresholding function, for r and s as gray-value of image before and after processing respectively?",
        "Options": [
            "a)\tr1 = s1 and r2 = s2",
            "b)\tr1 = r2, s1 = 0 and s2 = L – 1, L is the max gray value allowed",
            "c)\tr1 = 1 and r2 = 0",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tIf r1 = r2, s1 = 0 and s2 = L – 1, the contrast stretching transformation is a thresholding function."
    },
    {
        "id": 272,
        "Question": "What condition prevents the intensity artifacts to be created while processing with contrast stretching, if r and s are gray-values of image before and after processing respectively?",
        "Options": [
            "a)\tr1 = s1 and r2 = s2",
            "b)\tr1 = r2, s1 = 0 and s2 = L – 1, L is the max gray value allowed",
            "c)\tr1 = 1 and r2 = 0",
            "d)\tr1 ≤ r2 and s1 ≤ s2"
        ],
        "Answer": "Answer: d\nExplanation:\tWhile processing through contrast stretching, if r1 ≤ r2 and s1 ≤ s2 is maintained, the function remains single valued and so monotonically increasing. This helps in the prevention of creation of intensity artifacts."
    },
    {
        "id": 273,
        "Question": "A contrast stretching result been obtained by setting (r1, s1) = (rmin, 0) and (r2, s2) = (rmax, L – 1), where, r and s are gray-values of image before and after processing respectively, L is the max gray value allowed and rmax and rmin are maximum and minimum gray-values in image respectively. What should we term the transformation function if r1 = r2 = m, some mean gray-value.",
        "Options": [
            "a)\tLinear function",
            "b)\tThresholding function",
            "c)\tIntermediate function",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tFrom (r1, s1) = (rmin, 0) and (r2, s2) = (rmax, L – 1), we have s1 = 0 and s2 = L – 1 and if r1 = r2 = m is set then the result becomes r1 = r2, s1 = 0 and s2 = L – 1, i.e. a thresholding function."
    },
    {
        "id": 274,
        "Question": "A specific range of gray-levels highlighting is the basic idea of __________",
        "Options": [
            "a)\tContrast stretching",
            "b)\tBit –plane slicing",
            "c)\tThresholding",
            "d)\tGray-level slicing"
        ],
        "Answer": "Answer: d\nExplanation:\tgray-level slicing is being done by two approach: One approach is to give all gray level of a specific range high value and a low value to all other gray levels.\nSecond approach is to brighten the pixels gray-value of interest and preserve the background.\nI.e. in both highlighting of a specific range of gray-level is been done."
    },
    {
        "id": 275,
        "Question": "What is/are the approach(s) of the gray-level slicing?",
        "Options": [
            "a)\tTo give all gray level of a specific range high value and a low value to all other gray levels",
            "b)\tTo brighten the pixels gray-value of interest and preserve the background",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tThere are basically two approach of gray-level slicing:\nOne approach is to give all gray level of a specific range high value and a low value to all other gray levels.\nSecond approach is to brighten the pixels gray-value of interest and preserve the background."
    },
    {
        "id": 276,
        "Question": "Which of the following transform produces a binary image after processing?",
        "Options": [
            "a)\tContrast stretching",
            "b)\tGray-level slicing",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tThe approach of gray-level slicing “to give all gray level of a specific range high value and a low value to all other gray levels” produces a binary image.\nOne of the transformation in Contrast stretching darkens the value of r (input image gray-level) below m (some predefined gray-value) and brightens the value of r above m, giving a binary image as result."
    },
    {
        "id": 277,
        "Question": "Specific bit contribution in the image highlighting is the basic idea of __________",
        "Options": [
            "a)\tContrast stretching",
            "b)\tBit –plane slicing",
            "c)\tThresholding",
            "d)\tGray-level slicing"
        ],
        "Answer": "Answer: b\nExplanation:\tBit-plane slicing highlights the contribution of specific bits made to total image, instead of highlighting a specific gray-level range."
    },
    {
        "id": 278,
        "Question": "In bit-plane slicing if an image is represented by 8 bits and is composed of eight 1-bit plane, with plane 0 showing least significant bit and plane 7 showing most significant bit. Then, which plane(s) contain the majority of visually significant data.",
        "Options": [
            "a)\tPlane 4, 5, 6, 7",
            "b)\tPlane 0, 1, 2, 3",
            "c)\tPlane 0",
            "d)\tPlane 2, 3, 4, 5"
        ],
        "Answer": "Answer: a\nExplanation:\tIn bit-plane slicing, for the given data, the higher-ordered bits (mostly top four) contains most of the data visually signified."
    },
    {
        "id": 279,
        "Question": "Which of the following helps to obtain the number of bits to be used to quantize each pixel.",
        "Options": [
            "a)\tGray-level slicing",
            "b)\tContrast stretching",
            "c)\tContouring",
            "d)\tBit-plane slicing"
        ],
        "Answer": "Answer: d\nExplanation:\tBits-plane slicing helps in obtaining the importance played by each bit in the image by separating the image into bit-planes. "
    },
    {
        "id": 280,
        "Question": "1.\tIf the Gaussian filter is expressed as H(u, v) = e(-D2 (u,v)/2D 02),where D(u, v) is the distance from point(u, v), D0  is the distance defining cutoff frequency, then for what value of D(u, v) the filter is down to 0.607 of its maximum value?",
        "Options": [
            "a)\tD(u, v) = D0",
            "b)\tD(u, v) = D02",
            "c)\tD(u, v) = D03",
            "d)\tD(u, v) = 0"
        ],
        "Answer": "Answer: a\nExplanation:\tFor the given Gaussian filter of 2-D image, the value D(u, v) = D0  gives the filter a down to 0.607 of its maximum value."
    },
    {
        "id": 281,
        "Question": "3.\tIn general, which of the following assures of no ringing in the output?",
        "Options": [
            "a)\tGaussian Lowpass Filter",
            "b)\tIdeal Lowpass Filter",
            "c)\tButterworth Lowpass Filter",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tFor the same value of cutoff frequency, the GLPF did not produce as much smoothing as the BLPF of order 2, because the profile of GLPF is not as tight as BLPF of order 2."
    },
    {
        "id": 282,
        "Question": "4.\tThe lowpass filtering process can be applied in which of the following area(s)?",
        "Options": [
            "a)\tThe field of machine perception, with application of character recognition",
            "b)\tIn field of printing and publishing industry",
            "c)\tIn field of processing satellite and aerial images",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tUsing Gaussian Lowpass Filter no ringing is assured, but Ideal Lowpass Filter and Butterworth Lowpass Filter of order 2and more produces significant ringing."
    },
    {
        "id": 283,
        "Question": "5.\tThe edges and other abrupt changes in gray-level of an image are associated with_________",
        "Options": [
            "a)\tHigh frequency components",
            "b)\tLow frequency components",
            "c)\tEdges with high frequency and other abrupt changes in gray-level with low frequency components",
            "d)\tEdges with low frequency and other abrupt changes in gray-level with high frequency components"
        ],
        "Answer": "Answer: d\nExplanation:\tIn case of broken characters recognition system, LPF is used. LPF is used as preprocessing system in printing and publishing industry, and in case of remote sensed images LPF is used to blur out as much detail as possible leaving the large feature recognizable."
    },
    {
        "id": 284,
        "Question": "6.\tA type of Image is called as VHRR image. What is the definition of VHRR image?",
        "Options": [
            "a)\tVery High Range Resolution image",
            "b)\tVery High Resolution Range image",
            "c)\tVery High Resolution Radiometer image",
            "d)\tVery High Range Radiometer Image"
        ],
        "Answer": "Answer: a\nExplanation:\tHigh frequency components are related with the edges and other abrupt changes in gray-level of an image."
    },
    {
        "id": 285,
        "Question": "7.\tThe Image sharpening in frequency domain can be achieved by which of the following method(s)?",
        "Options": [
            "a)\tAttenuating the high frequency components",
            "b)\tAttenuating the low-frequency components",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tA VHRR image is a Very High Resolution Radiometer Image."
    },
    {
        "id": 286,
        "Question": "8.\tThe function of filters in Image sharpening in frequency domain is to perform reverse operation of which of the following Lowpass filter?",
        "Options": [
            "a)\tGaussian Lowpass filter",
            "b)\tButterworth Lowpass filter",
            "c)\tIdeal Lowpass filter",
            "d)\tNone of the Mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tThe Image sharpening in frequency domain is achieved by attenuating the low-frequency components without disturbing the high-frequency components."
    },
    {
        "id": 287,
        "Question": "9.\tIf D0 is the cutoff distance measured from origin of frequency rectangle and D(u, v) is the distance from point(u, v). Then what value does an Ideal Highpass filter will give if D(u, v) ≤ D0 andifD(u, v) >D0?",
        "Options": [
            "a)\t0 and 1 respectively",
            "b)\t1 and 0 respectively",
            "c)\t1 in both case",
            "d)\t0 in both case"
        ],
        "Answer": "Answer: c\nExplanation:\tThe function of filters in Image sharpening in frequency domain is to perform precisely reverse operation of Ideal Lowpass filter.\nThe transfer function of Highpass filter is obtained by relation: Hhp(u, v) = 1 – Hlp(u, v), where Hlp(u, v) is transfer function of corresponding lowpass filter."
    },
    {
        "id": 288,
        "Question": "10.\tWhat is the relation of the frequencies to a circle of radius D0, where D0 is the cutoff distance measured from origin of frequency rectangle, for an Ideal Highpass filter?",
        "Options": [
            "a)\tIHPF sets all frequencies inside circle to zero",
            "b)\tIHPF allows all frequencies, without attenuating, outside the circle",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tUnlike Ideal lowpass filter, an Ideal highpass filter attenuates the low-frequency components and so gives 0 for D(u, v) ≤ D0 and 1 for D(u, v) >D0."
    },
    {
        "id": 289,
        "Question": "11.\tWhich of the following is the transfer function of the Butterworth Highpass Filter, of order n, D0 is the cutoff distance measured from origin of frequency rectangle and D(u, v) is the distance from point(u, v)?",
        "Options": [
            "a)\t<img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11.png\" alt=\"digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11\" width=\"153\" height=\"30\" class=\"alignnone size-full wp-image-148774\" srcset=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11.png 153w, https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11-150x30.png 150w\" sizes=\"(max-width: 153px) 100vw, 153px\" />",
            "b)\t<img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11a.png\" alt=\"digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11a\" width=\"191\" height=\"49\" class=\"alignnone size-full wp-image-148775\" />",
            "c)\t<img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11b.png\" alt=\"digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11b\" width=\"171\" height=\"26\" class=\"alignnone size-full wp-image-148776\" />",
            "d)\tnone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tAn Ideal high pass filter gives 0 for D(u, v) ≤ D0 and 1 for D(u, v) >D0."
    },
    {
        "id": 290,
        "Question": "12.\tWhich of the following is the transfer function of the Ideal Highpass Filter? Given D0 is the cutoff distance measured from origin of frequency rectangle and D(u, v) is the distance from point(u, v).",
        "Options": [
            "a)\t<img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11.png\" alt=\"digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11\" width=\"153\" height=\"30\" class=\"alignnone size-full wp-image-148774\" srcset=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11.png 153w, https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11-150x30.png 150w\" sizes=\"(max-width: 153px) 100vw, 153px\" />",
            "b)\t<img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11a.png\" alt=\"digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11a\" width=\"191\" height=\"49\" class=\"alignnone size-full wp-image-148775\" />",
            "c)\t<img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11b.png\" alt=\"digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11b\" width=\"171\" height=\"26\" class=\"alignnone size-full wp-image-148776\" />",
            "d)\tnone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tThe transfer function of Butterworth highpass filter of order n, D0 is the cutoff distance measured from origin of frequency rectangle and D(u, v) is the distance from point(u, v) is given by:<img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11.png\" alt=\"digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11\" width=\"153\" height=\"30\" class=\"alignnone size-full wp-image-148774\" srcset=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11.png 153w, https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11-150x30.png 150w\" sizes=\"(max-width: 153px) 100vw, 153px\" /> ."
    },
    {
        "id": 291,
        "Question": "13.\tWhich of the following is the transfer function of the Gaussian Highpass Filter? Given D0 is the cutoff distance measured from origin of frequency rectangle and D(u, v) is the distance from point(u, v).",
        "Options": [
            "a)\t<img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11.png\" alt=\"digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11\" width=\"153\" height=\"30\" class=\"alignnone size-full wp-image-148774\" srcset=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11.png 153w, https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11-150x30.png 150w\" sizes=\"(max-width: 153px) 100vw, 153px\" />",
            "b)\t<img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11a.png\" alt=\"digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11a\" width=\"191\" height=\"49\" class=\"alignnone size-full wp-image-148775\" />",
            "c)\t<img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11b.png\" alt=\"digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11b\" width=\"171\" height=\"26\" class=\"alignnone size-full wp-image-148776\" />",
            "d)\tnone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tThe transfer function of Ideal highpass filter, whereD0 is the cutoff distance measured from origin of frequency rectangle and D(u, v) is the distance from point(u, v) is given by: <img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11a.png\" alt=\"digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11a\" width=\"191\" height=\"49\" class=\"alignnone size-full wp-image-148775\" />."
    },
    {
        "id": 292,
        "Question": "14.\tFor a given image having smaller objects, which of the following filter(s), having D0 as the cutoff distance measured from origin of frequency rectangle, would you prefer for a comparably smoother result?",
        "Options": [
            "a)\tIHLF with D0 15",
            "b)\tBHPF with D0 15 and order 2",
            "c)\tGHPF with D0 15 and order 2",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tThe transfer function of Gaussian highpass filter, where D0 is the cutoff distance measured from origin of frequency rectangle and D(u, v) is the distance from point(u, v) is given by: <img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11b.png\" alt=\"digital-image-processing-questions-answers-gaussain-lowpass-frequency-domain-filters-sharpening-q11b\" width=\"171\" height=\"26\" class=\"alignnone size-full wp-image-148776\" />."
    },
    {
        "id": 293,
        "Question": "15.\tWhich of the following statement(s) is true for the given fact that “Applying Highpass filters has an effect on the background of the output image”?",
        "Options": [
            "a)\tThe average background intensity increases to near white",
            "b)\tThe average background intensity reduces to near black",
            "c)\tThe average background intensity changes to a value average of black and white",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tFor the same format as for BHPF, GHPF gives a result comparably smoother than BHPF. However, BHPF performance for filtering smaller object is comparable with IHPF."
    },
    {
        "id": 294,
        "Question": "Which of the following is a receptor in the retina of human eye?",
        "Options": [
            "a) Rods",
            "b) Cones",
            "c) Rods and Cones",
            "d) Neither Rods nor Cones"
        ],
        "Answer": "Answer: c\nExplanation: Rods are long slender receptors while cones are shorter and thicker receptors."
    },
    {
        "id": 295,
        "Question": "How is image formation in the eye different from that in a photographic camera",
        "Options": [
            "a) No difference",
            "b) Variable focal length",
            "c) Varying distance between lens and imaging plane",
            "d) Fixed focal length"
        ],
        "Answer": "Answer: b\nExplanation: Fibers in ciliary body vary shape of the lens thereby varying its focal length."
    },
    {
        "id": 296,
        "Question": "Range of light intensity levels to which the human eye can adapt (in Log of Intensity-mL)",
        "Options": [
            "a) 10-6 to 10-4",
            "b) 104 to 106",
            "c) 10-6 to 104",
            "d) 10-5 to 105"
        ],
        "Answer": "Answer: c\nExplanation: Range of light intensity to which human eye can adapt is enormous\n\t         and about the order 1010 from 10-6 to 104."
    },
    {
        "id": 297,
        "Question": "What is subjective brightness?",
        "Options": [
            "a) Related to intensity",
            "b) Related to brightness",
            "c) Related to image perception",
            "d) Related to image formation"
        ],
        "Answer": "Answer: a\nExplanation: It is the intensity as perceived by the human eye."
    },
    {
        "id": 298,
        "Question": "What is brightness adaptation?",
        "Options": [
            "a) Changing the eye’s overall sensitivity",
            "b) Changing the eye’s imaging ability",
            "c) Adjusting the focal length",
            "d) Transition from scotopic to photopic vision"
        ],
        "Answer": "Answer: a\nExplanation: The human eye a wide dynamic range by changing the eye’s overall sensitivity and this is called brightness adaptation."
    },
    {
        "id": 299,
        "Question": "The inner most membrane of the human eye is",
        "Options": [
            "a) Blind Spot",
            "b) Sclera",
            "c) Choroid",
            "d) Retina"
        ],
        "Answer": "Answer: d\nExplanation: Retina is the innermost membrane of the human eye."
    },
    {
        "id": 300,
        "Question": "What is the function of Iris?",
        "Options": [
            "a) Source of nutrition",
            "b) Detect color",
            "c) Varies focal length",
            "d) Control amount of light"
        ],
        "Answer": "Answer: d\nExplanation: Iris is responsible for controlling the amount of light that enters the human eye."
    },
    {
        "id": 301,
        "Question": "________ serve to a general, overall picture of the field of view.",
        "Options": [
            "a) Cones",
            "b) Rods",
            "c) Retina",
            "d) All of the Mentioned"
        ],
        "Answer": "Answer: b\nExplanation: Rods produce an overall picture of the field of view."
    },
    {
        "id": 302,
        "Question": "Ratio of number of rods to the number of cones is _______",
        "Options": [
            "a) 1:20",
            "b) 1:2",
            "c) 1:1",
            "d) 1:5"
        ],
        "Answer": "Answer: a\nExplanation: No of rods: 6 to 7 million, No of rods: 75 to 150."
    },
    {
        "id": 303,
        "Question": "The absence of receptors is in the retinal area called _____________",
        "Options": [
            "a) Lens",
            "b) Ciliary body",
            "c) Blind spot",
            "d) Fovea"
        ],
        "Answer": "Answer: c\nExplanation: Except the blind spot, receptors are radially distributed."
    },
    {
        "id": 304,
        "Question": "In 4-neighbours of a pixel p, how far are each of the neighbours located from p?",
        "Options": [
            "a) one pixel apart",
            "b) four pixels apart",
            "c) alternating pixels",
            "d) none of the Mentioned"
        ],
        "Answer": "Answer: a\nExplanation: Each pixel is a unit distance apart from the pixel p."
    },
    {
        "id": 305,
        "Question": " If S is a subset of pixels, pixels p and q are said to be ____________ if there exists a path between them consisting of pixels entirely in S.",
        "Options": [
            "a) continuous",
            "b) ambiguous",
            "c) connected",
            "d) none of the Mentioned"
        ],
        "Answer": "Answer: c\nExplanation: Pixels p and q are said to be connected if there exists a path between them consisting of pixels entirely in S."
    },
    {
        "id": 306,
        "Question": "If R is a subset of pixels, we call R a _________ of the image if R is a connected set.",
        "Options": [
            "a) Disjoint",
            "b) Region",
            "c) Closed",
            "d) Adjacent"
        ],
        "Answer": "Answer: b\nExplanation:  R is called a Region of the image."
    },
    {
        "id": 307,
        "Question": "Two regions are said to be ___________ if their union forms a connected set.",
        "Options": [
            "a) Adjacent",
            "b) Disjoint",
            "c) Closed",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: a\nExplanation: The regions are said to be Adjacent to each other."
    },
    {
        "id": 308,
        "Question": "If an image contains K disjoint regions, what does the union of all the regions represent?",
        "Options": [
            "a) Background",
            "b) Foreground",
            "c) Outer Border",
            "d) Inner Border"
        ],
        "Answer": "Answer: b\nExplanation: The union of all regions is called Foreground and its complement is called the Background."
    },
    {
        "id": 309,
        "Question": "For a region R, the set of points that are adjacent to the complement of R is called as ________",
        "Options": [
            "a) Boundary",
            "b) Border",
            "c) Contour",
            "d) All of the Mentioned"
        ],
        "Answer": "Answer: d\nExplanation: The words boundary, border and contour mean the same set."
    },
    {
        "id": 310,
        "Question": "The distance between pixels p and q, the pixels have a distance less than or equal to some value of radius r centred at (x,y) is called :",
        "Options": [
            "a) Euclidean distance",
            "b) City-Block distance",
            "c) Chessboard distance",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: a\nExplanation: Euclidean distance is measured using a radius from a defined centre."
    },
    {
        "id": 311,
        "Question": "The distance between pixels p and q, the pixels have a distance less than or equal to some value of radius r, form a diamond centred at (x,y) is called :",
        "Options": [
            "a) Euclidean distance",
            "b) Chessboard distance",
            "c) City-Block distance",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: c\nExplanation: Formation of a diamond is measured as City-Block distance."
    },
    {
        "id": 312,
        "Question": "The distance between pixels p and q, the pixels have a distance less than or equal to some value of radius r, form a square centred at (x,y) is called :",
        "Options": [
            "a) Euclidean distance",
            "b) Chessboard distance",
            "c) City-Block distance",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: b\nExplanation: Distance measured by forming a square around the centre is called Chessboard distance."
    },
    {
        "id": 313,
        "Question": "Which of the following is NOT is not a type of Adjacency?",
        "Options": [
            "a) 4-Adjacency",
            "b) 8-Adjacency",
            "c) m-Adjacency",
            "d) None of the Mentioned"
        ],
        "Answer": "Answer: d\nExplanation: All the mentioned adjacency types are valid."
    },
    {
        "id": 314,
        "Question": "How many categories does the color image processing is basically divided into?",
        "Options": [
            "a) 4",
            "b) 2",
            "c) 3",
            "d) 5"
        ],
        "Answer": "Answer: b\nExplanation: Color image processing is divided into two major areas: full-color and pseudo-color processing."
    },
    {
        "id": 315,
        "Question": "What are the names of categories of color image processing?",
        "Options": [
            "a) Full-color and pseudo-color processing",
            "b) Half-color and full-color processing",
            "c) Half-color and pseudo-color processing",
            "d) Pseudo-color and Multi-color processing"
        ],
        "Answer": "Answer: a\nExplanation: Color image processing is divided into two major areas: full-color and pseudo-color processing. In the first category, the images are acquired with a full-color sensor like color TV or color scanner. In the second category, there is a problem of assigning a color to a particular monochrome intensity or range of intensities."
    },
    {
        "id": 316,
        "Question": "What are the basic quantities that are used to describe the quality of a chromatic light source?",
        "Options": [
            "a) Radiance, brightness and wavelength",
            "b) Brightness and luminence",
            "c) Radiance, brightness and luminence",
            "d) Luminence and radiance"
        ],
        "Answer": "Answer: c\nExplanation: Three quantities are used to describe the quality of a chromatic light source: radiance, luminance and brightness."
    },
    {
        "id": 317,
        "Question": "What is the quantity that is used to measure the total amount of energy flowing from the light source?",
        "Options": [
            "a) Brightness",
            "b) Intensity",
            "c) Luminence",
            "d) Radiance"
        ],
        "Answer": "Answer: d\nExplanation: Three quantities are used to describe the quality of a chromatic light source: radiance, luminance and brightness. Radiance is used to measure the total amount of energy flows from the light source and is generally measured in watts (W)."
    },
    {
        "id": 318,
        "Question": "What are the characteristics that are used to distinguish one color from the other?",
        "Options": [
            "a) Brightness, Hue and Saturation",
            "b) Hue, Brightness and Intensity",
            "c) Saturation, Hue",
            "d) Brightness, Saturation and Intensity"
        ],
        "Answer": "Answer: a\nExplanation: The characteristics generally used to distinguish one color from another are brightness, hue and saturation. Brightness embodies the chromatic notion of intensity. Hue is an attribute associated with dominant wavelength in a mixture of light waves. Saturation refers to the relative purity or the amount of white light mixed with a hue."
    },
    {
        "id": 319,
        "Question": "What are the characteristics that are taken together in chromaticity?",
        "Options": [
            "a) Saturation and Brightness",
            "b) Hue and Saturation",
            "c) Hue and Brightness",
            "d) Saturation, Hue and Brightness"
        ],
        "Answer": "Answer: b\nExplanation: Hue and saturation are taken together are called chromaticity and therefore, a color may be characterized by its brightness and chromaticity."
    },
    {
        "id": 320,
        "Question": "Which of the following represent the correct equations for trichromatic coefficients?",
        "Options": [
            "a) x=X/(X+Y+Z), y=Y/(X+Y+Z), z=Z/(X+Y+Z)",
            "b) x=(Y+Z)/(X+Y+Z), y=(X+Z)/(X+Y+Z), z=(X+Y)/(X+Y+Z)",
            "c) x=X/(X-Y+Z), y=Y/(X-Y+Z), z=Z/(X-Y+Z)",
            "d) x=(-X)/(X+Y+Z), y=(-Y)/(X+Y+Z), z=(-Z)/(X+Y+Z)"
        ],
        "Answer": "Answer: a\nExplanation: Tri-stimulus values are the amounts of red, green and blue needed to form any particular color and they are denoted as X,Y and Z respectively. A colors the specified by its trichromatic coefficients x, y & z: =X/(X+Y+Z), y=Y/(X+Y+Z), z=Z/(X+Y+Z)."
    },
    {
        "id": 321,
        "Question": "What do you mean by tri-stimulus values?",
        "Options": [
            "a) It is the amount of red, green and yellow needed to form any particular color",
            "b) It is the amount of red, green and indigo needed to form any particular color",
            "c) It is the amount of red, yellow and blue needed to form any particular color",
            "d) It is the amount of red, green and blue needed to form any particular color"
        ],
        "Answer": "Answer: d\nExplanation: The amounts of red, green and blue needed to form any particular color are called the tri-stimulus values and are denoted by X, Y and Z respectively. A color is then specified by its trichromatic coefficients, whose equations are formed from tri-stimulus values."
    },
    {
        "id": 322,
        "Question": "What is the value obtained by the sum of the three trichromatic coefficients?",
        "Options": [
            "a) 0",
            "b)-1",
            "c) 1",
            "d) Null"
        ],
        "Answer": "Answer: c\nExplanation: From the equations: x=X/(X+Y+Z), y=Y/(X+Y+Z), z=Z/(X+Y+Z) it is the noted that sum of the coefficients is x+y+z≅1."
    },
    {
        "id": 323,
        "Question": "What is the name of area of the triangle in C.I E chromatic diagram that shows a typical range of colors produced by RGB monitors?",
        "Options": [
            "a) Color gamut",
            "b) Tricolor",
            "c) Color game",
            "d) Chromatic colors"
        ],
        "Answer": "Answer: a\nExplanation: The triangle in C.I.E chromatic diagram shows a typical range of colors called the color gamut produced by RGB monitors. The irregular region inside the triangle is representative of the color gamut of today’s high-quality color printing devices."
    },
    {
        "id": 324,
        "Question": "Color model is also named as (another name):",
        "Options": [
            "a) Color space",
            "b) Color gap",
            "c) Color space & color system",
            "d) Color system"
        ],
        "Answer": "Answer: c\nExplanation: A color model is also called as color space or color system .Its purpose is to facilitate the specification of colors in some standard, generally accepted way."
    },
    {
        "id": 325,
        "Question": "What do you mean by the term pixel depth?",
        "Options": [
            "a) It is the number of bits used to represent each pixel in RGB space",
            "b) It is the number of bytes used to represent each pixel in RGB space",
            "c) It is the number of units used to represent each pixel in RGB space",
            "d) It is the number of mm used to represent each pixel in RGB space"
        ],
        "Answer": "Answer: a\nExplanation: Images are represented in the RGB color model consist of three component images one for each primary color. When fed into RGB monitor, these three images combine on the phosphor screen to produce a composite color image. The number of bits used to represent each pixel in RGB space is called the pixel depth."
    },
    {
        "id": 326,
        "Question": "How many bit RGB color image is represented by full-color image?",
        "Options": [
            "a) 32-bit RGB color image",
            "b) 24-bit RGB color image",
            "c) 16-bit RGB color image",
            "d) 8-bit RGB color image"
        ],
        "Answer": "Answer: b\nExplanation: The term full-color image is used often to denote a 24-bit RGB color image. The total number of colors in a 24-bit RGB color image is (28)3=16777216."
    },
    {
        "id": 327,
        "Question": "What is the equation used to obtain S component of each RGB pixel in RGB color format?",
        "Options": [
            "a) S=1+3/(R+G+B) [min⁡(R,G,B)].",
            "b) S=1+3/(R+G+B) [max⁡(R,G,B)].",
            "c) S=1-3/(R+G+B) [max⁡(R,G,B)].",
            "d) S=1-3/(R+G+B) [min⁡(R,G,B)]."
        ],
        "Answer": "Answer: d\nExplanation: If an image is given in RGB format then the saturation component is obtained by the equation."
    },
    {
        "id": 328,
        "Question": "What is the equation used to obtain I(Intensity) component of each RGB pixel in RGB color format?",
        "Options": [
            "a) I=1/2(R+G+B)",
            "b) I=1/3(R+G+B)",
            "c) I=1/3(R-G-B)",
            "d) I=1/3(R-G+B)"
        ],
        "Answer": "Answer: b\nExplanation: If an image is given in RGB format then the intensity (I) component is obtained by the equation, I=1/3 (R+G+B)."
    },
    {
        "id": 329,
        "Question": "What is the equation used for obtaining R value in terms of HSI components?",
        "Options": [
            "a) R=I[1-(S cos⁡H)/cos⁡(60°-H) ].",
            "b) R=I[1+(S cos⁡H)/cos(120°-H)].",
            "c) R=I[1+(S cos⁡H)/cos⁡(60°-H) ].",
            "d) R=I[1+(S cos⁡H)/cos(30°-H) ]."
        ],
        "Answer": "Answer: c\nExplanation: Given values of HSI in the interval [0, 1], the R value in the RGB components is given by the equation: "
    },
    {
        "id": 330,
        "Question": "What is the equation used for calculating B value in terms of HSI components?",
        "Options": [
            "a) B=I(1+S)",
            "b) B=S(1-I)",
            "c) B=S(1+I)",
            "d) B=I(1-S)"
        ],
        "Answer": "Answer: d\nExplanation: Given values of HSI in the interval [0, 1], the B value in the RGB components is given by the equation:  B=I(1-S)."
    },
    {
        "id": 331,
        "Question": "What is the equation used for calculating G value in terms of HSI components?",
        "Options": [
            "a) G=3I-(R+B)",
            "b) G=3I+(R+B)",
            "c) G=3I-(R-B)",
            "d) G=2I-(R+B)"
        ],
        "Answer": "Answer: a\nExplanation: Given values of HSI in the interval [0, 1], the B value in the RGB components is given by the equation: G=3I-(R+B)."
    },
    {
        "id": 332,
        "Question": "Which of the following color models are used for color printing?",
        "Options": [
            "a) RGB",
            "b) CMY",
            "c) CMYK",
            "d) CMY and CMYK"
        ],
        "Answer": "Answer: d\nExplanation: The hardware oriented models which are prominently used in the color printing process are CMY (cyan, magenta and yellow) and CMYK (cyan, magenta, yellow and black)."
    },
    {
        "id": 333,
        "Question": "What does the total number of pixels in the region defines?",
        "Options": [
            "a) Perimeter",
            "b) Area",
            "c) Intensity",
            "d) Brightness"
        ],
        "Answer": "Answer: b\nExplanation: The area of a region is defined by the total number of pixels in the region. The perimeter is given the number of pixels along the length of the boundary of the region."
    },
    {
        "id": 334,
        "Question": "What is the unit of compactness of a region?",
        "Options": [
            "a) Meter",
            "b) Meter2",
            "c) No units",
            "d) Meter-1"
        ],
        "Answer": "Answer: c\nExplanation: The compactness of a region is defined as (perimeter)2/area. Thus, the compactness of a region is a dimensionless quantity."
    },
    {
        "id": 335,
        "Question": "For which of the following regions, compactness is minimal?",
        "Options": [
            "a) Rectangle",
            "b) Square",
            "c) Irregular",
            "d) Disk"
        ],
        "Answer": "Answer: d\nExplanation: We know that, compactness of a region is defined as (perimeter)2/area. Thus, disk shaped region has a minimal value of this ratio and hence the minimal compactness."
    },
    {
        "id": 336,
        "Question": "Which of the following measures are not used to describe a region?",
        "Options": [
            "a) Mean and median of grey values",
            "b) Minimum and maximum of grey values",
            "c) Number of pixels alone",
            "d) Number of pixels above and below mean"
        ],
        "Answer": "Answer: a\nExplanation: With the exception of errors introduced by the rotation of the digital image, we can state that compactness of a region is insensitive to the orientation of the image."
    },
    {
        "id": 337,
        "Question": "What is the study of properties of a figure that are unaffected by any deformation?",
        "Options": [
            "a) Topology",
            "b) Geography",
            "c) Statistics",
            "d) Deformation"
        ],
        "Answer": "Answer: c\nExplanation: Some of the measures which are used to describe a region are mean and median of grey values, minimum and maximum of grey values and number of pixels above and below mean. The area of the region, i.e., the total number of pixels in the region cannot alone describe the region."
    },
    {
        "id": 338,
        "Question": "On which of the following operation of an image, the topology of the region changes?",
        "Options": [
            "a)  Stretching",
            "b) Rotation",
            "c) Folding",
            "d) Change in distance measure"
        ],
        "Answer": "Answer: b\nExplanation: One of the regional descriptor is normalized area. It can be quite useful to extract information from the image. In satellite images of earth, the data can be refined by normalized it with respect to land mass per region."
    },
    {
        "id": 339,
        "Question": "What is the Euler number of a region with polygonal network containing V,Q and F as the number of vertices, edges and faces respectively?",
        "Options": [
            "a) V+Q+F",
            "b) V-Q+F",
            "c) V+Q-F",
            "d) V-Q-F"
        ],
        "Answer": "Answer: a\nExplanation: We can define topology as the study of properties of a figure that are unaffected by any deformation, as long as there is no joining or tearing of the figure. We use topological properties in the region description."
    },
    {
        "id": 340,
        "Question": "The texture of the region provides measure of which of the following properties?",
        "Options": [
            "a) Smoothness alone",
            "b) Coarseness alone",
            "c) Regularity alone",
            "d) Smoothness, coarseness and regularity"
        ],
        "Answer": "Answer: c\nExplanation: If a topological descriptor is defined by the number of holes in an image, then the number of holes will not vary if the image is stretched or rotated. The number of holes in the region will change only if the image is torn or folded."
    },
    {
        "id": 341,
        "Question": "Which of the following techniques is based on the Fourier transform?",
        "Options": [
            "a) Structural",
            "b) Spectral",
            "c) Statistical",
            "d) Topological"
        ],
        "Answer": "Answer: a\nExplanation: We know that, as stretching affects distance, topological properties do not depend on the notion of distance or any properties implicitly based on the concept of distance measures."
    },
    {
        "id": 342,
        "Question": "Which of the following of a boundary is defined as the line perpendicular to the major axis?",
        "Options": [
            "a) Equilateral axis",
            "b) Equidistant axis",
            "c) Minor axis",
            "d) Median axis"
        ],
        "Answer": "Answer: a\nExplanation: The length of a boundary is one of the simple boundary descriptor. The length of the boundary is approximately given by the number of pixels along that boundary."
    },
    {
        "id": 343,
        "Question": "Which of the following is the useful descriptor of a boundary, whose value is given by the ratio of length of the major axis to the minor axis?",
        "Options": [
            "a) Radius",
            "b) Perimeter",
            "c) Area",
            "d) Eccentricity"
        ],
        "Answer": "Answer: c\nExplanation: The minor axis of a boundary is defined as the line perpendicular to the major axis and of such length that a box passing through the outer four points of intersection of the boundary with the two axes completely encloses the boundary."
    },
    {
        "id": 344,
        "Question": "The term, Curvature is defined as:",
        "Options": [
            "a) Rate of change of area",
            "b) Rate of change of slope",
            "c) Slope",
            "d) Rate of change of diameter"
        ],
        "Answer": "Answer: d\nExplanation: Eccentricity, which is the ratio of major axis to the minor axis which is one of the important parameter that is used to describe a boundary."
    },
    {
        "id": 345,
        "Question": "If the boundary is traversed in the clockwise direction, a vertex point ‘p’ is said to be a part of the convex segment if the rate of change of slope at ‘p’ is:",
        "Options": [
            "a) Negative",
            "b) Zero",
            "c) Non negative",
            "d) Cannot be determined"
        ],
        "Answer": "Answer: b\nExplanation: Curvature of a boundary is defined as the rate of change of slope. In general, as the boundaries tend to be locally ragged, it is difficult to obtain reliable measures of curvature at a point on a digital boundary."
    },
    {
        "id": 346,
        "Question": "Based on the 4-directional code, the first difference of smallest magnitude is called as:",
        "Options": [
            "a) Shape number",
            "b) Chain number",
            "c) Difference",
            "d) Difference number"
        ],
        "Answer": "Answer: c\nExplanation: If the boundary is traversed in the clockwise direction and the rate of change of slope at the vertex point is non negative, then that point is said to be in the convex segment."
    },
    {
        "id": 347,
        "Question": "The order of shape number for a closed boundary is:",
        "Options": [
            "a) Odd",
            "b) Even",
            "c) 1",
            "d) Any positive value"
        ],
        "Answer": "Answer: b\nExplanation: In general, a point ‘p’ is said to be on the straight line segment if the change of slope is less than 100 and said to be at the corner point if the change exceeds 900."
    },
    {
        "id": 348,
        "Question": "What is the order of the shape number of a rectangular boundary with the dimensions of 3×3?",
        "Options": [
            "a) 3",
            "b) 6",
            "c) 9",
            "d) 12"
        ],
        "Answer": "Answer: a\nExplanation: We know that, the first difference of a chain coded boundary depends on the starting point. Based on such 4 directional boundary, the first difference of smallest magnitude is called as the shape number of the boundary."
    },
    {
        "id": 349,
        "Question": "What is the shape number for the boundary given in the previous figure?",
        "Options": [
            "a) 003231023101230123",
            "b) 012301220331023010",
            "c) 133021030012330120",
            "d) 000310330130031303"
        ],
        "Answer": "Answer: b\nExplanation: The order of shape number gives the number of digits in its representation. The value of this order is even for closed boundary and limits the number of possible different shapes."
    },
    {
        "id": 350,
        "Question": "Which of the following techniques of boundary descriptions have the physical interpretation of boundary shape?",
        "Options": [
            "a) Fourier transform",
            "b) Statistical moments",
            "c) Laplace transform",
            "d) Curvature"
        ],
        "Answer": "Answer: d\nExplanation: The order of shape number is also defined as the perimeter of the boundary. Since, given is a rectangle of dimensions 3×3, the perimeter of the rectangle is given as 2(3+3) = 12."
    },
    {
        "id": 351,
        "Question": "The principal factor to determine the spatial resolution of an image is _______",
        "Options": [
            "a)\tQuantization",
            "b)\tSampling",
            "c)\tContrast",
            "d)\tDynamic range"
        ],
        "Answer": "Answer: b\nExplanation:\tThe spatial resolution of an image principally determine by Sampling."
    },
    {
        "id": 352,
        "Question": "What causes the effect, imperceptible set of very fine ridge like structures in areas of smooth gray levels?",
        "Options": [
            "a)\tCaused by the use of an insufficient number of gray levels in smooth areas of a digital image",
            "b)\tCaused by the use of huge number of gray levels in smooth areas of a digital image",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tThe set of very fine ridge like structures in area of smooth gray levels generally is quite visible in images displayed using 16 or less uniformly spaced gray levels."
    },
    {
        "id": 353,
        "Question": "What is the name of the effect caused by the use of an insufficient number of gray levels in smooth areas of a digital image?",
        "Options": [
            "a)\tDynamic range",
            "b)\tRidging",
            "c)\tGraininess",
            "d)\tFalse contouring"
        ],
        "Answer": "Answer: d\nExplanation:\tThe effect, caused due to insufficient number of gray levels in smooth areas of a digital image, is called false contouring, so called because the ridges resemble topographic contours in a map."
    },
    {
        "id": 354,
        "Question": "Using rough rule of thumb, and assuming powers of 2 for convenience, what image size are about the smallest images that can be expected to be reasonably free of objectionable sampling checkerboards and false contouring?",
        "Options": [
            "a)\t512*512pixels and 16 gray levels",
            "b)\t256*256pixels and 64 gray levels",
            "c)\t64*64pixels and 16 gray levels",
            "d)\t32*32pixels and 32 gray levels"
        ],
        "Answer": "Answer: b\nExplanation:\tAn image of 128*128pixels shows a pronounced checkerboard pattern, while for 256*256pixels image a minimum gray level of 64 is required to remove false contouring.\nAlso the effect is quite visible in images displayed using 16 or less uniformly spaced gray levels."
    },
    {
        "id": 355,
        "Question": "What does a shift up and right in the curves of isopreference curve simply means? Verify in terms of N (number of pixels) and k (L=2k, L is the gray level) values.",
        "Options": [
            "a)\tSmaller values for N and k, implies a better picture quality",
            "b)\tLarger values for N and k, implies low picture quality",
            "c)\tLarger values for N and k, implies better picture quality",
            "d)\tSmaller values for N and k, implies low picture quality"
        ],
        "Answer": "Answer: c\nExplanation:\tPoints lying on an isopreference curve correspond to images of equal subjective quality. It was found that the isopreference curves tended to shift right and upward with the details of the image. So, a shift up and right in the curves simply means larger values for N and k, implying better picture quality."
    },
    {
        "id": 356,
        "Question": "How does the curves behave to the detail in the image in isopreference curve?",
        "Options": [
            "a)\tCurves tend to become more vertical as the detail in the image decreases",
            "b)\tCurves tend to become less vertical as the detail in the image increases",
            "c)\tCurves tend to become less vertical as the detail in the image decreases",
            "d)\tCurves tend to become more vertical as the detail in the image increases"
        ],
        "Answer": "Answer: d\nExplanation:\tThe curves in isopreference curve tend to become more vertical as the detail in the image increases.\nThe right side graph shows the same, curve for crowd is nearly vertical.\n<img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-online-test-q6.png\" alt=\"digital-image-processing-questions-answers-online-test-q6\" width=\"572\" height=\"184\" class=\"alignnone size-full wp-image-148792\" srcset=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-online-test-q6.png 572w, https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-online-test-q6-300x97.png 300w\" sizes=\"(max-width: 572px) 100vw, 572px\" /> "
    },
    {
        "id": 357,
        "Question": "For an image with a large amount of detail, if the value of N (number of pixels) is fixed then what is the gray level dependency in the perceived quality of this type of image?",
        "Options": [
            "a)\tTotally independent of the number of gray levels used",
            "b)\tNearly independent of the number of gray levels used",
            "c)\tHighly dependent of the number of gray levels used",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tFor image with high details of the image only a few gray levels may be needed."
    },
    {
        "id": 358,
        "Question": "What is a band-limited function?",
        "Options": [
            "a)\tA function of limited duration whose highest frequency is finite",
            "b)\tA function of limited duration whose highest frequency is infinite",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tFunctions whose area under the curve is finite can be represented in terms of sines and cosines of various frequencies. The highest frequency is determined by the sine/cosine component is the highest “frequency content” of the function. If this highest frequency is finite and that the function is of unlimited duration, then, these functions are called band-limited functions."
    },
    {
        "id": 359,
        "Question": "For a band-limited function, which Theorem says that “if the function is sampled at a rate equal to or greater than twice its highest frequency, the original function can be recovered from its samples”?",
        "Options": [
            "a)\tBand-limitation theorem",
            "b)\tAliasing frequency theorem",
            "c)\tShannon sampling theorem",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tFor a band-limited function, Shannon sampling theorem says that “if the function is sampled at a rate equal to or greater than twice its highest frequency, the original function can be recovered from its samples”."
    },
    {
        "id": 360,
        "Question": "What is the name of the phenomenon that corrupts the sampled image, and how does it happen?",
        "Options": [
            "a)\tShannon sampling, if the band-limited functions are undersampled",
            "b)\tShannon sampling, if the band-limited functions are oversampled",
            "c)\tAliasing, if the band-limited functions are undersampled",
            "d)\tAliasing, if the band-limited functions are oversampled"
        ],
        "Answer": "Answer: c\nExplanation:\tIf the band-limited functions is undersampled, then a phenomenon called aliasing corrupts the sampled image."
    },
    {
        "id": 361,
        "Question": "How aliasing does corrupts the sampled image?",
        "Options": [
            "a)\tBy introducing additional frequency components to the sampled function",
            "b)\tBy removing some frequency components from the sampled function",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tAliasing corrupts the sampled image by introducing additional frequency components into the sampled function. These added components are called aliased frequencies."
    },
    {
        "id": 362,
        "Question": "How can one reduce the aliasing effect on an image?",
        "Options": [
            "a)\tBy reducing the high-frequency components of image by blurring the image",
            "b)\tBy increasing the high-frequency components of image by blurring the image",
            "c)\tBy reducing the high-frequency components of image by clarifying the image",
            "d)\tBy increasing the high-frequency components of image by clarifying the image"
        ],
        "Answer": "Answer: a\nExplanation:\tAliasing corrupts the sampled image by introducing additional frequency components to the sampled function. So, the principal approach for reducing the aliasing effects on an image is to reduce its high-frequency components by blurring the image prior to sampling."
    },
    {
        "id": 363,
        "Question": "In terms of Sampling and Quantization, Zooming and Shrinking may be viewed as ___________",
        "Options": [
            "a)\tOversampling for both",
            "b)\tOversampling and Undersampling respectively",
            "c)\tUndersampling and Oversampling respectively",
            "d)\tUndersampling for both"
        ],
        "Answer": "Answer: b\nExplanation:\tOversampling increases the number of sample in the image, i.e. like Zooming.\nUndersampling decreases the number of samples in the image, i.e. like Shrinking."
    },
    {
        "id": 364,
        "Question": "The two steps: one is the creation of new pixel locations, and other is the assignment of gray levels to those new locations are involved in ____________",
        "Options": [
            "a)\tShrinking",
            "b)\tZooming",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tSuppose that we have an image of size500*500pixels and we want to enlarge it 1.5 times to 750*750pixels.\nCreation of new Pixels: One of the easiest ways to visualize zooming is laying an imaginary 750*750 grid over the original image and so there would be less spacing by one pixel in the grid because we are fitting it over a smaller image.\nAssignment of gray levels to new locations: In order to perform gray-level assignment for any point in the overlay, we assign its gray level to the new pixel in the grid its closest pixel in the original image.\nWhen the above steps are done with all points in the overlay grid, we expand it to the original specified size to obtain the zoomed image."
    },
    {
        "id": 365,
        "Question": "While Zooming, In order to perform gray-level assignment for any point in the overlay, we assign its gray level to the new pixel in the grid its closest pixel in the original image. What’s this method of gray-level assignment called?",
        "Options": [
            "a)\tNeighbor Duplication",
            "b)\tDuplication",
            "c)\tNearest neighbor Interpolation",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tBecause we look for the closest pixel in the original image and assign its gray level to the new pixel in the grid."
    },
    {
        "id": 366,
        "Question": "A special case of nearest neighbor Interpolation that just duplicates the pixels the number of times to achieve the desired size, is known as ___________",
        "Options": [
            "a)\tBilinear Interpolation",
            "b)\tContouring",
            "c)\tRidging",
            "d)\tPixel Replication"
        ],
        "Answer": "Answer: d\nExplanation:\tA special case of nearest neighbor interpolation is Pixel replication and is applicable when we want to increase the size of an image an integer number of times.\nFor example, doubling the size of an image is achieved duplicating each column and hence image size gets doubled in the horizontal direction. Then, we duplicate each row of the enlarged image to double the size in the vertical direction. Similarly, enlarging the image by any integer number of times (triple, quadruple, and so on) is possible."
    },
    {
        "id": 367,
        "Question": "Nearest neighbor Interpolation has an undesirable feature, that is _________",
        "Options": [
            "a)\tAliasing effect",
            "b)\tFalse contouring effect",
            "c)\tRidging effect",
            "d)\tCheckerboard effect"
        ],
        "Answer": "Answer: d\nExplanation:\tAt greater magnification nearest neighbor Interpolation has the undesirable feature that it produces a checkerboard effect."
    },
    {
        "id": 368,
        "Question": "What does the bilinear Interpolation do for gray-level assignment?",
        "Options": [
            "a)\tAssign gray level to the new pixel using its right neighbor",
            "b)\tAssign gray level to the new pixel using its left neighbor",
            "c)\tAssign gray level to the new pixel using its four nearest neighbors",
            "d)\tAssign gray level to the new pixel using its eight nearest neighbors"
        ],
        "Answer": "Answer: c\nExplanation:\tBilinear interpolation uses the four nearest neighbors of the new pixel. Let (x’, y’) is the coordinates of a point in the zoomed image and the gray level assigned to the point is v(x, y’).\nFor bilinear interpolation, the assigned gray level is given by\n\tv(x’, y’) = ax’ + by’ + cx’y’ + d\nHere, a, b, c and d are determined from the four equations in four unknowns that can be written using the four nearest neighbors of point (x’, y’)."
    },
    {
        "id": 369,
        "Question": "Row-column deletion method of Image Shrinking is an equivalent process to which method of Zooming?",
        "Options": [
            "a)\tBilinear Interpolation",
            "b)\tContouring",
            "c)\tPixel Replication",
            "d)\tThere is no such equivalent process"
        ],
        "Answer": "Answer: c\nExplanation:\tRow-column deletion method is used to shrink an image by one-half, one-fourth and so on.\nIn case of one-half we delete every other row and column."
    },
    {
        "id": 370,
        "Question": "Image Shrinking has an undesirable feature, that is ____________",
        "Options": [
            "a)\tAliasing effect",
            "b)\tFalse contouring effect",
            "c)\tRidging effect",
            "d)\tCheckerboard effect"
        ],
        "Answer": "Answer: a\nExplanation:\tAlthough Image Shrinking uses the grid analogy of nearest neighbor interpolation, but that we now expand the grid to fit over the original image, do gray-level nearest neighbor or bilinear interpolation, causing the possible aliasing effect, and then shrink the grid back to its original specified size."
    },
    {
        "id": 371,
        "Options": [
            "9. State for the validation of the statement:",
            "“In general-purpose for a digital image of zooming and shrinking, where Bilinear Interpolation generally is the method of choice over nearest neighbor Interpolation”.",
            "a)\tTrue",
            "b)\tFalse"
        ],
        "Answer": "Answer: a\nExplanation:\tFor case 32*32 to 1024*1024, the data is rather lost in nearest neighbor Interpolation, but the result of Bilinear Interpolation remains reasonably good for the same."
    },
    {
        "id": 372,
        "Question": "What is the set of pixels of 8-neighbors of pixel p at coordinates (x, y)?",
        "Options": [
            "a)\t(x+1, y), (x-1, y), (x, y+1), (x, y-1), (x+2, y), (x-2, y), (x, y+2), (x, y-2)",
            "b)\t(x+1, y), (x-1, y), (x, y+1), (x, y-1), (x+1, y+1), (x+1, y-1), (x-1, y+1), (x-1, y-1)",
            "c)\t(x+1, y+1), (x+1, y-1), (x-1, y+1), (x-1, y-1), (x+2, y+2), (x+2, y-2), (x-2, y+2), (x-2, y-2)",
            "d)\t(x+2, y), (x-2, y), (x, y+2), (x, y-2), (x+2, y+2), (x+2, y-2), (x-2, y+2), (x-2, y-2)"
        ],
        "Answer": "Answer: a\nExplanation:\tThe given set of neighbor pixel are 1 unit distance to right, left, up and below respectively from pixel p(x, y). So, are called 4-neighbors of p."
    },
    {
        "id": 373,
        "Question": "Two pixels p and q having gray values from V, the set of gray-level values used to define adjacency, are m-adjacent if:",
        "Options": [
            "a)\tq is in N4(p)",
            "b)\tq is in ND(p) and the set N4(p) ∩ N4(q) has no pixels whose values are from V",
            "c)\tAny of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tThe given set of neighbor pixel are 1 unit distance to right-up diagonal, right-down diagonal, left-up diagonal  and left-down diagonal respectively from pixel p(x, y). So, are called Diagonal neighbors of p."
    },
    {
        "id": 374,
        "Question": "Let S, a subset of pixels in an image, is said to be a connected set if:",
        "Options": [
            "a)\tIf for any pixel p in S, the set of pixels that are connected to it in Sis only one",
            "b)\tIf it only has one connected component",
            "c)\tIf S is a region",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tThe set of pixels of 4-neighbors of p and Diagonal neighbors of p together are called as 8-neighbors of pixel p(x, y)."
    },
    {
        "id": 375,
        "Question": "Let R be a subset of pixels in an image. How can we define the contour of R?",
        "Options": [
            "a)\tIf R is a region, and the set of pixels in R have one or more neighbors that are not in R",
            "b)\tIf R is an entire image, then the set of pixels in the first and last rows and columns of R",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tMixed adjacency is a modified form of 8-adjacency.\nThe above conditioned Two pixels p and q are m-adjacent if:\nq is in N4(p), or\nq is in ND(p) and the set N4(p) ∩ N4(q) has no pixels whose values are from V."
    },
    {
        "id": 376,
        "Question": "For pixels p(x, y), q(s, t), and z(v, w), D is a distance function or metric if:",
        "Options": [
            "a)\tD(p, q) ≥ 0",
            "b)\tD(p, q) = D(q, p)",
            "c)\tD(p, z) ≤ D(p, q) + D(q, z)",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation:\tFor a subset of pixels in an image S\nFor any pixel p in S, the set of pixels is called a connected component of S if connected to p in S. The set S is called a connected set if it only has one connected component.\nS, is a region of the image if S is a connected set."
    },
    {
        "id": 377,
        "Question": "For pixels p(x, y), q(s, t), the Euclidean distance between p and q is defined as:",
        "Options": [
            "a)\tD(p, q) = [(x – s)2 + (y – t)2]1/2",
            "b)\tD(p, q) = |x – s| + |y – t|",
            "c)\tD(p, q) = max (|x – s| + |y – t|)",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tFor a subset of pixels in an image R\nThe boundary or contour of a region R is the set of pixels in the region that have one or more neighbors that are not in R.\nIn case R is an entire image, then its boundary is defined as the set of pixels in the first and last rows and columns of the image."
    },
    {
        "id": 378,
        "Question": "For pixels p(x, y), q(s, t), the city-block distance between p and q is defined as:",
        "Options": [
            "a)\tD(p, q) = [(x – s)2 + (y – t)2]1/2",
            "b)\tD(p, q) = |x – s| + |y – t|",
            "c)\tD(p, q) = max (|x – s| + |y – t|)",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation:\tFor pixels p(x, y), q(s, t), and z(v, w), D is a distance function or metric if:\n(i)\tD(p, q) ≥ 0, \t(D(p, q) = 0  if p=q),\n(ii)\tD(p, q) = D(q, p), and\n(iii)\tD(p, z) ≤ D(p, q) + D(q, z)."
    },
    {
        "id": 379,
        "Question": "For pixels p(x, y), q(s, t), the chessboard distance between p and q is defined as:",
        "Options": [
            "a)\tD(p, q) = [(x – s)2 + (y – t)2]1/2",
            "b)\tD(p, q) = |x – s| + |y – t|",
            "c)\tD(p, q) = max (|x – s| + |y – t|)",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tThe Euclidean distance for pixels p(x, y), q(s, t) is:\nD(p, q) = [(x – s)2 + (y – t)2]1/2."
    },
    {
        "id": 380,
        "Question": "The domain that refers to image plane itself and the domain that refers to Fourier transform of an image is/are :",
        "Options": [
            "a)\tSpatial domain in both",
            "b)\tFrequency domain in both",
            "c)\tSpatial domain and Frequency domain respectively",
            "d)\tFrequency domain and Spatial domain respectively"
        ],
        "Answer": "Answer: b\nExplanation:\tThe city-block distance for pixels p(x, y), q(s, t) is the D4 distance given by:\nD(p, q) = |x – s| + |y – t|."
    },
    {
        "id": 381,
        "Question": "What is the technique for a gray-level transformation function called, if the transformation would be to produce an image of higher contrast than the original by darkening the levels below some gray-level m and brightening the levels above m in the original image.",
        "Options": [
            "a)\tContouring",
            "b)\tContrast stretching",
            "c)\tMask processing",
            "d)\t Point processing"
        ],
        "Answer": "Answer: c\nExplanation:\tThe chessboard distance for pixels p(x, y), q(s, t) is the D8 distance given by:\nD(p, q) = max (|x – s| + |y – t|)."
    },
    {
        "id": 382,
        "Question": "For Image Enhancement a general-approach is to use a function of values of f (input image) in a predefined neighborhood of (x, y) to determine the value of g (output image) at (x, y). The techniques that uses such approaches are called ________",
        "Options": [
            "a)\tContouring",
            "b)\tContrast stretching",
            "c)\tMask processing",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tSpatial domain itself refers to the image plane, and approaches in this category are based on direct manipulation of pixels in an image.\nTechniques based on Frequency domain processing are based on modifying the Fourier transform of an image."
    },
    {
        "id": 383,
        "Question": "Using gray-level transformation, the basic function linearity deals with which of the following transformation?",
        "Options": [
            "a)\tlog and inverse-log transformations",
            "b)\tnegative and identity transformations",
            "c)\tnth and nth  root transformations",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tFor Image Enhancement gray-level transformation shows three basic function that are:\nLinearity for negative and identity transformation\nLogarithmic for log and inverse-log transformation, and\nPower-law for nth and nth  root transformations."
    },
    {
        "id": 384,
        "Question": "Using gray-level transformation, the basic function Logarithmic deals with which of the following transformation?",
        "Options": [
            "a)\tLog and inverse-log transformations",
            "b)\tNegative and identity transformations",
            "c)\tnth and nth  root transformations",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tFor Image Enhancement gray-level transformation shows three basic function that are:\nLinearity for negative and identity transformation\nLogarithmic for log and inverse-log transformation, and\nPower-law for nth and nth  root transformations."
    },
    {
        "id": 385,
        "Question": "Using gray-level transformation, the basic function power-law deals with which of the following transformation?",
        "Options": [
            "a)\tlog and inverse-log transformations",
            "b)\tnegative and identity transformations",
            "c)\tnth and nth  root transformations",
            "d)\tall of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tFor Image Enhancement gray-level transformation shows three basic function that are:\nLinearity for negative and identity transformation\nLogarithmic for log and inverse-log transformation, and\nPower-law for nth and nth  root transformations."
    },
    {
        "id": 386,
        "Question": "If r be the gray-level of image before processing and s after processing then which expression defines the negative transformation, for the gray-level in the range [0, L-1]?",
        "Options": [
            "a)\ts = L – 1 – r",
            "b)\ts = crᵞ, c and ᵞ are positive constants",
            "c)\ts = c log (1 + r), c is a constant and r ≥ 0",
            "d)\tnone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tThe expression for negative transformation is given as: s = L – 1 – r."
    },
    {
        "id": 387,
        "Question": "If r be the gray-level of image before processing and s after processing then which expression helps to obtain the negative of an image for the gray-level in the range [0, L-1]?",
        "Options": [
            "a)\ts = L – 1 – r",
            "b)\ts = crᵞ, c and ᵞ are positive constants",
            "c)\ts = c log (1 + r), c is a constant and r ≥ 0",
            "d)\tnone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tThe expression for log transformation is given as: s = c log (1 + r), c is a constant and r ≥ 0."
    },
    {
        "id": 388,
        "Question": "If r be the gray-level of image before processing and s after processing then which expression defines the power-law transformation, for the gray-level in the range [0, L-1]?",
        "Options": [
            "a)\ts = L – 1 – r",
            "b)\ts = crᵞ, c and ᵞ are positive constants",
            "c)\ts = c log (1 + r), c is a constant and r ≥ 0",
            "d)\tnone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tThe expression for power-law transformation is given as: s = crᵞ, c and ᵞ are positive constants."
    },
    {
        "id": 389,
        "Question": "Which of the following transformations is particularly well suited for enhancing an image with white and gray detail embedded in dark regions of the image, especially when there is more black area in the image.",
        "Options": [
            "a)\tLog transformations",
            "b)\tPower-law transformations",
            "c)\tNegative transformations",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tNegative transformation reverses the intensity levels in the image and produces an equivalent photographic negative. So, well suited for the above given condition."
    },
    {
        "id": 390,
        "Question": "Which of the following transformations expands the value of dark pixels while the higher-level values are being compressed?",
        "Options": [
            "a)\tLog transformations",
            "b)\tInverse-log transformations",
            "c)\tNegative transformations",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tLog transformation derives a narrow range of gray-level values in input image to wider range of gray-levels in the output image, and does performs the above given transformation.\nThe inverse-log is applied for the opposite."
    },
    {
        "id": 391,
        "Question": "Although power-law transformations are considered more versatile than log transformations for compressing of gray-levels in an image, then, how is log transformations advantageous over power-law transformations?",
        "Options": [
            "a)\tThe log transformation compresses the dynamic range of images",
            "b)\tThe log transformations reverses the intensity levels in the images",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tFor compressing gray-levels in an image, power-law transformation is more versatile than log transformation, but log transformation has an important characteristics of compressing dynamic ranges of pixels having a large variation of values."
    },
    {
        "id": 392,
        "Question": "A typical Fourier Spectrum with spectrum value ranging from 0 to 106, which of the following transformation is better to apply.",
        "Options": [
            "a)\tLog transformations",
            "b)\tPower-law transformations",
            "c)\tNegative transformations",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tThe log transformation compresses the dynamic range of images and so the given range turns to 0 to approx. 7, which is easily displayable with 8-bit display. "
    },
    {
        "id": 393,
        "Question": "The power-law transformation is given as: s = crᵞ, c and ᵞ are positive constants, and r is the gray-level of image before processing and s after processing. Then, for what value of c and ᵞ does power-law transformation becomes identity transformation?",
        "Options": [
            "a)\tc = 1 and ᵞ < 1",
            "b)\tc = 1 and ᵞ > 1",
            "c)\tc = -1 and ᵞ = 0",
            "d)\tc = ᵞ = 1"
        ],
        "Answer": "Answer: d\nExplanation:\tFor c = ᵞ = 1 the power-law transformations s = crᵞ become s = r that is an identity transformations."
    },
    {
        "id": 394,
        "Question": "What is gamma correction?",
        "Options": [
            "a)\tA process to remove power-law transformation response phenomena",
            "b)\tA process to remove log transformation response phenomena",
            "c)\tA process to correct log transformation response phenomena",
            "d)\tA process to correct power-law transformation response phenomena"
        ],
        "Answer": "Answer: d\nExplanation:\tThe exponent used in power-law transformation is called gamma. So, using the ᵞ value, either ᵞ < 1 or ᵞ> 1, various responses are obtained."
    },
    {
        "id": 395,
        "Question": "Which of the following transformation is used cathode ray tube (CRT) devices?",
        "Options": [
            "a)\tLog transformations",
            "b)\tPower-law transformations",
            "c)\tNegative transformations",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tThe CRT devices has a power function relation between intensity and volt response.\nIn such devices output appears darker than input. So, gamma correction is a must in this case."
    },
    {
        "id": 396,
        "Question": "Log transformation is generally used in which of the following device(s)?",
        "Options": [
            "a)\tCathode ray tube",
            "b)\tScanners and printers",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation:\tAll the mentioned devices uses gamma correction and so power-law transformation is generally of use in such case."
    },
    {
        "id": 397,
        "Question": "The power-law transformation is given as: s = crᵞ, c and ᵞ are positive constants, and r is the gray-level of image before processing and s after processing. What happens if we increase the gamma value from 0.3 to 0.7?",
        "Options": [
            "a)\tThe contrast increases and the detail increases",
            "b)\tThe contrast decreases and the detail decreases",
            "c)\tThe contrast increases and the detail decreases",
            "d)\tThe contrast decreases and the detail increases"
        ],
        "Answer": "Answer: c\nExplanation:\tIn power-law transformation as gamma decreases is increase in image details however, the contrast reduces."
    },
    {
        "id": 398,
        "Question": "1.\tIf h(rk) = nk, rk the kth gray level and nk total pixels with gray level rk, is a histogram in gray level range [0, L – 1]. Then how can we normalize a histogram?",
        "Options": [
            "a)\tIf each value of histogram is added by total number of pixels in image, say n, p(rk)=nk+n",
            "b)  If each value of histogram is subtracted by total number of pixels in image, say n, p(rk)=nk-n",
            "c)\tIf each value of histogram is multiplied by total number of pixels in image, say n, p(rk)=nk * n",
            "d)\tIf each value of histogram is divided by total number of pixels in image, say n, p(rk)=nk / n"
        ],
        "Answer": "Answer: d\nExplanation:\tTo normalize a histogram each of its value is divided by total number of pixels in image, say n. p(rk) = nk / n."
    },
    {
        "id": 399,
        "Question": "2.\tWhat is the sum of all components of a normalized histogram?",
        "Options": [
            "a)\t1",
            "b)\t-1",
            "c)\t0",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tA normalized histogram. p(rk) = nk / n\nWhere, n is total number of pixels in image, rk the kth gray level and nk total pixels with gray level rk.\nHere, p(rk) gives the probability of occurrence of rk."
    },
    {
        "id": 400,
        "Question": "3.\tA low contrast image will have what kind of histogram when, the histogram, h(rk) = nk, rk the kth gray level and nk total pixels with gray level rk, is plotted nk versus rk?",
        "Options": [
            "a)\tThe histogram that are concentrated on the dark side of gray scale",
            "b)\tThe histogram whose component are biased toward high side of gray scale",
            "c)\tThe histogram that is narrow and centered toward the middle of gray scale",
            "d)\tThe histogram that covers wide range of gray scale and the distribution of pixel is approximately uniform"
        ],
        "Answer": "Answer: c\nExplanation:\tThe histogram plot is nk versus rk. So, the histogram of a low contrast image will be narrow and centered toward the middle of gray scale.\nA dark image will have the histogram that are concentrated on the dark side of gray scale.\nA bright image will have the histogram whose component are biased toward high side of gray scale.\nA high contrast image will have the histogram that covers wide range of gray scale and the distribution of pixel is approximately uniform."
    },
    {
        "id": 401,
        "Question": "4.\tA bright image will have what kind of histogram, when the histogram, h(rk) = nk, rk the kth gray level and nk total pixels with gray level rk, is plotted nk versus rk?",
        "Options": [
            "a)\tThe histogram that are concentrated on the dark side of gray scale",
            "b)\tThe histogram whose component are biased toward high side of gray scale",
            "c)\tThe histogram that is narrow and centered toward the middle of gray scale",
            "d)\tThe histogram that covers wide range of gray scale and the distribution of pixel is approximately uniform"
        ],
        "Answer": "Answer: b\nExplanation:\tThe histogram plot is nk versus rk. So, the histogram of a low contrast image will be narrow and centered toward the middle of gray scale.\nA dark image will have the histogram that are concentrated on the dark side of gray scale.\nA bright image will have the histogram whose component are biased toward high side of gray scale.\nA high contrast image will have the histogram that covers wide range of gray scale and the distribution of pixel is approximately uniform."
    },
    {
        "id": 402,
        "Question": "6.\tThe transformation s = T(r) producing a gray level s for each pixel value r of input image. Then, if the T(r) is single valued in interval 0 ≤ r ≤ 1, what does it signifies?",
        "Options": [
            "a)\tIt guarantees the existence of inverse transformation",
            "b)\tIt is needed to restrict producing of some inverted gray levels in output",
            "c)\tIt guarantees that the output gray level and the input gray level will be in same range",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation:\tThe histogram plot is nk versus rk. So, the histogram of a low contrast image will be narrow and centered toward the middle of gray scale.\nA dark image will have the histogram that are concentrated on the dark side of gray scale.\nA bright image will have the histogram whose component are biased toward high side of gray scale.\nA high contrast image will have the histogram that covers wide range of gray scale and the distribution of pixel is approximately uniform."
    },
    {
        "id": 403,
        "Question": "7.\tThe transformation s = T(r) producing a gray level s for each pixel value r of input image. Then, if the T(r) is monotonically increasing in interval 0 ≤ r ≤ 1, what does it signifies?",
        "Options": [
            "a)\tIt guarantees the existence of inverse transformation",
            "b)\tIt is needed to restrict producing of some inverted gray levels in output",
            "c)\tIt guarantees that the output gray level and the input gray level will be in same range",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tThe T(r) is single valued in interval 0 ≤ r ≤ 1, guarantees the existence of inverse transformation."
    },
    {
        "id": 404,
        "Question": "8.\tThe transformation s = T(r) producing a gray level s for each pixel value r of input image. Then, if the T(r) is satisfying 0 ≤ T(r) ≤ 1 in interval 0 ≤ r ≤ 1, what does it signifies?",
        "Options": [
            "a)\tIt guarantees the existence of inverse transformation",
            "b)\tIt is needed to restrict producing of some inverted gray levels in output",
            "c)\tIt guarantees that the output gray level and the input gray level will be in same range",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tA T(r) which is not monotonically increasing, could result in an output containing at least a section of inverted intensity range. The T(r) is monotonically increasing in interval 0 ≤ r ≤ 1, is needed to restrict producing of some inverted gray levels in output."
    },
    {
        "id": 405,
        "Question": "9.\tWhat is the full form for PDF, a fundamental descriptor of random variables i.e. gray values in an image?",
        "Options": [
            "a)\tPixel distribution function",
            "b)\tPortable document format",
            "c)\tPel deriving function",
            "d)\tProbability density function"
        ],
        "Answer": "Answer: c\nExplanation:\tIf, 0 ≤ T(r) ≤ 1 in interval 0 ≤ r ≤ 1, then the output gray level and the input gray level will be in same range."
    },
    {
        "id": 406,
        "Question": "10.\tWhat is the full form of CDF?",
        "Options": [
            "a)\tCumulative density function",
            "b)\tContour derived function",
            "c)\tCumulative distribution function",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation:\tFor a random variable, a PDF, probability density function, is one of the most fundamental descriptor."
    },
    {
        "id": 407,
        "Question": "11.\tFor the transformation T(r) = [∫0r pr(w) dw], r is gray value of input image, pr(r) is PDF of random variable r and w is a dummy variable. If, the PDF are always positive and that the function under integral gives the area under the function, the transformation is said to be __________",
        "Options": [
            "a)\tSingle valued",
            "b)\tMonotonically increasing",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tCDF of random variable r, gray value of input image, is cumulative distribution function."
    },
    {
        "id": 408,
        "Question": "12.\tThe transformation T (rk) = ∑k(j=0) nj /n, k = 0, 1, 2, …, L-1, where L is max gray value possible and r-k is the kth gray level, is called _______",
        "Options": [
            "a)\tHistogram linearization",
            "b)\tHistogram equalization",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tFor the given transformation, the PDF being positive and the integral providing area under the function, the transformation function is single valued as well as monotonically increasing."
    },
    {
        "id": 409,
        "Question": "13.\tIf the histogram of same images, with different contrast, are different, then what is the relation between the histogram equalized images?",
        "Options": [
            "a)\tThey look visually very different from one another",
            "b)\tThey look visually very similar to one another",
            "c)\tThey look visually different from one another just like the input images",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tThe given transformation is the equation for the Histogram equalization also called as Histogram linearization."
    },
    {
        "id": 410,
        "Question": "1.\tThe technique of Enhancement that has a specified Histogram processed image as result, is called?",
        "Options": [
            "a)\tHistogram Linearization",
            "b)\tHistogram Equalization",
            "c)\tHistogram Matching",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tHistogram Specification method uses a specified Histogram, i.e. the shape of histogram can be specified by self, to generate a processed image.\nAnd the same is also known as Histogram Matching."
    },
    {
        "id": 411,
        "Question": "2.\tIn Histogram Matching r and z are gray level of input and output image and p stands for PDF, then, what does pz(z) stands for?",
        "Options": [
            "a)\tSpecific probability density function",
            "b)\tSpecified pixel distribution function",
            "c)\tSpecific pixel density function",
            "d)\tSpecified probability density function"
        ],
        "Answer": "Answer: d\nExplanation:\tIn Histogram Matching, pr(r) is estimated from input image while pz(z) is Specified probability density function that output image is supposed to have."
    },
    {
        "id": 412,
        "Question": "3.\tInverse transformation plays an important role in which of the following Histogram processing Techniques?",
        "Options": [
            "a)\tHistogram Linearization",
            "b)\tHistogram Equalization",
            "c)\tHistogram Matching",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tIn Histogram Matching or Specification, z = G-1[T(r)], r and z are gray level of input and output image and T & G are transformations.\nIn Histogram Linearization or Equalization s = T(r), r and s are gray level of input and output image and T is the only transformations."
    },
    {
        "id": 413,
        "Question": "4.\tIn Histogram Matching or Specification, z = G-1[T(r)], r and z are gray level of input and output image and T & G are transformations, to confirm the single value and monotonous of G-1  what of the following is/are required?",
        "Options": [
            "a)\tG must be strictly monotonic",
            "b)\tG must be strictly decreasing",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tG being strictly monotonic, confirms that the values of specified histogram pz(zi) can’t be zero. That is G-1 is also single valued and monotonic."
    },
    {
        "id": 414,
        "Question": "5.\tWhich of the following histogram processing techniques is global?",
        "Options": [
            "a)\tHistogram Linearization",
            "b)\tHistogram Specification",
            "c)\tHistogram Matching",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation:\tAll of the mentioned methods modifies the pixel value by transformations that are based on the gray-level of the whole image."
    },
    {
        "id": 415,
        "Question": "6.\tWhat happens to the output image when global Histogram equalization method is applied on smooth and noisy area of an image?",
        "Options": [
            "a)\tThe contrast increases little bit with considerable enhancement of noise",
            "b)\tThe result would have a fine noise texture",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tTo an image’s smooth and noisy area, when global histogram method is applied the contrast increases little bit with considerable enhancement of noise, while for local method the result has a fine noise texture.\n  <img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-online-quiz-q6.png\" alt=\"digital-image-processing-questions-answers-online-quiz-q6\" width=\"569\" height=\"175\" class=\"alignnone size-full wp-image-148723\" srcset=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-online-quiz-q6.png 569w, https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-online-quiz-q6-300x92.png 300w\" sizes=\"(max-width: 569px) 100vw, 569px\" />\n(a) Original image. (b) Result using global histogram equalization. (c) Result using local histogram equalization using 7*7 neighborhood about each pixel."
    },
    {
        "id": 416,
        "Question": "8.\tIn terms of enhancement, what does mean and variance refers to?",
        "Options": [
            "a)\tAverage contrast and average gray level respectively",
            "b)\tAverage gray level and average contrast respectively",
            "c)\tAverage gray level in both",
            "d)\tAverage contrast in both"
        ],
        "Answer": "Answer: b\nExplanation:\tFor global histogram enhancement, the small squares have a very close gray value with larger square and have a very small size to be influenced by global histogram equalization method.\nBut, local histogram enhancement using a 7*7 neighborhood reveals the small square.\n <img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-online-quiz-q6.png\" alt=\"digital-image-processing-questions-answers-online-quiz-q6\" width=\"569\" height=\"175\" class=\"alignnone size-full wp-image-148723\" srcset=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-online-quiz-q6.png 569w, https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-online-quiz-q6-300x92.png 300w\" sizes=\"(max-width: 569px) 100vw, 569px\" />\n(a) Original image. (b) Result using global histogram equalization. (c) Result using local histogram equalization using 7*7 neighborhood about each pixel."
    },
    {
        "id": 417,
        "Question": "9.\tFor a local enhancement using mean and variance, there is one condition:\t\tms(x, y) ≤ k0 MG, where, MG is global mean, k0 a constant and ms(x, y) a measure of gray value as light or dark at point (x, y). Then, which fact is true for k0?",
        "Options": [
            "a)\tIt is a negative constant with values less than -1.0",
            "b)\tIt is a positive constant with values less than 1.0",
            "c)\tIt is an integer constant with values between -1.0 and 1.0",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tIn terms of enhancement, mean refers to average gray level and variance to average contrast.\nGiven by, mean as: m = ∑_(i=0)^(L-1) ri p(ri )\tand variance as: σ2(r) = ∑_(i=0)^(L-1) (ri –m)2 p(ri ).\nWhere, ri is histogram component of ith value of r, p(ri) is probability occurrence of gray level ri and L is the max gray value allowed."
    },
    {
        "id": 418,
        "Question": "10.\tFor a local enhancement using mean and variance, there is one condition:\t\tσs(x, y) ≤ k2DG, where, MDG is global standard deviation, k2 a positive constant and σs(x, y) a measure of contrast at point (x, y). Then, which fact is true for k2 if its values is less than 1.0?",
        "Options": [
            "a)\tEnhancement is being done on light areas",
            "b)\tEnhancement is being done on dark areas",
            "c)\tEnhancement is being done independent of value of k0",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tIn the condition ms(x, y) ≤ k0 MG, k0 is a positive constants whose value is always less than 1.0."
    },
    {
        "id": 419,
        "Question": "11.\tFor a local enhancement using mean and variance, there is one condition:\t\tσs(x, y) ≤ k2DG,  where, MDG is global standard deviation, k2 a positive constant and σs(x, y) a measure of contrast at point (x, y). Then, which fact is true for k2 if its values is greater than 1.0?",
        "Options": [
            "a)\tEnhancement is being done on light areas",
            "b)\tEnhancement is being done on dark areas",
            "c)\tEnhancement is being done independent of value of k0",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tIn the condition σs(x, y) ≤ k2DG, k0 is a positive constants that helps in enhancing light areas if value is greater than 1.0 and dark areas if value is less than 1.0."
    },
    {
        "id": 420,
        "Question": "12.\tWhat is standard deviation value for constant area?",
        "Options": [
            "a)\t0",
            "b)\t1",
            "c)\t-1",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tIn the condition σs(x, y) ≤ k2DG, k0 is a positive constants that helps in enhancing light areas if value is greater than 1.0 and dark areas if value is less than 1.0."
    },
    {
        "id": 421,
        "Question": "13.\tFor a local enhancement using mean and variance, what happens if the lowest value of contrast is not restricted as per the willingness of acceptance of value?",
        "Options": [
            "a)\tThere wouldn’t be any enhancement",
            "b)      Enhancement will occur for areas with standard deviation value > 1",
            "c)\tEnhancement of the constant areas will also be the part of procedure",
            "d)\tEnhancement will occur for areas with standard deviation value > 0 and < 1"
        ],
        "Answer": "Answer: a\nExplanation:\tStandard deviation is given by:<img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-online-quiz-q12.png\" alt=\"digital-image-processing-questions-answers-online-quiz-q12\" width=\"147\" height=\"26\" class=\"alignnone size-full wp-image-148729\" /> that results 0 for constant areas."
    },
    {
        "id": 422,
        "Question": "Logic operations between two or more images are performed on pixel-by-pixel basis, except for one that is performed on a single image. Which one is that?",
        "Options": [
            "a)\tAND",
            "b)\tOR",
            "c)\tNOT",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tAlthough all the Arithmetic/Logic operations between two or more images are performed on pixel-by-pixel basis, except for NOT that is performed on a single image."
    },
    {
        "id": 423,
        "Question": "Which of the following logical operator(s) is/are functionally complete?",
        "Options": [
            "a)\tAND",
            "b)\tOR",
            "c)\tNOT",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation:\tAll the three logical operators given are functionally complete because all other logical operators can be implemented using these three."
    },
    {
        "id": 424,
        "Question": "While implementing logic operation on gray-scale images, the processing of pixel values is done as __________",
        "Options": [
            "a)\tString of integer numbers",
            "b)\tString of floating numbers",
            "c)\tString of binary numbers",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tLogic operation on gray-scale images are done by processing of pixel values as string of binary numbers. "
    },
    {
        "id": 425,
        "Question": "What is the equivalent for a black, 8-bit pixel to be processed under logic operation on gray scale image?",
        "Options": [
            "a)\tA string: 00000000",
            "b)\tA string: 11111111",
            "c)\tA string: 10000000",
            "d)\tA string: 01111111"
        ],
        "Answer": "Answer: a\nExplanation:\tLogic operation on gray-scale images are done by processing of pixel values as string of binary numbers, so, a black, 8-bit pixel is processed as a string of eight 0’s."
    },
    {
        "id": 426,
        "Question": "Which of the following operation(s) is/are equivalent to negative transformation?",
        "Options": [
            "a)\tAND",
            "b)\tOR",
            "c)\tNOT",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tApplying NOT operator on a black, 8-bit pixel gives a white, 8-bit pixel, so, is equivalent to negative transformation."
    },
    {
        "id": 427,
        "Question": "Which of the following operations are used for masking?",
        "Options": [
            "a)\tAND, OR",
            "b)\tAND, NOT",
            "c)\tNOT, OR",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tAND, OR operators are used for masking, while NOT works as negative transformation."
    },
    {
        "id": 428,
        "Question": "Two images having one pixel gray value 01010100 and 00000101 at the same location, are operated against AND operator. What would be the resultant pixel gray value at that location in the enhanced image?",
        "Options": [
            "a)\t10100100",
            "b)\t11111011",
            "c)\t00000100",
            "d)\t01010101"
        ],
        "Answer": "Answer: c\nExplanation:\tFor AND operation results in 1 only for 1AND 1, else 0.\nAll the bits of the given gray value are operated similar resulting in 00000100."
    },
    {
        "id": 429,
        "Question": "Which of the following arithmetic operator is primarily used as a masking operator in enhancement?",
        "Options": [
            "a)\tAddition",
            "b)\tSubtraction",
            "c)\tMultiplication",
            "d)\tDivision"
        ],
        "Answer": "Answer: c\nExplanation:\tMultiplication of one image by another is used as a gray-level mask."
    },
    {
        "id": 430,
        "Question": "1.\tWhich of the following is/are more commercially successful image enhancement method in mask mode radiography, an area under medical imaging?",
        "Options": [
            "a)\tAddition",
            "b)\tSubtraction",
            "c)\tMultiplication",
            "d)\tDivision"
        ],
        "Answer": "Answer: b\nExplanation:\tIn the given area of medical imaging, a mask of an X-ray image of a region of subject is captured using TV camera is subtracted from image of same region taken after injecting a contrast medium to the bloodstream. The subtraction result gives an enhanced detail of how a contrast medium propagates through the bloodstream.\nThis the best commercially successful method."
    },
    {
        "id": 431,
        "Question": "2.\tThe subtraction operation results in areas that appear as dark shades of gray. Why?",
        "Options": [
            "a)\tBecause the difference in such areas is little, that yields low value",
            "b)\tBecause the difference in such areas is high, that yields low value",
            "c)\tBecause the difference in such areas is high, that yields high value",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tThere remains a little change in some areas in the images to be subtracted that yields low value and so the result appears as dark shades of gray."
    },
    {
        "id": 432,
        "Question": "3.\tIf the images are displayed using 8-bits, then, what is the range of the value of an image if the image is a result of subtraction operation?",
        "Options": [
            "a)\t0 to 255",
            "b)\t0 to 511",
            "c)\t-255 to 0",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation:\tThe range of a result of a subtracted image is -255 m inimum to 255 max imum, if 8-bit channel is used to display the original images."
    },
    {
        "id": 433,
        "Question": "4.\tThe subtracted image needs to be scaled, if 8-bit channel is used to display the subtracted images. So, the method of adding 255 to each pixel and then dividing by 2, has certain lim its. What is/are those lim its?",
        "Options": [
            "a)\tVery complex method",
            "b)\tVery difficult to implement",
            "c)\tThe truncation inherent in division by 2 causes loss in accuracy",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tThe given method is quite simple and easy to implement, however it has the lim itation of accuracy loss because of truncation inherent in division by 2 and also that it doesn’t ensure the full range usage."
    },
    {
        "id": 434,
        "Question": "5.\tWhich of the following is/are the fundamental factors that need tight control for difference based inspection work?",
        "Options": [
            "a)\tProper registration",
            "b)\tControlled illum ination",
            "c)\tNoise levels should be low enough so that the variation due to noise won’t affect the difference value much",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation:\tProper Registration does special marking into the product in case two images are identical so as the difference won’t create any sense.\nControlled Illum ination is important because changes in illum ination can affect dramatically the difference image values.\nNoise levels of a difference image must low enough so that the variation due to noise won’t affect the difference value much."
    },
    {
        "id": 435,
        "Question": "6.\tWhen can two random variables be uncorrelated?",
        "Options": [
            "a)\tTheir covariance is 0",
            "b)\tTheir covariance is 1",
            "c)\tTheir covariance is -1",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tThe covariance of two random variables x i and x j given by: E [(x i – m i) (x j – mj)], E {.} is expected value of the argument and m is the mean. If this covariance turns out to 0, the variables are uncorrelated."
    },
    {
        "id": 436,
        "Question": "7.\tIn Image Averaging enhancement method assumptions are made for a noisy image g(x, y). What is/are those?",
        "Options": [
            "a)\tThe noise is correlated at every pair of coordinate (x, y)",
            "b)\tThe noise has average value 1 at every pair of coordinate (x, y)",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation:\tIn Image Averaging enhancement method assumptions are made for a noisy image g(x, y) that at every coordinate (x, y) the noise has 0 average value and must be uncorrelated."
    },
    {
        "id": 437,
        "Question": "8.\tThe standard deviation ‘σ’ at any point in image averaging: σḡ(x, y) = 1/√K σɳ(x, y), where ḡ(x, y) is the average image formed by averaging K different noisy images and ɳ(x, y) is the noise added to an original image f(x, y). What is the relation between K and the variability of the pixel values at each location (x, y)?",
        "Options": [
            "a)\tIncrease in K, decreases the noise of pixel values",
            "b)\tIncrease in K, increases the noise of pixel values",
            "c)\tDecrease in K, decreases the noise of pixel values",
            "d)\tDecrease in K, increases the noise of pixel values"
        ],
        "Answer": "Answer: a\nExplanation:\tAs K increases, E {ḡ(x, y)} the expected value approaches f(x, y) the original image, i.e. decreasing the noise component."
    },
    {
        "id": 438,
        "Question": "1.\tA filter is applied to an image whose response is independent of the direction of discontinuities in the image. The filter is/are ________",
        "Options": [
            "a)\tIsotropic filters",
            "b)\tBox filters",
            "c)\tMedian filter",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tIsotropic filter are rotation invariant because it has a same response when applied to the image first and the after rotating the image."
    },
    {
        "id": 439,
        "Question": "2.\tIn isotropic filtering, which of the following is/are the simplest isotropic derivative operator?",
        "Options": [
            "a)\tLaplacian",
            "b)\tGradient",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tAn isotropic filtering is an example of second order derivative for enhancement and uses Laplacian as the simplest derivative operator, while gradient is used with first derivatives."
    },
    {
        "id": 440,
        "Question": "3.\tThe Laplacian is which of the following operator?",
        "Options": [
            "a)\tNonlinear operator",
            "b)\tOrder-Statistic operator",
            "c)\tLinear operator",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tDerivative of any order are linear operations and since, Laplacian is the simplest isotropic derivative operator, so is a linear operator.\nOrder-Statistics operator are nonlinear operators."
    },
    {
        "id": 441,
        "Question": "4.\tA Laplacian for an image f(x, y) is defined as: <img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-second-order-derivative-enhancement-q5.png\" alt=\"digital-image-processing-questions-answers-second-order-derivative-enhancement-q5\" width=\"209\" height=\"38\" class=\"alignnone size-full wp-image-148757\" />  is given by ________",
        "Options": [
            "a)\t[f(x + 1, y) + f(x – 1, y) – 2f(x, y)] and [f(x, y + 1) + f(x, y – 1) – 2f(x, y)] respectively",
            "b)\t[f(x + 1, y + 1) + f(x, y – 1) – 2f(x, y)] and [f(x , y + 1) + f(x – 1, y) – 2f(x, y)] respectively",
            "c)\t[f(x, y + 1) + f(x, y – 1) – 2f(x, y)] and [f(x + 1, y) + f(x – 1, y) – 2f(x, y)] respectively",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tFor a Laplacian given by:∇2 f=<img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-second-order-derivative-enhancement-q4.png\" alt=\"digital-image-processing-questions-answers-second-order-derivative-enhancement-q4\" width=\"62\" height=\"36\" class=\"alignnone size-full wp-image-148749\" />\nApplying second order derivative in x direction (∂2 f)/∂x2  = [f(x + 1, y) + f(x – 1, y) – 2f(x, y)], and\nApplying second order derivative in y direction (∂2 f)/∂y2 = [f(x, y + 1) + f(x, y – 1) – 2f(x, y)]."
    },
    {
        "id": 442,
        "Question": "5.\tThe Laplacian ∇2 f=[f(x + 1, y) + f(x – 1, y) + f(x, y + 1) + f(x, y – 1) – 4f(x, y)], gives an isotropic result for rotations in increment by what degree?",
        "Options": [
            "a)\t90o",
            "b)\t0o",
            "c)\t45o",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tThe given Laplacian gives isotropic result for 90o incremental rotations."
    },
    {
        "id": 443,
        "Question": "6.\tThe Laplacian incorporated with diagonal directions, i.e.  ∇2 f=[f(x + 1, y) + f(x – 1, y) + f(x, y + 1) + f(x, y – 1) – 8f(x, y)], gives an isotropic result for rotations in increment by what degree?",
        "Options": [
            "a)\t90o",
            "b)\t0o",
            "c)\t45o",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tThe given Laplacian since includes the diagonal direction, so, gives an isotropic result for  45o incremental rotations."
    },
    {
        "id": 444,
        "Question": "7.\tApplying Laplacian has which of the following result(s)?",
        "Options": [
            "a)\tProduces image having greyish edge lines",
            "b)\tProduces image having featureless background",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tSince, Laplacian is a derivative operator, so, highlights the gray-level discontinuities in an image and deemphasizes areas with slowly varying gray levels. Hence, produces images having greyish edge lines superimposed on featureless background."
    },
    {
        "id": 445,
        "Question": "8.\tApplying Laplacian produces image having featureless background which is recovered maintaining the sharpness of Laplacian operation by either adding or subtracting it from the original image depending upon the Laplacian definition used. Which of the following is true based on above statement?",
        "Options": [
            "a)\tIf definition used has a negative center coefficient, then subtraction is done",
            "b)\tIf definition used has a positive center coefficient, then subtraction is done",
            "c)\tIf definition used has a negative center coefficient, then addition is done",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tApplying Laplacian produces image having featureless background which is recovered maintaining the sharpness of Laplacian operation using original image either added if Laplacian definition used has a positive center coefficient  or subtracting result from original image if has a negative center coefficient."
    },
    {
        "id": 446,
        "Question": "9.\tA mask of size 3*3 is formed using Laplacian including diagonal neighbors that has central coefficient as 9. Then, what would be the central coefficient of same mask if it is made without diagonal neighbors?",
        "Options": [
            "a)\t 5",
            "b)\t-5",
            "c)\t8",
            "d)\t-8"
        ],
        "Answer": "Answer: a\nExplanation:\tThe mask formed by eliminating diagonal neighbors i.e. 4f(x, y), since each diagonal contain a -2f(x, y), the mask has 5 as its central coefficient. "
    },
    {
        "id": 447,
        "Question": "10.\tWhich of the following mask(s) is/are used to sharpen images by subtracting a blurred version of original image from the original image itself?",
        "Options": [
            "a)\tUnsharp mask",
            "b)\tHigh-boost filter",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tUnsharp mask sharpens images by subtracting a blurred version of original image from the original image itself.\nA high-boost filter is a generalized form of unsharp mask."
    },
    {
        "id": 448,
        "Question": "11.\tWhich of the following gives an expression for high boost filtered image fhb, if f represents an image, f blurred version of f, fs  unsharp mask filtered image and A ≥ 1?",
        "Options": [
            "a)\tfhb = (A – 1) f(x, y) + f(x, y) – f x, y)",
            "b)\tfhb = A f(x, y) – f(x,y)",
            "c)\tfhb = (A – 1) f(x, y) + fs(x, y)",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: d\nExplanation:\tA high-boost filter is a generalized form of unsharp mask and is given by:\n\tfhb = A f(x, y) – f (x, y)\n\tOr, fhb = (A – 1) f(x, y) + f(x, y) – f(x, y), that can be written as\n\tfhb = (A – 1) f(x, y) + fs(x, y), where fs(x, y) = f(x, y) – f (x, y)."
    },
    {
        "id": 449,
        "Question": "12.\tIf we use a Laplacian to obtain sharp image for unsharp mask filtered image fs(x, y) of f(x, y) as input image, and if the center coefficient of the Laplacian mask is negative then, which of the following expression gives the high boost filtered image fhb, if ∇2 f represent Laplacian?",
        "Options": [
            "a)\tfhb = A f(x, y) – ∇2  f(x,y)",
            "b)\tfhb = A f(x, y) + ∇2  f(x,y)",
            "c)\tfhb = ∇2 f(x,y)",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tIf Laplacian is used to obtain sharp image for unsharp mask filtered image, then\n\t<img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-second-order-derivative-enhancement-q12.png\" alt=\"digital-image-processing-questions-answers-second-order-derivative-enhancement-q12\" width=\"508\" height=\"36\" class=\"alignnone size-full wp-image-148759\" srcset=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-second-order-derivative-enhancement-q12.png 508w, https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-second-order-derivative-enhancement-q12-300x21.png 300w\" sizes=\"(max-width: 508px) 100vw, 508px\" />."
    },
    {
        "id": 450,
        "Question": "For what value of A this high boost filtering becomes the standard Laplacian sharpening filter?",
        "Options": [
            "a)\t0",
            "b)\t1",
            "c)\t-1",
            "d)\t∞"
        ],
        "Answer": "Answer: b\nExplanation:\tfor A=1 the high boost filtering is given by:\n<img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-second-order-derivative-enhancement-q12.png\" alt=\"digital-image-processing-questions-answers-second-order-derivative-enhancement-q12\" width=\"508\" height=\"36\" class=\"alignnone size-full wp-image-148759\" srcset=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-second-order-derivative-enhancement-q12.png 508w, https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-second-order-derivative-enhancement-q12-300x21.png 300w\" sizes=\"(max-width: 508px) 100vw, 508px\" />."
    },
    {
        "id": 451,
        "Question": "2.\tSubtracting Laplacian from an image is proportional to which of the following?",
        "Options": [
            "a)\tUnsharp masking",
            "b)\tBox filter",
            "c)\tMedian filter",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tAs the value of A increases, sharpening process contribution becomes less important and so at some very large value A, the contribution becomes almost negligible and so high boost filtered image is approximately equal to the original image."
    },
    {
        "id": 452,
        "Question": "3.\tA First derivative in image processing is implemented using which of the following given operator(s)?",
        "Options": [
            "a)\tMagnitude of Gradient vector",
            "b)\tThe Laplacian",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tsubtracting Laplacian from an image gives:\nf(x,y)- ∇2 f(x,y) = f(x, y) – [f(x + 1, y) + f(x – 1, y) + f(x, y + 1) + f(x, y – 1) – 4f(x, y)]\nThat on calculation gives 5[1.2 f(x, y) – f ̅(x, y)] ≈ 5[f(x, y) – f(x, y)]\nWhere f(x, y) – f(x, y) is the unsharp masking definition."
    },
    {
        "id": 453,
        "Question": "4.\tIf for an image function f(x, y), the magnitude of gradient vector <img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-bank-q4.png\" alt=\"digital-image-processing-questions-bank-q4\" width=\"112\" height=\"53\" class=\"alignnone size-full wp-image-148764\" />is given by: mag(∇f)=[G2x+G2y] (1/2), then which of the following fact is correct?",
        "Options": [
            "a)\tThe component of Gradient vector are linear operator and also the magnitude of the vector",
            "b)\tThe component of Gradient vector are linear operator, but the magnitude are not",
            "c)\tThe component of Gradient vector are nonlinear operator and also the magnitude of the vector",
            "d)\tThe component of Gradient vector are nonlinear operator, but the magnitude are not"
        ],
        "Answer": "Answer: a\nExplanation:\tMagnitude of Gradient vector is used for implementation of first derivative in image processing, while Laplacian is for second order implementation in image processing."
    },
    {
        "id": 454,
        "Question": "5.\tWhat is the sum of the coefficient of the mask defined using gradient?",
        "Options": [
            "a)\t1",
            "b)\t-1",
            "c)\t0",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tThe component of Gradient vector are linear operator because these are derivatives but the magnitude of the vector are not because of the squaring and square root operations."
    },
    {
        "id": 455,
        "Question": "6.\tGradient is used in which of the following area(s)?",
        "Options": [
            "a)\tTo aid humans in detection of defects",
            "b)\tAs a preprocessing step for automated inspections",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tSince, first order derivative of a digital function must be zero in the areas of constant grey values. So, the mask using gradient has a sum 0, so to produce a zero result if applied on constant gray level areas."
    },
    {
        "id": 456,
        "Question": "7.\tGradient have some important features. Which of the following is/are some of them?",
        "Options": [
            "a)\tEnhancing small discontinuities in an otherwise flat gray field",
            "b)\tEnhancing prominent edges",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tGradient has a usage in both human analysis as well as a preprocessing step for automated inspections."
    },
    {
        "id": 457,
        "Question": "8.\tAn image has significant edge details. Which of the following fact(s) is/are true for the gradient image and the Laplacian image of the same?",
        "Options": [
            "a)\tThe gradient image is brighter than the Laplacian image",
            "b)\tThe gradient image is brighter than the Laplacian image",
            "c)\tBoth the gradient image and the Laplacian image has equal values",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tSince gradient are used in fist order derivative image enhancement that enhances the discontinuities except for in flat areas and produces thick edge for constant slope ramp. So, Gradient has all the mentioned features."
    },
    {
        "id": 458,
        "Question": "1.\tThe expression [∂2 f(x,y)/∂x2 +∂2 f(x,y)/∂y2] is considered as _________ where f(x, y) is an input image.",
        "Options": [
            "a)\tLaplacian of f(x, y)",
            "b)\tGradient of f(x, y)",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tThe Laplacian for an image f(x, y) is defined as: ∇2 f=∂2 f/∂x2 +  ∂2 f/∂y2 ."
    },
    {
        "id": 459,
        "Question": "2.\tIf the Laplacian in frequency domain is: <img src=\"https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-entrance-exams-q2.png\" alt=\"digital-image-processing-questions-answers-entrance-exams-q2\" width=\"262\" height=\"33\" class=\"alignnone size-full wp-image-148782\" /> where is the Fourier transform operator and F(u, v) is Fourier transformed function of f(x, y), then what is -(u2+ v2) is considered as?",
        "Options": [
            "a)\tLaplacian operation",
            "b)\tFiltering operation",
            "c)\tShift operation",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tThe Laplacian in frequency domain is simply implemented by using filter:\nH(u, v)= -(u2+ v2)."
    },
    {
        "id": 460,
        "Question": "3.\tThe Laplacian in frequency domain is simply implemented by using filter __________",
        "Options": [
            "a)\tH(u, v)= -(u2– v2)",
            "b)\tH(u, v)= -(1)",
            "c)\tH(u, v)= -(u2+ v2)",
            "d)\tnone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tLaplacian in frequency domain is: I[(∂2 f(x,y))/∂x2 +(∂2 f(x,y))/∂y2 ]= -(u2+v2)F(u,v), where ℑ is the Fourier transform operator and F(u, v) is Fourier transformed function of f(x, y) and -(u2+ v2) is the filter."
    },
    {
        "id": 461,
        "Question": "4.\tAssuming that the origin of F(u, v), Fourier transformed function of f(x, y) an input image, has been correlated by performing the operation f(x, y)(-1)x+y prior to taking the transform of the image. If F and f are of same size, then what does the given operation is/are supposed to do?",
        "Options": [
            "a)\tResize the transform",
            "b)\tRotate the transform",
            "c)\tShifts the center transform",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tThe given operation f(x, y)(-1)x+y shifts the center transform so that (u, v)=(0,0) is at point (M/2, N/2) for F and f of same size M*N."
    },
    {
        "id": 462,
        "Question": "5.\tAssuming that the origin of F(u, v), Fourier transformed function of f(x, y) an input image, has been correlated by performing the operation f(x, y)(-1)x+y prior to taking the transform of the image. If F and f are of same size M*N, where does the point (u, v) =(0,0) shifts?",
        "Options": [
            "a)\t(M -1, N -1)",
            "b)\t(M/2, N/2)",
            "c)\t(M+1, N+1)",
            "d)\t(0, 0)"
        ],
        "Answer": "Answer: b\nExplanation:\tThe given operation f(x, y)(-1)x+y shifts the center transform so that (u, v)=(0, 0) is at point (M/2, N/2) for F and f of same size M*N."
    },
    {
        "id": 463,
        "Question": "6.\tAssuming that the origin of F(u, v), Fourier transformed function of f(x, y) an input image, has been correlated by performing the operation f(x, y)(-1)x+y prior to taking the transform of the image. If F and f are of same size M*N, then which of the following is an expression for H(u, v), the filter used for implementing Laplacian in frequency domain?",
        "Options": [
            "a)\tH(u, v)= -(u2+ v2)",
            "b)\tH(u, v)= -(u2– v2)",
            "c)\tH(u, v)= -[(u – M/2)2+ (v – N/2)2].",
            "d)\tH(u, v)= -[(u – M/2)2– (v – N/2)2]."
        ],
        "Answer": "Answer: c\nExplanation:\tThe given operation f(x, y)(-1)x+y shifts the center transform so that (u, v)=(0, 0) is at point (M/2, N/2) and hence the filter is: H(u, v)= -[(u – M/2)2+ (v – N/2)2]."
    },
    {
        "id": 464,
        "Question": "7.\tComputing the Fourier transform of the Laplacian result in spatial domain is equivalent to multiplying the F(u, v), Fourier transformed function of f(x, y) an input image, and H(u, v), the filter used for implementing Laplacian in frequency domain. This dual relationship is expressed as _________",
        "Options": [
            "a)\tFourier transform pair notation",
            "b)\tLaplacian",
            "c)\tGradient",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: a\nExplanation:\tThe Fourier transform of the Laplacian result in spatial domain is equivalent to multiplying the F(u, v) and H(u, v). This dual relationship is expressed as Fourier transform pair notation given by: ∇2 f(x,y)-[(u – M/2)2+ (v – N/2)2]F(u,v), for an image of size M *N."
    },
    {
        "id": 465,
        "Question": "8.\tComputing the Fourier transform of the Laplacian result in spatial domain is equivalent to multiplying the F(u, v), Fourier transformed function of f(x, y) an input image of size M*N, and H(u, v), the filter used for implementing Laplacian in frequency domain. This dual relationship is expressed as Fourier transform pair notation given by_____________",
        "Options": [
            "a)\t∇2 f(x,y)↔[(u –M/2)2+ (v –N/2)2]F(u,v)",
            "b)\t∇2 f(x,y)↔-[(u+M/2)2– (v+N/2)2]F(u,v)",
            "c)\t∇2 f(x,y)↔-[(u –M/2)2+ (v –N/2)2]F(u,v)",
            "d)\t∇2 f(x,y)↔[(u+M/2)2– (v+N/2)2]F(u,v)"
        ],
        "Answer": "Answer: c\nExplanation:\tThe Fourier transform of the Laplacian result in spatial domain is equivalent to multiplying the F(u, v) and H(u, v). This dual relationship is expressed as Fourier transform pair notation given by:∇2 f(x,y)↔-[(u – M/2)2+ (v – N/2)2]F(u,v), for an image of size M*N."
    },
    {
        "id": 466,
        "Question": "9.\tAn enhanced image can be obtained as: g(x,y)=f(x,y)-∇2 f(x,y), where Laplacian is being subtracted from f(x, y) the input image. What does this conclude?",
        "Options": [
            "a)\tThat the center spike would be negative",
            "b)\tThat the immediate neighbors of center spike would be positive.",
            "c)\tAll of the mentioned",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tFor the above given enhanced image the Laplacian subtraction suggest that the center coefficient of Laplacian mask is negative and so the center spike is negative with its immediate neighbors being positive."
    },
    {
        "id": 467,
        "Question": "10.\tAn enhanced image can be obtained as: g(x,y)=f(x,y)-∇2 f(x,y), where Laplacian is being subtracted from f(x, y) the input image of size M*Non which an operation f(x, y)(-1)x+yis applied.Unlike enhancing in spatial domain with one single mask, it is possible to perform the same in frequency domain using one filter. Which of the following is/are the required filter(s)?",
        "Options": [
            "a)\tH(u, v)= -[1 + u2+ v2].",
            "b)\tH(u, v)= -[(u – M/2)2+ (v– N/2)2].",
            "c)\tH(u, v)= [1 + (u – M/2)2+ (v – N/2)2].",
            "d)\tAll of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tThe filter H(u, v)= [1 + (u – M/2)2+ (v – N/2)2] is used to perform the same enhancement in frequency domain like in spatial domain."
    },
    {
        "id": 468,
        "Question": "11.\tWhy is scaling of Laplacian filtered images necessary?",
        "Options": [
            "a)\tBecause it contain high positive values",
            "b)\tBecause it contain high negative value",
            "c)\tBecause it contain both positive and negative values",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: c\nExplanation:\tA Laplacian filtered image contain both positive and negative values of comparable magnitudes. So, scaling is necessary."
    },
    {
        "id": 469,
        "Question": "12.\tWhich of the following fact is true for the masks that includes diagonal neighbors than the masks that doesn’t?",
        "Options": [
            "a)\tMask that excludes diagonal neighbors has more sharpness than the masks that doesn’t",
            "b)\tMask that includes diagonal neighbors has more sharpness than the masks that doesn’t",
            "c)\tBoth masks have same sharpness result",
            "d)\tNone of the mentioned"
        ],
        "Answer": "Answer: b\nExplanation:\tIncluding diagonal neighbor pixels enhances sharpness of the image. So, Mask that includes diagonal neighbors has more sharpness than the masks that doesn’t."
    }
]